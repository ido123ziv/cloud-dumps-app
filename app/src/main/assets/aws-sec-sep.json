[
    {
        "Correct": [
            "Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the proper API key. Launch each Amazon EC2 instance with the proper IAM role.\n"
        ],
        "Answers": [
            "Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM user with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the API key for the environment. Store an access key for that user in a credential store on each Amazon EC2 instance.\n",
            "Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the proper API key. Launch each Amazon EC2 instance with the proper IAM role.\n",
            "Create an Amazon DynamoDB table encrypted with an AWS KMS customer master key (CMK). Store each API key in a different item in the table. Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the dynamodb:getitem action for the correct item. Launch each Amazon EC2 instance with the proper IAM role.\n",
            "Pass the proper API key to each Amazon EC2 instance upon launch utilizing user data. Assign an IAM role to each EC2 instance with permissions to the kms:encrypt and the kms:decrypt actions for a customer-managed AWS KMS customer master key (CMK). In the user data script, encrypt the API key using the CMK. Store the encrypted API key on each EC2 instance.\n"
        ],
        "Question": "A company is migrating an application from its data center to AWS. The application currently stores an API key used to access a third-party service in a local file. When deployed on AWS, the application will run on Amazon EC2 instances. As part of the migration, the application must make the API key more secure. Specifically: Each environment (such as development, test, and production) must have its own API key. All API key access requests should be logged for auditing purposes. The API keys must be encrypted at rest using a customer-managed key. Access permissions must be granular; the development environment cannot access the production API key, for example. What is the MOST secure way to meet these requirements?\n",
        "id": 10
    },
    {
        "Correct": [
            "Outbound; Protocol tcp; Destination 169.254.169.254; Destination port 80\n"
        ],
        "Answers": [
            "Inbound; Protocol tcp; Source [Instance`s EIP]; Destination 169.254.169.254\n",
            "Inbound; Protocol tcp; Destination 169.254.169.254; Destination port 80\n",
            "Outbound; Protocol tcp; Destination 169.254.169.254; Destination port 80\n",
            "Outbound; Protocol tcp; Destination 169 .254.169.254; Destination port 443\n"
        ],
        "Question": "Your security team implements a host-based firewall on all of your Amazon Elastic Compute Cloud (EC2) instances to block all outgoing traffic. Exceptions must be requested for each specific requirement. Until you request a new rule, you cannot access the instance metadata service. Which firewall rule should you request to be added to your instances to allow instance metadata access?\n",
        "id": 11
    },
    {
        "Correct": [
            "Enable Encryption during the DynamoDB table creation\n"
        ],
        "Answers": [
            "Enable Encryption during the DynamoDB table creation\n",
            "Enable Encryption on the existing table\n",
            "DynamoDB does not support encryption at rest, use AWS RDS service instead\n",
            "DynamoDB does not support encryption at rest, use AWS Redshift service instead\n"
        ],
        "Question": "Your company is going to develop an application in .Net Core which is going to store the data in a DynamoDB table. Security team mandates that all the data needs to be encrypted at rest. How can you achieve this?\n",
        "id": 12
    },
    {
        "Correct": [
            "Enable the CloudTrail file integrity feature on the trail. Use the digest file created by CloudTrail to verify the integrity of the delivered CloudTrail files.\n"
        ],
        "Answers": [
            "Create an Amazon CloudWatch Events rule that triggers an AWS Lambda function when a new file is delivered. Configure the Lambda function to perform an MD5 hash check on the file, store the name and location of the file, and post the returned hash to an Amazon DynamoDB table. The Security team can use the values stored in DynamoDB to verify the file authenticity.\n",
            "Enable the CloudTrail file integrity feature on an Amazon S3 bucket. Create an IAM policy that grants the Security team access to the file integrity logs stored in the S3 bucket.\n",
            "Enable the CloudTrail file integrity feature on the trail. Use the digest file created by CloudTrail to verify the integrity of the delivered CloudTrail files.\n",
            "Create an AWS Lambda function that is triggered each time a new file is delivered to the CloudTrail bucket. Configure the Lambda function to execute an MD5 hash check on the file, and store the result on a tag in an Amazon S3 object. The Security team can use the information on the tag to verify the integrity of the file.\n"
        ],
        "Question": "Security team wants to ensure that AWS CloudTrail files are not tampered with after being created. Currently, there is a process with multiple trails, using AWS IAM to restrict access to specific trails. The Security team wants to ensure they can trace the integrity of each file and make sure there has been no tampering. Which option will require the LEAST effort to implement and ensure the legitimacy of the file while allowing the Security team to prove the authenticity of the logs?\n",
        "id": 13
    },
    {
        "Correct": [
            "Configure the CloudTrail service in each AWS account and have the logs delivered to a single AWS bucket in the primary account and grant the auditor access to that single bucket in the primary account.\n"
        ],
        "Answers": [
            "Configure the CloudTrail service in each AWS account, and have the logs delivered to an AWS bucket on each account, while granting the auditor permissions to the bucket via roles in the secondary accounts and a single primary IAM account that can assume a read-only role in the secondary AWS accounts.\n",
            "Configure the CloudTrail service in the primary AWS account and configure consolidated billing for all the secondary accounts. Then grant the auditor access to the S3 bucket that receives the CloudTrail log files.\n",
            "Configure the CloudTrail service in each AWS account and enable consolidated logging inside of CloudTrail.\n",
            "Configure the CloudTrail service in each AWS account and have the logs delivered to a single AWS bucket in the primary account and grant the auditor access to that single bucket in the primary account.\n"
        ],
        "Question": "An auditor needs access to logs that record all API events on AWS. The auditor only needs read-only access to the log files and does not need access to each AWS account. The company has multiple AWS accounts, and the auditor needs access to all the logs for all the accounts. What is the best way to configure access for the auditor to view event logs from all accounts? Choose the correct answer from the options below\n",
        "id": 14
    },
    {
        "Correct": [
            "Launch the EC2 instances with an EC2 IAM role to access AWS services. Retrieve the database credentials from AWS Secrets Manager.\n"
        ],
        "Answers": [
            "Retrieve an access key from an AWS Systems Manager SecureString parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.\n",
            "Launch the EC2 instances with an EC2 IAM role to access AWS services. Retrieve the database credentials from AWS Secrets Manager.\n",
            "Retrieve an access key from an AWS Systems Manager plaintext parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.\n",
            "Launch the EC2 instances with an EC2 IAM role to access AWS services. Store the database passwords in an encrypted config file with the application artifacts.\n"
        ],
        "Question": "A large enterprise is deploying a web application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The application stores data in an Amazon RDS Oracle DB instance and Amazon DynamoDThere are separate environments for development, testing, and production. What is the MOST secure and flexible way to obtain password credentials during deployment?\n",
        "id": 15
    },
    {
        "Correct": [
            "Create a new S3 bucket. Configure CloudTrail in both accounts to log to this bucket.\n",
            "Create a new IAM role to control access to the S3 bucket.\n",
            "Create an S3 Bucket Policy to control access to the S3 bucket.\n"
        ],
        "Answers": [
            "Create a new S3 bucket. Configure CloudTrail in both accounts to log to this bucket.\n",
            "Use the existing S3 buckets in each account. Configure CloudTrail in each account to log to its own S3 bucket.\n",
            "Create a new IAM user policy to control access to the S3 bucket.\n",
            "Create a new IAM role to control access to the S3 bucket.\n",
            "Allow CloudTrail to perform PUT operations, explicitly deny GET operations, and explicitly allow the Security Team to perform GET operations.\n",
            "Allow CloudTrail to perform PUT operations. Allow the Security Team to perform GET operations.\n",
            "Create an S3 Bucket Policy to control access to the S3 bucket.\n"
        ],
        "Question": "Your organization has two AWS accounts; one for development and the other for production. Each account has EC2 instances running as web servers, a load balancer, and an RDS database. Your security team has asked you to ensure that they can log all interactions with these AWS services and that users cannot tamper with logs. Which of the following steps should you take? (Choose three)\n",
        "id": 16
    },
    {
        "Correct": [
            "Implement a \"write-only\" CloudTrail event filter to detect any modifications to the AWS account resources.\n"
        ],
        "Answers": [
            "Implement a \"write-only\" CloudTrail event filter to detect any modifications to the AWS account resources.\n",
            "Configure Amazon Macie to classify and discover sensitive data in the Amazon S3 bucket that contains the CloudTrail audit logs.\n",
            "Configure Amazon Athena to read from the CloudTrail S3 bucket and query the logs to examine account activities.\n",
            "Enable Amazon S3 event notifications to trigger an AWS Lambda function that sends an email alarm when there are new CloudTrail API entries.\n"
        ],
        "Question": "A Security Administrator is performing a log analysis as a result of a suspected AWS account compromise. The Administrator wants to analyze suspicious AWS CloudTrail log files but is overwhelmed by the volume of audit logs being generated. What approach enables the Administrator to search through the logs MOST efficiently?\n",
        "id": 17
    },
    {
        "Correct": [
            "Use an EC2 run command to confirm that the \"awslogs\" service is running on all instances.\n",
            "Verify that the permissions used by the agent allow creation of log groups/streams and to put log events.\n"
        ],
        "Answers": [
            "Use an EC2 run command to confirm that the \"awslogs\" service is running on all instances.\n",
            "Verify that the permissions used by the agent allow creation of log groups/streams and to put log events.\n",
            "Check whether any application log entries were rejected because of invalid time stamps by reviewing /var/cwlogs/rejects.log.\n",
            "Check that the trust relationship grants the service \"cwlogs.amazonaws.com\" permission to write objects to the Amazon S3 staging bucket.\n",
            "Verify that the time zone on the application servers is in UTC.\n"
        ],
        "Question": "An organization is using Amazon CloudWatch Logs with agents deployed on its Linux Amazon EC2 instances. The agent configuration files have been checked and the application log files to be pushed are configured correctly. A review has identified that logging from specific instances is missing. Which steps should be taken to troubleshoot the issue? (Choose two.)\n",
        "id": 18
    },
    {
        "Correct": [
            "Configure a proxy solution on Amazon EC2 and route all outbound VPC traffic through it. Perform inspection within proxy software on the EC2 instance.\n",
            "Configure the host-based agent on each EC2 instance within the VPPerform inspection within the host-based agent.\n"
        ],
        "Answers": [
            "Configure a proxy solution on Amazon EC2 and route all outbound VPC traffic through it. Perform inspection within proxy software on the EC2 instance.\n",
            "Configure the host-based agent on each EC2 instance within the VPPerform inspection within the host-based agent.\n",
            "Enable VPC Flow Logs for all subnets in the VPPerform inspection from the Flow Log data within Amazon CloudWatch Logs.\n",
            "Configure Elastic Load Balancing (ELB) access logs. Perform inspection from the log data within the ELB access log files.\n",
            "Configure the CloudWatch Logs agent on each EC2 instance within the VPPerform inspection from the log data within CloudWatch Logs.\n"
        ],
        "Question": "A company requires that IP packet data be inspected for invalid or malicious content. Which of the following approaches achieve this requirement? (Choose two.)\n",
        "id": 19
    },
    {
        "Correct": [
            "The mobile app should authenticate with an Amazon Cognito identity that is authorized to write to an Amazon Kinesis Firehose with an Amazon S3 destination.\n"
        ],
        "Answers": [
            "The mobile app should write to an S3 bucket that allows anonymous PutObject calls.\n",
            "The mobile app should authenticate with an Amazon Cognito identity that is authorized to write to an Amazon Kinesis Firehose with an Amazon S3 destination.\n",
            "The mobile app should authenticate with an embedded IAM access key that is authorized to write to an Amazon Kinesis Firehose with an Amazon S3 destination.\n",
            "The mobile app should call a REST-based service that stores data on Amazon EBS. Deploy the service on multiple EC2 instances across two Availability Zones.\n"
        ],
        "Question": "A mobile application collects data that must be stored in multiple Availability Zones within five minutes of being captured in the app. What architecture securely meets these requirements?\n",
        "id": 20
    },
    {
        "Correct": [
            "Enable log file validation in the AWS CloudTrail configuration.\n",
            "Configure AWS CloudTrail logs so that they are sent to an Amazon S3 bucket in a different account that only the Security team can access.\n"
        ],
        "Answers": [
            "Enable log file validation in the AWS CloudTrail configuration.\n",
            "Choose SHA-256 as the AWS CloudTrail digest encryption format in the CloudTrail configuration.\n",
            "Configure the AWS CloudTrail Amazon S3 bucket to enable SSE by default.\n",
            "Configure AWS CloudTrail logs so that they are sent to an Amazon S3 bucket in a different account that only the Security team can access.\n",
            "Configure AWS CloudTrail logs so that they are sent to an Amazon S3 bucket with a bucket policy granting access to only the Security team's IAM group.\n"
        ],
        "Question": "A CSO requires all AWS API logs to be stored, and access to those logs to be restricted to only security personnel for auditing purposes. Personnel need to be able to validate the log integrity, and logs must be encrypted in transit and at rest. Which steps should a Security Engineer take to ensure that these requirements are met? (Select TWO.)\n",
        "id": 21
    },
    {
        "Correct": [
            "Enabling rotation in Secrets Manager causes the secret to rotate immediately and the applications are using the earlier credential.\n"
        ],
        "Answers": [
            "Migrating the credential to RDS requires that all access come through requests to the Secrets Manager.\n",
            "Enabling rotation in Secrets Manager causes the secret to rotate immediately and the applications are using the earlier credential.\n",
            "The Secrets Manager IAM policy does not allow access to the RDS database.\n",
            "The Secrets Manager IAM policy does not allow access for the applications.\n"
        ],
        "Question": "A company`s database developer has just migrated an Amazon RDS database credential to be stored and managed by AWS Secrets Manager. The developer has also enabled rotation of the credential within the Secrets Manager console and set the rotation to change every 30 days. After a short period of time, a number of existing applications have failed with authentication errors.What is the MOST likely cause of the authentication errors?\n",
        "id": 22
    },
    {
        "Correct": [
            "VPC Flow Logs\n",
            "Lambda\n"
        ],
        "Answers": [
            "Internet gateway\n",
            "VPC Flow Logs\n",
            "AWS CloudTrail\n",
            "Lambda\n",
            "AWS Inspector\n"
        ],
        "Question": "You have a three-tier web application with separate subnets for Web, Applications, and Database tiers. Your CISO suspects your application will be the target of malicious activity. You are tasked with notifying the security team in the event your application is port scanned by external systems. Which two AWS Services cloud you leverage to build an automated notification system? (Select two.)\n",
        "id": 23
    },
    {
        "Correct": [
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from sgLB sgDB: allow port 3306 traffic from sgWeb and sgBastion sgBastion: allow port 22 traffic from the corporate IP address range\n"
        ],
        "Answers": [
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from 0.0.0.0/0 sgDB: allow port 3306 traffic from sgWeb and sgBastion sgBastion: allow port 22 traffic from the corporate IP address range\n",
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from sgLB sgDB: allow port 3306 traffic from sgWeb and sgLB sgBastion: allow port 22 traffic from the VPC IP address range\n",
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from sgLB sgDB: allow port 3306 traffic from sgWeb and sgBastion sgBastion: allow port 22 and traffic from the VPC IP address range\n",
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from sgLB sgDB: allow port 3306 traffic from sgWeb and sgBastion sgBastion: allow port 22 traffic from the corporate IP address range\n"
        ],
        "Question": "A web application runs in a VPC on EC2 instances behind an ELB Application Load Balancer. The application stores data in an RDS MySQL DB instance. A Linux bastion host is used to apply schema updates to the database - administrators connect to the host via SSH from a corporate workstation. The following security groups are applied to the infrastructure- sgLB - associated with the ELB sgWeb - associated with the EC2 instances sgDB - associated with the database sgBastion - associated with the bastion host Which security group configuration will allow the application to be secure and functional?\n",
        "id": 24
    },
    {
        "Correct": [
            "Use AWS WAF to scan inbound traffic for web exploits. Use a third-party AWS Marketplace solution to restrict egress traffic to specific whitelisted URLs.\n"
        ],
        "Answers": [
            "Use AWS Shield to scan inbound traffic for web exploits. Use VPC Flow Logs and AWS Lambda to restrict egress traffic to specific whitelisted URLs.\n",
            "Use AWS Shield to scan inbound traffic for web exploits. Use a third-party AWS Marketplace solution to restrict egress traffic to specific whitelisted URLs.\n",
            "Use AWS WAF to scan inbound traffic for web exploits. Use VPC Flow Logs and AWS Lambda to restrict egress traffic to specific whitelisted URLs.\n",
            "Use AWS WAF to scan inbound traffic for web exploits. Use a third-party AWS Marketplace solution to restrict egress traffic to specific whitelisted URLs.\n"
        ],
        "Question": "The Security Engineer is managing a web application that processes highly sensitive personal information. The application runs on Amazon EC2. The application has strict compliance requirements, which instruct that all incoming traffic to the application is protected from common web exploits and that all outgoing traffic from the EC2 instances is restricted to specific whitelisted URLs.Which architecture should the Security Engineer use to meet these requirements?\n",
        "id": 25
    },
    {
        "Correct": [
            "Create an IAM role for cross-account access allows the SaaS provider`s account to assume the role and assign it a policy that allows only the actions required by the SaaS application\n"
        ],
        "Answers": [
            "From the AWS Management Console, navigate to the Security Credentials page and retrieve the access and secret key for your account.\n",
            "Create an IAM user within the enterprise account assign a user policy to the IAM user that allows only the actions required by the SaaS application create a new access and secret key for the user and provide these credentials to the SaaS provider.\n",
            "Create an IAM role for cross-account access allows the SaaS provider`s account to assume the role and assign it a policy that allows only the actions required by the SaaS application\n",
            "Create an IAM role for EC2 instances, assign it a policy that allows only the actions required tor the SaaS application to work, provide the role ARN to the SaaS provider to use when launching their application instances.\n"
        ],
        "Question": "An enterprise wants to use a third-party SaaS application. The SaaS application needs to have access to issue several API commands to discover Amazon EC2 resources running within the enterprise`s account. The enterprise has internal security policies that require any outside access to their environment must conform to the principles of least privilege and there must be controls in place to ensure that the credentials used by the SaaS vendor cannot be used by any other third party. Which of the following would meet all of these conditions?\n",
        "id": 26
    },
    {
        "Correct": [
            "The application authenticates against LDAP and retrieves the name of an IAM role associated with the user. The application then calls the IAM Security Token Service to assume that IAM role The application can use the temporary credentials to access the appropriate S3 bucket.\n",
            "Develop an identity broker that authenticates against LDAP and then calls IAM Security Token Service to get IAM federated user credentials The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.\n"
        ],
        "Answers": [
            "Develop an identity broker that authenticates against IAM security Token service to assume a IAM role in order to get temporary AWS security credentials The application calls the identity broker to get AWS temporary security credentials with access to the appropriate S3 bucket.\n",
            "The application authenticates against LDAP and retrieves the name of an IAM role associated with the user. The application then calls the IAM Security Token Service to assume that IAM role The application can use the temporary credentials to access the appropriate S3 bucket.\n",
            "Develop an identity broker that authenticates against LDAP and then calls IAM Security Token Service to get IAM federated user credentials The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.\n",
            "The application authenticates against LDAP the application then calls the AWS identity and Access Management (IAM) Security Token service to log in to IAM using the LDAP credentials the application can use the IAM temporary credentials to access the appropriate S3 bucket.\n",
            "The application authenticates against IAM Security Token Service using the LDAP credentials the application uses those temporary AWS security credentials to access the appropriate S3 bucket.\n"
        ],
        "Question": "A corporate web application is deployed within an Amazon Virtual Private Cloud (VPC) and is connected to the corporate data center via an IPsec VPN. The application must authenticate against the on-premises LDAP server. After authentication, each logged-in user can only access an Amazon Simple Storage Space (S3) keyspace specific to that user. Which two approaches can satisfy these objectives? (Choose 2 answers)\n",
        "id": 27
    },
    {
        "Correct": [
            "Use Amazon S3 Server-Side Encryption with Amazon S3-Managed Keys. Set Amazon S3 ACLs to allow access to specific elements of the platform. Use Amazon S3 to access logs for auditing.\n"
        ],
        "Answers": [
            "Use Amazon S3 Server-Side Encryption with AWS KMS-Managed Keys for storing data. Use AWS KMS Grants to allow access to specific elements of the platform. Use AWS CloudTrail for auditing.\n",
            "Use Amazon S3 Server-Side Encryption with Amazon S3-Managed Keys. Set Amazon S3 ACLs to allow access to specific elements of the platform. Use Amazon S3 to access logs for auditing.\n",
            "Use Amazon S3 Client-Side Encryption with Client-Side Master Key. Set Amazon S3 ACLs to allow access to specific elements of the platform. Use Amazon S3 to access logs for auditing.\n",
            "Use Amazon S3 Client-Side Encryption with AWS KMS-Managed Keys for storing data. Use AWS KMS Grants to allow access to specific elements of the platform. Use AWS CloudTrail for auditing.\n"
        ],
        "Question": "A solutions architect works for a company that has a data lake based on a central Amazon S3 bucket. The data contains sensitive information. The architect must be able to specify exactly which files each user can access. Users access the platform through a SAML federation Single Sign On platform. The architect needs to build a solution that allows fine grained access control, traceability of access to the objects, and usage of the standard tools (AWS Console, AWS CLI) to access the data. Which solution should the architect build?\n",
        "id": 28
    },
    {
        "Correct": [
            "The CMK specified in the application does not exist.\n",
            "The CMK specified in the application is not enabled.\n"
        ],
        "Answers": [
            "The CMK specified in the application does not exist.\n",
            "The CMK specified in the application is currently is use.\n",
            "The CMK specified in the application is using the CMK KeyID instead of CMK Amazon Resource Name.\n",
            "The CMK specified in the application is not enabled.\n",
            "The CMK specified in the application is using an alias.\n"
        ],
        "Question": "The Development team receives an error message each time the team members attempt to encrypt or decrypt a Secure String parameter from the SSM Parameter Store by using an AWS KMS customer managed key (CMK). Which CMK-related issues could be responsible? (Choose two.)\n",
        "id": 29
    },
    {
        "Correct": [
            "Use OAI for CloudFront to access private S3 objects and select the Restrict Viewer Access option in CloudFront cache behavior to use signed URLs.\n"
        ],
        "Answers": [
            "Configure CloudFront to use signed-URLs to access Amazon S3\n",
            "Store the videos as private objects in Amazon S3 and let CloudFront serve the objects by using only Origin Access Identity (OAI)\n",
            "Use Amazon S3 static website as the origin of CloudFront, and configure CloudFront to deliver the videos by generating a signed URL for users\n",
            "Use OAI for CloudFront to access private S3 objects and select the Restrict Viewer Access option in CloudFront cache behavior to use signed URLs.\n"
        ],
        "Question": "A Solutions Architect has been asked to deliver video content stored on Amazon S3 to specific users from Amazon CloudFront while restricting access by unauthorized users. How can the Architect implement a solution to meet these requirements?\n",
        "id": 30
    },
    {
        "Correct": [
            "Allow Outgoing Traffic on the NACL for ephemeral ports\n"
        ],
        "Answers": [
            "Allow Outgoing Traffic on the NACL for ephemeral ports\n",
            "Allow Outgoing Traffic on the Security groups for port 80\n",
            "Allow Outgoing Traffic on the NACL for port 80\n",
            "Allow Outgoing Traffic on the Security groups for ephemeral ports\n"
        ],
        "Question": "You have setup an EC2 Instance that hosts a web application. You have set the following rulesSecurity Group RulesAllow Inbound Traffic on port 80 from 0.0.0.0/0 Deny Outgoing TrafficNetwork ACLsAllow Inbound Traffic on port 80 from 0.0.0.0/0 Deny Outgoing TrafficUsers are complaining that they cannot access the web server. How can you ensure that the issue gets resolved?\n",
        "id": 31
    },
    {
        "Correct": [
            "Use the AWS CloudTrail console to search for user activity.\n"
        ],
        "Answers": [
            "Use the AWS CloudTrail console to search for user activity.\n",
            "Use the Amazon CloudWatch Logs console to filter CloudTrail data by user.\n",
            "Use AWS Config to see what actions were taken by the user.\n",
            "Use Amazon Athena to query CloudTrail logs stored in Amazon S3.\n"
        ],
        "Question": "The Security team believes that a former employee may have gained unauthorized access to AWS resources sometime in the past 3 months by using an identified access key.What approach would enable the Security team to find out what the former employee may have done within AWS?\n",
        "id": 32
    },
    {
        "Correct": [
            "Use AWS Config to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n"
        ],
        "Answers": [
            "Use AWS Config to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n",
            "Use Macie to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n",
            "Use CloudTrail to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n",
            "Use Trusted Advisor to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n"
        ],
        "Question": "A security team is creating a response plan in the event an employee executes unauthorized actions on AWS infrastructure. They want to include steps to determine if the employee's IAM permissions changed as part of the incident. What steps should the team document in the plan?\n",
        "id": 33
    },
    {
        "Correct": [
            "Users request a SAML assertion from your on-premises SAML 2.0-compliant identity provider (IdP) and use that assertion to obtain federated access to the AWS Management Console via the AWS single sign-on (SSO) endpoint.\n"
        ],
        "Answers": [
            "Users log in to the AWS Management Console using the AWS Command Line Interface.\n",
            "Users request a SAML assertion from your on-premises SAML 2.0-compliant identity provider (IdP) and use that assertion to obtain federated access to the AWS Management Console via the AWS single sign-on (SSO) endpoint.\n",
            "Users sign in using an OpenID Connect (OIDC) compatible IdP, receive an authentication token, then use that token to log in to the AWS Management Console.\n",
            "Users log in directly to the AWS Management Console using the credentials from your on-premises Kerberos compliant identity provider.\n"
        ],
        "Question": "Your company is migrating infrastructure to AWS. A large number of developers and administrators will need to control this infrastructure using the AWS Management Console. The Identity Management team is objecting to creating an entirely new directory of IAM users for all employees, and the employees are reluctant to commit yet another password to memory. Which of the following will satisfy both these stakeholders?\n",
        "id": 34
    },
    {
        "Correct": [
            "The external ID used by the Auditor is missing or incorrect.\n",
            "The Auditor has not been granted sts:AssumeRole for the role in the destination account.\n",
            "The role ARN used by the Auditor is missing or incorrect.\n"
        ],
        "Answers": [
            "The external ID used by the Auditor is missing or incorrect.\n",
            "The Auditor is using the incorrect password.\n",
            "The Auditor has not been granted sts:AssumeRole for the role in the destination account.\n",
            "The Amazon EC2 role used by the Auditor must be set to the destination account role.\n",
            "The secret key used by the Auditor is missing or incorrect.\n",
            "The role ARN used by the Auditor is missing or incorrect.\n"
        ],
        "Question": "A company has contracted with a third party to audit several AWS accounts. To enable the audit, cross-account IAM roles have been created in each account targeted for audit. The Auditor is having trouble accessing some of the accounts. Which of the following may be causing this problem? (Choose three.)\n",
        "id": 35
    },
    {
        "Correct": [
            "Install intrusion prevention software (IPS) on each instance.\n"
        ],
        "Answers": [
            "Use custom route tables to prevent malicious traffic from routing to the instances.\n",
            "Update security groups to deny traffic from the originating source IP addresses.\n",
            "Use network ACLs.\n",
            "Install intrusion prevention software (IPS) on each instance.\n"
        ],
        "Question": "A distributed web application is installed across several EC2 instances in public subnets residing in two Availability Zones. Apache logs show several intermittent brute-force attacks from hundreds of IP addresses at the layer 7 level over the past six months. What would be the BEST way to reduce the potential impact of these attacks in the future?\n",
        "id": 36
    },
    {
        "Correct": [
            "The encryption of data at rest has to be enabled when the Amazon EFS file system is created. The encryption of data in transit can be enabled when the file system is mounted in EC2 instance\n"
        ],
        "Answers": [
            "The encryption of data at rest has to be enabled when the Amazon EFS file system is created. The encryption of data in transit can be enabled when the file system is mounted in EC2 instance\n",
            "The encryption of data at rest and in transit can be enabled when the Amazon EFS file system is created.\n",
            "The encryption of data at rest and in transit can only be enabled when the Amazon EFS file system is mounted in EC2 instance.\n",
            "The encryption of data at rest can be enabled when the Amazon EFS file system is mounted in EC2 instance. The encryption of data in transit is enabled when the EFS file system is created using AWS console or CLI.\n"
        ],
        "Question": "An IT company has a big data analytics application that is deployed in EC2 in multiple availability zones. These EC2 instances simultaneously access a shared Amazon EFS file system using a traditional file permissions model. A recent internal security audit has found that there is a potential security risk as the EFS file system is not encrypted for either at rest or in transit. What actions could be taken to address the potential security threat posed by non-encryption of the EFS volume?\n",
        "id": 37
    },
    {
        "Correct": [
            "Post your log data to an Amazon Kinesis data stream, and subscribe your log-processing application so that is configured to process your logging data.\n"
        ],
        "Answers": [
            "Publish your data to CloudWatch Logs, and configure your application to autoscale to handle the load on demand.\n",
            "Publish your log data to an Amazon S3 bucket. Use AWS CloudFormation to create an Auto Scaling group to scale your post-processing application which is configured to pull down your log files stored in Amazon S3.\n",
            "Post your log data to an Amazon Kinesis data stream, and subscribe your log-processing application so that is configured to process your logging data.\n",
            "Configure an Auto Scaling group to increase the size of your Amazon EMR cluster.\n",
            "Create a multi-AZ Amazon RDS MySQL cluster, post the logging data to MySQL, and run a map reduce job to retrieve the required information on user counts.\n"
        ],
        "Question": "Your current log analysis application takes more than four hours to generate a report of the top 10 users of your web application. You have been asked to implement a system that can report this information in real time, ensure that the report is always up to date, and handle increases in the number of requests to your web application. Choose the option that is cost-effective and can fulfill the requirements.\n",
        "id": 38
    },
    {
        "Correct": [
            "Use TCP load balancing on the load balancer, SSL termination on the Amazon EC2 instances, OS-level disk encryption on the Amazon EBS volumes, and Amazon S3 with server-side encryption.\n",
            "Use SSL termination on the load balancer, an SSL listener on the Amazon EC2 instances, Amazon EBS encryption on EBS volumes containing PHI, and Amazon S3 with server-side encryption.\n"
        ],
        "Answers": [
            "Use SSL termination on the load balancer, Amazon EBS encryption on Amazon EC2 instances, and Amazon S3 with server-side encryption.\n",
            "Use SSL termination with a SAN SSL certificate on the load balancer, Amazon EC2 with all Amazon EBS volumes using Amazon EBS encryption, and Amazon S3 with server-side encryption with customer-managed keys.\n",
            "Use TCP load balancing on the load balancer, SSL termination on the Amazon EC2 instances, OS-level disk encryption on the Amazon EBS volumes, and Amazon S3 with server-side encryption.\n",
            "Use TCP load balancing on the load balancer, SSL termination on the Amazon EC2 instances, and Amazon S3 with server-side encryption.\n",
            "Use SSL termination on the load balancer, an SSL listener on the Amazon EC2 instances, Amazon EBS encryption on EBS volumes containing PHI, and Amazon S3 with server-side encryption.\n"
        ],
        "Question": "You are designing an application that contains protected health information. Security and compliance requirements for your application mandate that all protected health information in the application use encryption at rest and in transit. The application uses a three-tier architecture where data flows through the load balancer and is stored on Amazon EBS volumes for processing, and the results are stored in Amazon S3 using the AWS SDK. Which of the following two options satisfy the security requirements? Choose 2 answers\n",
        "id": 39
    },
    {
        "Correct": [
            "Use the operating system built-in, host-based firewall to implement the required rules.\n"
        ],
        "Answers": [
            "Configure AWS WAF rules to implement the required rules.\n",
            "Use the operating system built-in, host-based firewall to implement the required rules.\n",
            "Use a NAT gateway to control ingress and egress according to the requirements.\n",
            "Launch an EC2-based firewall product from the AWS Marketplace, and implement the required rules in that product.\n"
        ],
        "Question": "A company has complex connectivity rules governing ingress, egress, and communications between Amazon EC2 instances. The rules are so complex that they cannot be implemented within the limits of the maximum number of security groups and network access control lists (network ACLs). What mechanism will allow the company to implement all required network rules without incurring additional cost?\n",
        "id": 40
    },
    {
        "Correct": [
            "Write a script that uses the GenerateCredentialReport, GetCredentialReport, and UpdateAccessKey APIs.\n"
        ],
        "Answers": [
            "In the AWS Console, choose the IAM service and select \"Users\". Review the \"Access Key Age\" column.\n",
            "Define an IAM policy that denies access if the key age is more than three months and apply to all users.\n",
            "Write a script that uses the GenerateCredentialReport, GetCredentialReport, and UpdateAccessKey APIs.\n",
            "Create an Amazon CloudWatch alarm to detect aged access keys and use an AWS Lambda function to disable the keys older than 90 days.\n"
        ],
        "Question": "A Security Engineer has been asked to create an automated process to disable IAM user access keys that are more than three months old.Which of the following options should the Security Engineer use?\n",
        "id": 41
    },
    {
        "Correct": [
            "Create IAM users in the Master account Create cross-account roles in the Dev and Test accounts that have full Admin permissions and grant the Master account access\n"
        ],
        "Answers": [
            "Create IAM users in the Master account with full Admin permissions. Create cross-account roles in the Dev and Test accounts that grant the Master account access to the resources in the account by inheriting permissions from the Master account.\n",
            "Create IAM users and a cross-account role in the Master account that grants full Admin permissions to the Dev and Test accounts.\n",
            "Create IAM users in the Master account Create cross-account roles in the Dev and Test accounts that have full Admin permissions and grant the Master account access\n",
            "Link the accounts using Consolidated Billing. This will give IAM users in the Master account access to resources in the Dev and Test accounts\n"
        ],
        "Question": "You are looking to migrate your Development (Dev) and Test environments to AWS. You have decided to use separate AWS accounts to host each environment. You plan to link each accounts bill to a Master AWS account using Consolidated Billing. To make sure you keep within budget you would like to implement a way for administrators in the Master account to have access to stop, delete and/or terminate resources in both the Dev and Test accounts. Identify which option will allow you to achieve this goal?\n",
        "id": 42
    },
    {
        "Correct": [
            "Update Amazon S3 lifecycle policies to archive old logs to Amazon Glacier, and use or write a service or use CloudWatch Logs agent to also stream your application logs to CloudWatch Logs.\n"
        ],
        "Answers": [
            "Update Amazon S3 lifecycle policies to archive old logs to Amazon Glacier, and add a new policy to push all log entries to Amazon SQS for ingestion by the support team.\n",
            "Update Amazon S3 lifecycle policies to archive old logs to Amazon Glacier, and use or write a service or use CloudWatch Logs agent to also stream your application logs to CloudWatch Logs.\n",
            "Update Amazon Glacier lifecycle policies to pull new logs from Amazon S3, and in the Amazon EC2 console, enable the CloudWatch Logs Agent on all of your application servers.\n",
            "Update Amazon S3 lifecycle policies to archive old logs to Amazon Glacier. Key can be different from the table. Enable Amazon S3 partial uploads on your Amazon S3 bucket, and trigger an Amazon SNS notification when a partial upload occurs.\n"
        ],
        "Question": "Due to compliance regulations, management has asked you to provide a system that allows for cost-effective long-term storage of your application logs and provides a way for support staff to view the logs more quickly. Currently your log system archives logs automatically to Amazon S3 every hour, and support staff must wait for these logs to appear in Amazon S3, because they do not currently have access to the systems to view live logs. What method should you use to become compliant while also providing a faster way for support staff to have access to logs?\n",
        "id": 43
    },
    {
        "Correct": [
            "Use AWS Config to monitor and alert, if any S3 bucket with public access is created\n"
        ],
        "Answers": [
            "Use a bucket policy and place a DENY statement for the PutObject Action\n",
            "Use AWS Config to monitor and alert, if any S3 bucket with public access is created\n",
            "Enable versioning for the bucket\n",
            "Use an IAM policy and place a DENY statement for the PutObject Action\n"
        ],
        "Question": "A company uses S3 to host its sensitive data. The CIO is worried about unwarranted access to the data in the bucket. Which of the following can be used as a security measure but also ensuring that you don`t put too much access restrictions on the bucket for existing users?\n",
        "id": 44
    },
    {
        "Correct": [
            "Use web identity federation and register your application with a third-party identity provider such as Google, Amazon, or Facebook to obtain a unique id.\n",
            "Create an IAM role, (TriviaRole), with an IAM policy document attached to it, specifying the conditions under which the app can access TriviaScores DynamoDB table.\n"
        ],
        "Answers": [
            "Use a third-party identity provider such as Google, Facebook or Amazon so users can become an AWS IAM User with access to the application.\n",
            "Use web identity federation and register your application with a third-party identity provider such as Google, Amazon, or Facebook to obtain a unique id.\n",
            "Create an IAM User so users can log in to a third-party identity provider such as a Google, Facebook or Amazon to use the application.\n",
            "Create an IAM role, (TriviaRole), with an IAM policy document attached to it, specifying the conditions under which the app can access TriviaScores DynamoDB table.\n"
        ],
        "Question": "You have created a Trivia Scores DynamoDB table for an application that needs to support thousands of users. You need to ensure that each user can only access their own data in the TriviaScores table. Many users already have accounts with a third-party identity provider, such as Facebook, Google, or Login with Amazon. What should you do? Choose the 2 correct answers:\n",
        "id": 45
    },
    {
        "Correct": [
            "Create IAM roles that can be mapped to group memberships in the corporate directory.\n",
            "Create an IAM role that establishes a trust relationship between IAM and the corporate directory identity provider (IdP).\n"
        ],
        "Answers": [
            "Create a Direct Connect connection between the corporate network and the AWS region with the company's infrastructure.\n",
            "Create IAM roles that can be mapped to group memberships in the corporate directory.\n",
            "Create a Lambda function to assign IAM roles to the temporary security tokens provided to the users\n",
            "Create IAM users that can be mapped to the employees' corporate identities.\n",
            "Create an IAM role that establishes a trust relationship between IAM and the corporate directory identity provider (IdP).\n"
        ],
        "Question": "A company wishes to enable Single Sign On (SSO) so its employees can login to the management console using their corporate directory identity. Which steps below are required as part of the process? (Select TWO.)\n",
        "id": 46
    },
    {
        "Correct": [
            "Use an 'on instance' proxy and configure this to perform DNS resolution and only allow traffic which doesn't breach security restrictions.\n"
        ],
        "Answers": [
            "Configure the NACL of the instance subnet to block any outbound traffic to the FQDN of the API endpoint or its return traffic\n",
            "Configure the SG of the instance to block any outbound traffic to the FQDN of the API endpoint or its return traffic\n",
            "Configure Layer-7 filtering on the NAT Gateway in the VPC and add a DNS blacklist entry\n",
            "Use an 'on instance' proxy and configure this to perform DNS resolution and only allow traffic which doesn't breach security restrictions.\n"
        ],
        "Question": "Your security team have approached you and asked that you restrict the ability of an EC2 instance to access a certain remote DNS API endpoint. The remote endpoint may change IP's over time and its imperative it can NEVER access this endpoint. What solution will work as expected?\n",
        "id": 47
    },
    {
        "Correct": [
            "Move the web servers to private subnets without public IP addresses.\n",
            "Configure AWS WAF to provide DDoS attack protection for the ALB.\n"
        ],
        "Answers": [
            "Configure the application`s EC2 instances to use NAT gateways for all inbound traffic.\n",
            "Move the web servers to private subnets without public IP addresses.\n",
            "Configure AWS WAF to provide DDoS attack protection for the ALB.\n",
            "Require all inbound network traffic to route through a bastion host in the private subnet.\n",
            "Require all inbound and outbound network traffic to route through an AWS Direct Connect connection.\n"
        ],
        "Question": "An application is currently secured using network access control lists and security groups. Web servers are located in public subnets behind an Application Load Balancer (ALB); application servers are located in private subnets. How can edge security be enhanced to safeguard the Amazon EC2 instances against attack? (Choose two.)\n",
        "id": 48
    },
    {
        "Correct": [
            "presentation-sg: Allow ports 80 and 443 from 0.0.0.0/0\n",
            "data-sg: Allow port 1433 from logic-sg\n",
            "logic-sg: Allow port 443 from presentation-sg\n"
        ],
        "Answers": [
            "presentation-sg: Allow ports 80 and 443 from 0.0.0.0/0\n",
            "data-sg: Allow port 1433 from presentation-sg\n",
            "data-sg: Allow port 1433 from logic-sg\n",
            "presentation-sg: Allow port 1433 from data-sg\n",
            "logic-sg: Allow port 443 from presentation-sg\n",
            "logic-sg: Allow port 443 from 0.0.0.0/0\n"
        ],
        "Question": "A Security Engineer must set up security group rules for a three-tier application: Presentation tier - Accessed by users over the web, protected by the security group presentation-sg Logic tier - RESTful API accessed from the presentation tier through HTTPS, protected by the security group logic-sg Data tier - SQL Server database accessed over port 1433 from the logic tier, protected by the security group data-sg Which combination of the following security group rules will allow the application to be secure and functional? (Select THREE.)\n",
        "id": 49
    },
    {
        "Correct": [
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:CreateLogGroup\", \"logs:CreateLogStream\", \"logs:PutLogEvents\"], \"Effect\": \"Allow\" }\n"
        ],
        "Answers": [
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:*\"], \"Effect\": \"Allow\" }\n",
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:CreateLogStream\"], \"Effect\": \"Allow\" }\n",
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:CreateLogGroup\", \"logs:CreateLogStream\", \"logs:PutLogEvents\"], \"Effect\": \"Allow\" }\n",
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:CreateLogGroup\", \"logs:CreateLogStream\", \"logs:DeleteLogGroup\", \"logs:DeleteLogStream\", \"logs:getLogEvents\", \"logs:PutLogEvents\"], \"Effect\": \"Allow\" }\n"
        ],
        "Question": "When testing a new AWS Lambda function that retrieves items from an Amazon DynamoDB table, the Security Engineer notices that the function was not logging any data to Amazon CloudWatch Logs.The following policy was assigned to the role assumed by the Lambda function:{ \"Version\": \"2012-10-17\", \"Statement\": [{ \"Sid\": \"Dynamo-1234567\", \"Action\": [ \"dynamodb:GetItem\" ], \"Effect\": \"Allow\", \"Resource\": \"*\" }] } Which least-privilege policy addition would allow this function to log properly?\n",
        "id": 50
    },
    {
        "Correct": [
            "Set up an AWS Organizations hierarchy, and replace the FullAWSAccess policy with the following Service Control Policy for the governed organization units:\n"
        ],
        "Answers": [
            "Set up an AWS Organizations hierarchy, and replace the FullAWSAccess policy with the following Service Control Policy for the governed organization units:\n",
            "Create multiple IAM users for the regulated accounts, and attach the following policy statement to restrict services as required:\n",
            "Set up an Organizations hierarchy, replace the global FullAWSAccess with the following Service Control Policy at the top level:\n",
            "Set up all users in the Active Directory for federated access to all accounts in the company. Associate Active Directory groups with IAM groups, and attach the following policy statement to restrict services as required:\n"
        ],
        "Question": "A Security Engineer must enforce the use of only Amazon EC2, Amazon S3, Amazon RDS, Amazon DynamoDB, and AWS STS in specific accounts.What is a scalable and efficient approach to meet this requirement?\n",
        "id": 51
    },
    {
        "Correct": [
            "Check the route tables for the application server subnets for routes to the VPC peering connection.\n",
            "Check the database security groups for rules that allow traffic from the application servers.\n"
        ],
        "Answers": [
            "Check to see if the application servers are in a private subnet or public subnet.\n",
            "Check the route tables for the application server subnets for routes to the VPC peering connection.\n",
            "Check the NACLs for the database subnets for rules that allow traffic from the Internet.\n",
            "Check the database security groups for rules that allow traffic from the application servers.\n",
            "Check to see if the database VPC has an Internet gateway\n"
        ],
        "Question": "A company decides to place database hosts in its own VPC, and to set up VPC peering to different VPCs containing the application and web tiers. The application servers are unable to connect to the database. Which network troubleshooting steps should be taken to resolve the issue? (Select TWO.)\n",
        "id": 52
    },
    {
        "Correct": [
            "AWS CloudTrail\n"
        ],
        "Answers": [
            "AWS CodeCommit\n",
            "AWS CodePipeline\n",
            "AWS CloudTrail\n",
            "AWS CloudWatch\n"
        ],
        "Question": "Your company has an application hosted in AWS, which makes use of DynamoDThere is a requirement from the IT security department to ensure that all source IP addresses, which make calls to the DynamoDB tables, are recorded. Which of the following services can be used to ensure this requirement is fulfilled?\n",
        "id": 53
    },
    {
        "Correct": [
            "Customer managed CMK with AWS generated key material\n"
        ],
        "Answers": [
            "AWS managed Customer Master Key (CMK)\n",
            "Customer managed CMK with AWS generated key material\n",
            "Customer managed CMK with imported key material\n",
            "AWS managed data key\n"
        ],
        "Question": "An organization policy states that all encryption keys must be automatically rotated every 12 months.Which AWS Key Management Service (KMS) key type should be used to meet this requirement?\n",
        "id": 54
    },
    {
        "Correct": [
            "A network ACL with rules that allow outgoing traffic on port 443 and incoming traffic on ephemeral ports.\n",
            "A security group with a rule that allows outgoing traffic on port 443.\n"
        ],
        "Answers": [
            "A network ACL with a rule that allows outgoing traffic on port 443.\n",
            "A network ACL with rules that allow outgoing traffic on port 443 and incoming traffic on ephemeral ports.\n",
            "A network ACL with rules that allow outgoing traffic on port 443 and incoming traffic on port 443.\n",
            "A security group with a rule that allows outgoing traffic on port 443.\n",
            "A security group with rules that allow outgoing traffic on port 443 and incoming traffic on ephemeral ports.\n",
            "A security group with rules that allow outgoing traffic on port 443 and incoming traffic on port 443.\n"
        ],
        "Question": "An application running on EC2 instances in a VPC must call an external web service via TLS (port 443). The instances run in public subnets. Which configurations below allow the application to function and minimize the exposure of the instances? (Select TWO.)\n",
        "id": 55
    },
    {
        "Correct": [
            "Configure the target region`s AWS service to communicate with the source region`s AWS KMS so that it can decrypt the resource in the target region.\n"
        ],
        "Answers": [
            "Copy the application`s AWS KMS CMK from the source region to the target region so that it can be used to decrypt the resource after it is copied to the target region.\n",
            "Configure AWS KMS to automatically synchronize the CMK between regions so that it can be used to decrypt the resource in the target region.\n",
            "Use AWS services that replicate data across regions, and re-wrap the data encryption key created in the source region by using the CMK in the target region so that the target region`s CMK can decrypt the database encryption key.\n",
            "Configure the target region`s AWS service to communicate with the source region`s AWS KMS so that it can decrypt the resource in the target region.\n"
        ],
        "Question": "An application has a requirement to be resilient across not only Availability Zones within the application`s primary region but also be available within another region altogether. Which of the following supports this requirement for AWS resources that are encrypted by AWS KMS?\n",
        "id": 56
    },
    {
        "Correct": [
            "Bypass the proxy and use an S3 VPC endpoint with a policy that whitelists only certain S3 buckets within Account 1.\n",
            "Block outbound access to public S3 endpoints on the proxy server.\n"
        ],
        "Answers": [
            "Bypass the proxy and use an S3 VPC endpoint with a policy that whitelists only certain S3 buckets within Account 1.\n",
            "Block outbound access to public S3 endpoints on the proxy server.\n",
            "Configure Network ACLs on Server X to deny access to S3 endpoints.\n",
            "Modify the S3 bucket policy for the legitimate bucket to allow access only from the public IP addresses associated with the application server.\n",
            "Remove the IAM instance role from the application server and save API access keys in a trusted and encrypted application config file.\n"
        ],
        "Question": "A threat assessment has identified a risk whereby an internal employee could exfiltrate sensitive data from production host running inside AWS (Account 1). The threat was documented as follows: Threat description: A malicious actor could upload sensitive data from Server X by configuring credentials for an AWS account (Account 2) they control and uploading data to an Amazon S3 bucket within their control.Server X has outbound internet access configured via a proxy server. Legitimate access to S3 is required so that the application can upload encrypted files to an S3 bucket. Server X is currently using an IAM instance role. The proxy server is not able to inspect any of the server communication due to TLS encryption.Which of the following options will mitigate the threat? (Choose two.)\n",
        "id": 57
    },
    {
        "Correct": [
            "AWS IAM roles\n"
        ],
        "Answers": [
            "AWS IAM groups\n",
            "AWS IAM users\n",
            "AWS IAM roles\n",
            "AWS IAM access keys\n"
        ],
        "Question": "A company wants to control access to its AWS resources by using identities and groups that are defined in its existing Microsoft Active Directory. What must the company create in its AWS account to map permissions for AWS services to Active Directory user attributes?\n",
        "id": 58
    },
    {
        "Correct": [
            "Send the local text log files to CloudWatch Logs and configure a CloudWatch metric filter. Trigger CloudWatch alarms based on the metrics.\n"
        ],
        "Answers": [
            "Create a Lambda function that mounts the EBS volume with the logs and scans the logs for security incidents. Trigger the function every 5 minutes with a scheduled CloudWatch event.\n",
            "Send the local text log files to CloudWatch Logs and configure a CloudWatch metric filter. Trigger CloudWatch alarms based on the metrics.\n",
            "Install the Amazon Inspector agent on any EC2 instance running the legacy application. Generate CloudWatch alerts based on any Amazon Inspector findings.\n",
            "Export the local text log files to CloudTrail. Create a Lambda function that queries the CloudTrail logs for security incidents using Athena.\n"
        ],
        "Question": "A company has a legacy application that outputs all logs to a local text file. Logs from all applications running on AWS must be continually monitored for security related messages. What can be done to allow the company to deploy the legacy application on Amazon EC2 and still meet the monitoring requirement?\n",
        "id": 59
    },
    {
        "Correct": [
            "Modify the Network ACLs associated with all public subnets in the VPC to deny access from the IP address block\n"
        ],
        "Answers": [
            "Create an AD policy to modify Windows Firewall settings on all hosts in the VPC to deny access from the IP address block\n",
            "Modify the Network ACLs associated with all public subnets in the VPC to deny access from the IP address block\n",
            "Add a rule to all of the VPC 5 Security Groups to deny access from the IP address block\n",
            "Modify the Windows Firewall settings on all Amazon Machine Images (AMIs) that your organization uses in that VPC to deny access from the IP address block\n"
        ],
        "Question": "You are currently hosting multiple applications in a VPC and have logged numerous port scans coming in from a specific IP address block. Your security team has requested that all access from the offending IP address block be denied for the next 24 hours. Which of the following is the best method to quickly and temporarily deny access from the specified IP address block?\n",
        "id": 60
    },
    {
        "Correct": [
            "Specify \"aws:SecureTransport\": \"true\" within a condition in the S3 bucket policy.\n",
            "Set up default encryption for the S3 bucket.\n",
            "Enable API logging of data events for all S3 objects.\n"
        ],
        "Answers": [
            "Specify \"aws:SecureTransport\": \"true\" within a condition in the S3 bucket policy.\n",
            "Enable a security group for the S3 bucket that allows port 443, but not port 80.\n",
            "Set up default encryption for the S3 bucket.\n",
            "Enable Amazon CloudWatch Logs for the AWS account.\n",
            "Enable API logging of data events for all S3 objects.\n",
            "Enable S3 object versioning for the S3 bucket.\n"
        ],
        "Question": "A Security Administrator is configuring an Amazon S3 bucket and must meet the following security requirements: Encryption in transit Encryption at rest Logging of all object retrievals in AWS CloudTrail Which of the following meet these security requirements? (Choose three.)\n",
        "id": 61
    },
    {
        "Correct": [
            "Ensure that file permissions for monitored files that allow the CloudWatch Logs agent to read the file have not been modified.\n",
            "Verify that the OS Log rotation rules are compatible with the configuration requirements for agent streaming.\n"
        ],
        "Answers": [
            "Ensure that file permissions for monitored files that allow the CloudWatch Logs agent to read the file have not been modified.\n",
            "Verify that the OS Log rotation rules are compatible with the configuration requirements for agent streaming.\n",
            "Configure an Amazon Kinesis producer to first put the logs into Amazon Kinesis Streams.\n",
            "Create a CloudWatch Logs metric to isolate a value that changes at least once during the period before logging stops.\n",
            "Use AWS CloudFormation to dynamically create and maintain the configuration file for the CloudWatch Logs agent.\n"
        ],
        "Question": "Amazon CloudWatch Logs agent is successfully delivering logs to the CloudWatch Logs service. However, logs stop being delivered after the associated log stream has been active for a specific number of hours.What steps are necessary to identify the cause of this phenomenon? (Choose two.)\n",
        "id": 62
    },
    {
        "Correct": [
            "email-smtp.us-east-1.amazonaws.com over port 587\n"
        ],
        "Answers": [
            "email.us-east-1.amazonaws.com over port 8080\n",
            "email-pop3.us-east-1.amazonaws.com over port 995\n",
            "email-smtp.us-east-1.amazonaws.com over port 587\n",
            "email-imap.us-east-1.amazonaws.com over port 993\n"
        ],
        "Question": "A Systems Engineer has been tasked with configuring outbound mail through Simple Email Service (SES) and requires compliance with current TLS standards. The mail application should be configured to connect to which of the following endpoints and corresponding ports?\n",
        "id": 63
    },
    {
        "Correct": [
            "Turn on VPC Flow Logs, send the logs to Amazon S3, and use Amazon Athena to query the logs.\n",
            "Use Systems Manager Patch Manager to generate the report of out of compliance instances/servers. Use Systems Manager Patch Manager to install the missing patches.\n"
        ],
        "Answers": [
            "Turn on VPC Flow Logs, send the logs to Amazon S3, and use Amazon Athena to query the logs.\n",
            "Install an Amazon Inspector agent on each EC2 instance, send the logs to Amazon S3, and use Amazon EMR to query the logs.\n",
            "Create an AWS Config rule for each network ACL and security group configuration, send the logs to Amazon S3, and use Amazon Athena to query the logs.\n",
            "Turn on AWS CloudTrail, send the trails to Amazon S3, and use AWS Lambda to query the trails.\n",
            "Use Amazon QuickSight and CloudTrail to generate the report of out of compliance instances/servers. Redeploy all out of compliance instances/servers using an AMI with the latest patches.\n",
            "Use Systems Manager Patch Manager to generate the report of out of compliance instances/servers. Use Systems Manager Patch Manager to install the missing patches.\n",
            "Use Systems Manager Patch Manager to generate the report of out of compliance instances/servers. Redeploy all out of compliance instances/servers using an AMI with the latest patches.\n",
            "Use Trusted Advisor to generate the report of out of compliance instances/servers. Use Systems Manager Patch Manager to install the missing patches.\n"
        ],
        "Question": "An organization has tens of applications deployed on thousands of Amazon EC2 instances. During testing, the Application team needs information to let them know whether the network access control lists (network ACLs) and security groups are working as expected. How can the Application team`s requirements be met?\n",
        "id": 64
    },
    {
        "Correct": [
            "Use your on-premises SAML 2.0 compliant identity provider (IDP) to grant the NOC members federated access to the AWS Management Console via the AWS single sign-on (SSO) endpoint\n"
        ],
        "Answers": [
            "Use OAuth 2.0 to retrieve temporary AWS security credentials to enable your NOC members to sign in to the AVVS Management Console.\n",
            "Use web Identity Federation to retrieve AWS temporary security credentials to enable your NOC members to sign in to the AWS Management Console.\n",
            "Use your on-premises SAML 2.0 compliant identity provider (IDP) to grant the NOC members federated access to the AWS Management Console via the AWS single sign-on (SSO) endpoint\n",
            "Use your on-premises SAML 2.0 compliant identity provider (IDP) to retrieve temporary security credentials to enable NOC members to sign in to the AWS Management Console\n"
        ],
        "Question": "Your company has recently extended its datacenter into a VPC on AWS to add burst computing capacity as needed Members of your Network Operations Center need to be able to go to the AWS Management Console and administer Amazon EC2 instances as necessary. You don`t want to create new IAM users for each NOC member and make those users sign in again to the AWS Management Console. Which option below will meet the needs for your NOC members?\n",
        "id": 65
    },
    {
        "Correct": [
            "The cipher suites on the Application Load Balancers are blocking connections.\n"
        ],
        "Answers": [
            "Application Load Balancers do not support older web browsers.\n",
            "The Perfect Forward Secrecy settings are not configured correctly.\n",
            "The intermediate certificate is installed within the Application Load Balancer.\n",
            "The cipher suites on the Application Load Balancers are blocking connections.\n"
        ],
        "Question": "The Information Technology department has stopped using Classic Load Balancers and switched to Application Load Balancers to save costs. After the switch, some users on older devices are no longer able to connect to the website. What is causing this situation?\n",
        "id": 66
    },
    {
        "Correct": [
            "Trigger a Lambda function with a monthly CloudWatch event that creates a new CMK and updates the S3 bucket to use the new CMK.\n"
        ],
        "Answers": [
            "Trigger a Lambda function with a monthly CloudWatch event that creates a new CMK and updates the S3 bucket to use the new CMK.\n",
            "Configure the CMK to rotate the key material every month.\n",
            "Trigger a Lambda function with a monthly CloudWatch event that creates a new CMK, updates the S3 bucket to use the new CMK, and deletes the old CMK.\n",
            "Trigger a Lambda function with a monthly CloudWatch event that rotates the key material in the CMK.\n"
        ],
        "Question": "A company continually generates sensitive records that it stores in an S3 bucket. All objects in the bucket are encrypted using SSE-KMS using one of the company's CMKs. Company compliance policies require that no more than one month of data be encrypted using the same encryption key. What solution below will meet the company's requirements?\n",
        "id": 67
    },
    {
        "Correct": [
            "Verify that the S3 bucket policy allows access for CloudTrail from the production AWS account IDs.\n",
            "Confirm in the CloudTrail Console that each trail is active and healthy.\n",
            "Confirm in the CloudTrail Console that the S3 bucket name is set correctly.\n"
        ],
        "Answers": [
            "Verify that the log file prefix is set to the name of the S3 bucket where the logs should go.\n",
            "Verify that the S3 bucket policy allows access for CloudTrail from the production AWS account IDs.\n",
            "Create a new CloudTrail configuration in the account, and configure it to log to the account`s S3 bucket.\n",
            "Confirm in the CloudTrail Console that each trail is active and healthy.\n",
            "Open the global CloudTrail configuration in the master account, and verify that the storage location is set to the correct S3 bucket.\n",
            "Confirm in the CloudTrail Console that the S3 bucket name is set correctly.\n"
        ],
        "Question": "A company has multiple production AWS accounts. Each account has AWS CloudTrail configured to log to a single Amazon S3 bucket in a central account. Two of the production accounts have trails that are not logging anything to the S3 bucket.Which steps should be taken to troubleshoot the issue? (Choose three.)\n",
        "id": 68
    },
    {
        "Correct": [
            "AWS CloudTrail\n",
            "VPC Flow Logs\n",
            "Security groups\n"
        ],
        "Answers": [
            "AWS CloudTrail\n",
            "Amazon Athena\n",
            "AWS Key Management Service (AWS KMS)\n",
            "VPC Flow Logs\n",
            "AWS Firewall Manager\n",
            "Security groups\n"
        ],
        "Question": "A security alert has been raised for an Amazon EC2 instance in a customer account that is exhibiting strange behavior. The Security Engineer must first isolate the EC2 instance and then use tools for further investigation.What should the Security Engineer use to isolate and research this event? (Choose three.)\n",
        "id": 69
    },
    {
        "Correct": [
            "Deploy AWS Config rules and check all running instances for compliance.\n"
        ],
        "Answers": [
            "Terminate all Amazon EC2 instances and relaunch them with approved AMIs.\n",
            "Patch all running instances by using AWS Systems Manager.\n",
            "Deploy AWS Config rules and check all running instances for compliance.\n",
            "Define a metric filter in Amazon CloudWatch Logs to verify compliance.\n"
        ],
        "Question": "The InfoSec team has mandated that in the future only approved Amazon Machine Images (AMIs) can be used.How can the InfoSec team ensure compliance with this mandate?\n",
        "id": 70
    },
    {
        "Correct": [
            "Delete or rotate the user`s key, review the AWS CloudTrail logs in all regions, and delete any unrecognized or unauthorized resources.\n"
        ],
        "Answers": [
            "Review the user's IAM permissions and delete any unrecognized or unauthorized resources.\n",
            "Delete the user, review Amazon CloudWatch Logs in all regions, and report the abuse.\n",
            "Delete or rotate the user`s key, review the AWS CloudTrail logs in all regions, and delete any unrecognized or unauthorized resources.\n",
            "Instruct the user to remove the key from the GitHub submission, rotate keys, and re-deploy any instances that were launched.\n"
        ],
        "Question": "A Security Engineer has been informed that a user`s access key has been found on GitHub. The Engineer must ensure that this access key cannot continue to be used, and must assess whether the access key was used to perform any unauthorized activities. Which steps must be taken to perform these tasks?\n",
        "id": 71
    },
    {
        "Correct": [
            "A VPN between the VPC and the data center over a Direct Connect connection.\n"
        ],
        "Answers": [
            "Expose the data with a public HTTPS endpoint.\n",
            "A VPN between the VPC and the data center over a Direct Connect connection.\n",
            "A VPN between the VPC and the data center.\n",
            "A Direct Connect connection between the VPC and data center.\n"
        ],
        "Question": "An application running on EC2 instances in a VPC must access sensitive data in the data center. The access must be encrypted in transit and have consistent low latency. Which hybrid architecture will meet these requirements?\n",
        "id": 72
    },
    {
        "Correct": [
            "Submit a Penetration Testing Request form to AWS Support.\n"
        ],
        "Answers": [
            "Deploy the test client within the same VPC as the application.\n",
            "Run the test against EC2 instances with Amazon Inspector installed.\n",
            "Submit a Penetration Testing Request form to AWS Support.\n",
            "Exclude ports 80 (HTTP) and 443 (HTTPS) from the penetration test.\n"
        ],
        "Question": "An AWS customer performs penetration testing on their new web application running on Amazon EC2. Later they are contacted by AWS and informed that the penetration testing violated the AWS Acceptable Use Policy. How can the customer perform penetration testing without violating the policy?\n",
        "id": 73
    },
    {
        "Correct": [
            "Use an ELB Application Load Balancer and Auto Scaling group to scale to absorb application layer traffic.\n",
            "Use CloudFront and AWS WAF to prevent malicious traffic from reaching the application.\n"
        ],
        "Answers": [
            "Associate the EC2 instances with a security group that blocks traffic from blacklisted IP addresses.\n",
            "Use an ELB Application Load Balancer and Auto Scaling group to scale to absorb application layer traffic.\n",
            "Use Amazon Inspector on the EC2 instances to examine incoming traffic and discard malicious traffic.\n",
            "Use CloudFront and AWS WAF to prevent malicious traffic from reaching the application.\n",
            "Enable GuardDuty to block malicious traffic from reaching the application.\n"
        ],
        "Question": "A company is deploying a new web application on AWS. Based on their other web applications, they anticipate being the target of frequent DDoS attacks. Which steps can the company use to protect their application? (Select TWO.)\n",
        "id": 74
    },
    {
        "Correct": [
            "Use AWS WAF to block the IP addresses.\n"
        ],
        "Answers": [
            "Use inbound security group rules to block the IP addresses.\n",
            "Use inbound network ACL rules to block the IP addresses.\n",
            "Use AWS WAF to block the IP addresses.\n",
            "Write iptables rules on the instance to block the IP addresses.\n"
        ],
        "Question": "The Web Application Development team is worried about malicious activity from 200 random IP addresses. Which action will ensure security and scalability from this type of threat?\n",
        "id": 75
    },
    {
        "Correct": [
            "Create an organizational unit (OU) in Organizations with a service control policy that controls usage of the root user. Add all operational accounts to the new OU.\n"
        ],
        "Answers": [
            "Disable the use of the root user account at the organizational root. Enable multifactor authentication of the root user account for each organizational member account.\n",
            "Configure IAM user policies to restrict root account capabilities for each Organizations member account.\n",
            "Create an organizational unit (OU) in Organizations with a service control policy that controls usage of the root user. Add all operational accounts to the new OU.\n",
            "Configure AWS CloudTrail to integrate with Amazon CloudWatch Logs and then create a metric filter for RootAccountUsage.\n"
        ],
        "Question": "A Security Administrator is restricting the capabilities of company root user accounts. The company uses AWS Organizations and has enabled it for all feature sets, including consolidates billing. The top level account is used for billing and administrative purposes, not for operational AWS resource purposes.How can the Administrator restrict usage of member root user accounts across the organization?\n",
        "id": 76
    },
    {
        "Correct": [
            "Add the aws:sourceVpce condition to the AWS KMS key policy referencing the company's VPC endpoint ID.\n",
            "Create a VPC endpoint for AWS KMS with private DNS enabled.\n"
        ],
        "Answers": [
            "Add the aws:sourceVpce condition to the AWS KMS key policy referencing the company's VPC endpoint ID.\n",
            "Remove the VPC internet gateway from the VPC and add a virtual private gateway to the VPC to prevent direct, public internet connectivity.\n",
            "Create a VPC endpoint for AWS KMS with private DNS enabled.\n",
            "Use the KMS Import Key feature to securely transfer the AWS KMS key over a VPN.\n",
            "Add the following condition to the AWS KMS key policy: \"aws:SourceIp\": \"10.0.0.0/16\".\n"
        ],
        "Question": "A corporate cloud security policy states that communication between the company's VPC and KMS must travel entirely within the AWS network and not use public service endpoints. Which combination of the following actions MOST satisfies this requirement? (Select TWO.)\n",
        "id": 77
    },
    {
        "Correct": [
            "Create an IAM service role with permissions to write to the DynamoDB table. Associate that role with the Lambda function.\n"
        ],
        "Answers": [
            "Create a VPC endpoint for DynamoDB within a VPConfigure the Lambda function to access resources in the VPC.\n",
            "Create a resource policy that grants the Lambda function permissions to write to the DynamoDB table. Attach the policy to the DynamoDB table.\n",
            "Create an IAM user with permissions to write to the DynamoDB table. Store an access key for that user in the Lambda environment variables.\n",
            "Create an IAM service role with permissions to write to the DynamoDB table. Associate that role with the Lambda function.\n"
        ],
        "Question": "A Lambda function reads metadata from an S3 object and stores the metadata in a DynamoDB table. The function is triggered whenever an object is stored within the S3 bucket. How should the Lambda function be given access to the DynamoDB table?\n",
        "id": 78
    },
    {
        "Correct": [
            "Add a statement to the IAM policy used by the application to allow cloudwatch:putMetricData.\n"
        ],
        "Answers": [
            "Add a statement to the IAM policy used by the application to allow logs:putLogEvents and logs:createLogStream\n",
            "Modify the IAM role used by the application by adding the CloudWatchFullAccess managed policy.\n",
            "Add a statement to the IAM policy used by the application to allow cloudwatch:putMetricData.\n",
            "Add a trust relationship to the IAM role used by the application for cloudwatch.amazonaws.com.\n"
        ],
        "Question": "An application has been written that publishes custom metrics to Amazon CloudWatch. Recently, IAM change have been made on the account and the metrics are no longer being reported. Which of the following is the LEAST permissive solution that will allow the metrics to be delivered?\n",
        "id": 79
    },
    {
        "Correct": [
            "Add the public IP addresses to the ingress rules of the instance security groups.\n"
        ],
        "Answers": [
            "Associate the instances to the same security groups.\n",
            "Add 0.0.0.0/0 to the egress rules of the instance security groups.\n",
            "Add the instance IDs to the ingress rules of the instance security groups.\n",
            "Add the public IP addresses to the ingress rules of the instance security groups.\n"
        ],
        "Question": "A Security Engineer launches two Amazon EC2 instances in the same Amazon VPC but in separate Availability Zones. Each instance has a public IP address and is able to connect to external hosts on the internet. The two instances are able to communicate with each other by using their private IP addresses, but they are not able to communicate with each other when using their public IP addresses. Which action should the Security Engineer take to allow communication over the public IP addresses?\n",
        "id": 80
    },
    {
        "Correct": [
            "Use KMS automatic key rotation to replace the master key, and use this new master key for future encryption operations without re-encrypting previously encrypted data.\n"
        ],
        "Answers": [
            "Use KMS automatic key rotation to replace the master key, and use this new master key for future encryption operations without re-encrypting previously encrypted data.\n",
            "Generate a new Customer Master Key (CMK), re-encrypt all existing data with the new CMK, and use it for all future encryption operations.\n",
            "Change the CMK alias every 90 days, and update key-calling applications with the new key alias.\n",
            "Change the CMK permissions to ensure that individuals who can provision keys are not the same individuals who can use the keys.\n"
        ],
        "Question": "Which option for the use of the AWS Key Management Service (KMS) supports key management best practices that focus on minimizing the potential scope of data exposed by a possible future key compromise?\n",
        "id": 81
    },
    {
        "Correct": [
            "Use the EC2 RunCommand to modify the authorized_keys file on any EC2 instance that is using the key.\n"
        ],
        "Answers": [
            "Delete the key-pair key from the EC2 console, then create a new key pair.\n",
            "Use the modify-instance-attribute API to change the key on any EC2 instance that is using the key.\n",
            "Use the EC2 RunCommand to modify the authorized_keys file on any EC2 instance that is using the key.\n",
            "Update the key pair in any AMI used to launch the EC2 instances, then restart the EC2 instances.\n"
        ],
        "Question": "A Developer`s laptop was stolen. The laptop was not encrypted, and it contained the SSH key used to access multiple Amazon EC2 instances. A Security Engineer has verified that the key has not been used, and has blocked port 22 to all EC2 instances while developing a response plan.How can the Security Engineer further protect currently running instances?\n",
        "id": 82
    },
    {
        "Correct": [
            "All actions listed here would provide additional layers of protection.\n"
        ],
        "Answers": [
            "Ensure that the proper tagging strategies have been implemented to identify all of your EC2 resources.\n",
            "Add an IP address condition to policies that specify that requests to EC2 instances should come from a specific IP address or CIDR block range.\n",
            "Add policies which have deny and/or allow permissions on tagged resources\n",
            "All actions listed here would provide additional layers of protection.\n"
        ],
        "Question": "Your CIO has become very paranoid recently after a series of security breaches and wants you to start providing additional layers of security to all your company's AWS resources. First up he wants you to provide additional layers of protection to all your EC2 resources. Which of the following would be a way of providing that additional layer of protection to all your EC2 resources? Choose the correct answer:\n",
        "id": 83
    },
    {
        "Correct": [
            "Use 3rd-party CA certificate in the origin and CloudFront default certificate in CloudFront\n",
            "Use 3rd-party CA certificate in both origin and CloudFront\n"
        ],
        "Answers": [
            "Use self signed certificate in the origin and CloudFront default certificate in CloudFront.\n",
            "Use the CloudFront default certificate in both origin and CloudFront\n",
            "Use 3rd-party CA certificate in the origin and CloudFront default certificate in CloudFront\n",
            "Use 3rd-party CA certificate in both origin and CloudFront\n",
            "Use a self signed certificate in both the origin and CloudFront\n"
        ],
        "Question": "To enable end-to-end HTTPS connections from the user's browser to the origin via CloudFront, which of the following options are valid? Choose 2 answers\n",
        "id": 84
    },
    {
        "Correct": [
            "Encrypt all EBS volumes attached to EC2 Instances.\n",
            "Use Server-Side Encryption for S3.\n",
            "Use SSL/HTTPS when using the Elastic Load Balancer.\n"
        ],
        "Answers": [
            "Encrypt all EBS volumes attached to EC2 Instances.\n",
            "Use Server-Side Encryption for S3.\n",
            "Use IOPS Volumes when working with EBS Volumes on EC2 Instances.\n",
            "Use IAM policies with least privilege to control access to EC2 Instances\n",
            "Use SSL/HTTPS when using the Elastic Load Balancer.\n",
            "Disable sticky session on ELB\n"
        ],
        "Question": "An IT company would like to secure their resources in their AWS Account. Which of the following options is able to secure data at rest and in transit in AWS? Choose 3 answers\n",
        "id": 85
    },
    {
        "Correct": [
            "Create an AWS IAM role in the MasterPayer account with the ViewBilling permission, then grant the finance users in the FinanceDept account the permission to assume that role.\n"
        ],
        "Answers": [
            "Create an IAM group for the finance users in the FinanceDept account, then attach the AWS managed ReadOnlyAccess IAM policy to the group.\n",
            "Create an IAM group for the finance users in the MasterPayer account, then attach the AWS managed ReadOnlyAccess IAM policy to the group.\n",
            "Create an AWS IAM role in the FinanceDept account with the ViewBilling permission, then grant the finance users in the MasterPayer account the permission to assume that role.\n",
            "Create an AWS IAM role in the MasterPayer account with the ViewBilling permission, then grant the finance users in the FinanceDept account the permission to assume that role.\n"
        ],
        "Question": "A company uses AWS Organization to manage 50 AWS accounts. The finance staff members logs in as AWS IAM users in the FinanceDept AWS account. The staff members need to read the consolidated billing information in the MasterPayer AWS account. They should not be able to view any other resources in the MasterPayer AWS account. IAM access to billing has been enabled in the MasterPayer account. Which of the following approaches grants the finance staff the permissions they require without granting any unnecessary permissions?\n",
        "id": 86
    },
    {
        "Correct": [
            "ABC has to setup one centralized VPC which will peer in to all the other VPCs of the tenants.\n"
        ],
        "Answers": [
            "ABC has to setup one centralized VPC which will peer in to all the other VPCs of the tenants.\n",
            "ABC should setup VPC peering with all the VPCs peering each other but block the IPs from CIDR of the tenant VPCs to deny them.\n",
            "ABC should setup all the VPCs with the same CIDR but have a centralized VPThis way only the centralized VPC can talk to the other VPCs using VPC peering.\n",
            "ABC should setup all the VPCs meshed together with VPC peering for all VPCs.\n"
        ],
        "Question": "ABC has created a multi-tenant Learning Management System (LMS). The application is hosted for five different tenants (clients) in the VPCs of the respective AWS accounts of the tenant. ABC wants to setup a centralized server which can connect with the LMS of each tenant for upgrade if required. ABC also wants to ensure that one tenant VPC should not be able to connect to the other tenant VPC for security reasons.How can ABC setup this scenario?\n",
        "id": 87
    },
    {
        "Correct": [
            "Disable DNS resolution within the VPC configuration.\n"
        ],
        "Answers": [
            "Deny access to the Amazon DNS IP within all security groups.\n",
            "Add a rule to all network access control lists that deny access to the Amazon DNS IP.\n",
            "Add a route to all route tables that black holes traffic to the Amazon DNS IP.\n",
            "Disable DNS resolution within the VPC configuration.\n"
        ],
        "Question": "A company has deployed a custom DNS server in AWS. The Security Engineer wants to ensure that Amazon EC2 instances cannot use the Amazon-provided DNS. How can the Security Engineer block access to the Amazon-provided DNS in the VPC?\n",
        "id": 88
    },
    {
        "Correct": [
            "The policy allows access for the AWS account 111122223333 to manage key access though IAM policies.\n",
            "The policy allows the root user in account 111122223333 to have full access to the KMS key.\n"
        ],
        "Answers": [
            "The policy allows access for the AWS account 111122223333 to manage key access though IAM policies.\n",
            "The policy allows all IAM users in account 111122223333 to have full access to the KMS key.\n",
            "The policy allows the root user in account 111122223333 to have full access to the KMS key.\n",
            "The policy allows the KMS service-linked role in account 111122223333 to have full access to the KMS key.\n",
            "The policy allows all IAM roles in account 111122223333 to have full access to the KMS key.\n"
        ],
        "Question": "The Security Engineer created a new AWS Key Management Service (AWS KMS) key with the following key policy:\n",
        "id": 89
    },
    {
        "Correct": [
            "Run an Amazon Inspector assessment using the Runtime Behavior Analysis rules package against every EC2 instance\n"
        ],
        "Answers": [
            "Trigger an AWS Config Rules evaluation of the restricted-common-ports rule against every EC2 instance\n",
            "Query the Trusted Advisor API for all best Practice security checks and check for \"action recommended\" status\n",
            "Enable a GuardDuty threat detection analysis targeting the port configuration on every EC2 instance\n",
            "Run an Amazon Inspector assessment using the Runtime Behavior Analysis rules package against every EC2 instance\n"
        ],
        "Question": "Company policy requires that all insecure server protocols, such as FTP, Telnet, Http, etc, be disabled on all the servers. The security team would like to regularly check whether all the servers to ensure compliance with this requirements by using a scheduled Cloud Watch event to trigger a review of the current infrastructureWhat process will check compliance of the company's EC2 instance?\n",
        "id": 90
    },
    {
        "Correct": [
            "Add additional IAM policies to the application IAM roles that deny user privileges based on information security policy.\n"
        ],
        "Answers": [
            "Operate an authentication service that generates AWS STS tokens with IAM policies from application-defined IAM roles.\n",
            "Add additional IAM policies to the application IAM roles that deny user privileges based on information security policy.\n",
            "Configure IAM policies that restrict modification of the application IAM roles only to the information security team.\n",
            "Enable federation with the internal LDAP directory and grant the application teams permissions to modify users.\n"
        ],
        "Question": "A customer is in the process of deploying multiple applications to AWS that are owned and operated by different development teams. Each development team maintains the authorization of its users independently from other teams. The customer`s information security team would like to be able to delegate user authorization to the individual development teams but independently apply restrictions to the users permissions based on factors such as the users device and location. For example, the information security team would like to grant read-only permissions to a user who is defined by the development team as read/write whenever the user is authenticating from outside the corporate network. What steps can the information security team take to implement this capability?\n",
        "id": 91
    },
    {
        "Correct": [
            "Create an Amazon CloudFront distribution and set the Elastic Load Balancer as the origin. Create an AWS Lambda function to identify malformed requests from the Cloud Front logs and update AWS WAF rules on CloudFront to block the source IP addresses of the malicious traffic.\n"
        ],
        "Answers": [
            "Create an Amazon CloudFront distribution and set the Elastic Load Balancer as the origin. Enable AWS Shield Standard to mitigate the attacks.\n",
            "Apply an AWS WAF rule to the load balancer with string match conditions to block requests that are malformed.\n",
            "Create an AWS Lambda function to identify malformed requests from the Elastic Load Balancer access logs and update AWS WAF rules on the load balancer to block the source IP addresses of the malicious traffic.\n",
            "Create an Amazon CloudFront distribution and set the Elastic Load Balancer as the origin. Create an AWS Lambda function to identify malformed requests from the Cloud Front logs and update AWS WAF rules on CloudFront to block the source IP addresses of the malicious traffic.\n"
        ],
        "Question": "A company runs a web application on Amazon EC2 instances behind an ELB Application Load Balancer. There have been spikes in traffic that caused the application to slow down and fail several times. Logs reveal that the additional traffic contained malformed requests from multiple sources. Which solution will MOST quickly block these types of attacks in the future?\n",
        "id": 92
    },
    {
        "Correct": [
            "Enable automatic key rotation for a CMK.\n",
            "Import new key material to a new CMK; Point the key alias to the new CMK.\n"
        ],
        "Answers": [
            "Enable automatic key rotation for a CMK.\n",
            "Import new key material to an existing CMK.\n",
            "Use the CLI or console to explicitly rotate an existing CMK.\n",
            "Import new key material to a new CMK; Point the key alias to the new CMK.\n",
            "Delete an existing CMK and a new default CMK will be created.\n"
        ],
        "Question": "A company has several Customer Master Keys (CMK), some of which have imported key material. Each CMK must be rotated annually. What two methods can the security team use to rotate each key? (Select TWO.)\n",
        "id": 93
    },
    {
        "Correct": [
            "Route all traffic throughout a TCP listener on a Classic Load Balancer, and terminate the TLS connection on the EC2 instances.\n"
        ],
        "Answers": [
            "Offload SSL termination onto an SSL listener on a Classic Load Balancer, and use a TCP connection between the load balancer and the EC2 instances.\n",
            "Route all traffic throughout a TCP listener on a Classic Load Balancer, and terminate the TLS connection on the EC2 instances.\n",
            "Create an HTTPS listener using an Application Load Balancer, and route all of the communication through that load balancer.\n",
            "Offload SSL termination onto an SSL listener using an Application Load Balancer, and re-spawn and SSL connection between the load balancer and the EC2 instances.\n"
        ],
        "Question": "Compliance requirements state that all communications between company on-premises hosts and EC2 instances be encrypted in transit. Hosts use custom proprietary protocols for their communication, and EC2 instances need to be fronted by a load balancer for increased availability. Which of the following solutions will meet these requirements?\n",
        "id": 94
    },
    {
        "Correct": [
            "Access the S3 bucket through a VPC endpoint for S3.\n"
        ],
        "Answers": [
            "Access the S3 bucket through a proxy server.\n",
            "Access the S3 bucket through a NAT gateway.\n",
            "Access the S3 bucket through a VPC endpoint for S3.\n",
            "Access the S3 bucket through the SSL protected S3 endpoint.\n"
        ],
        "Question": "A new application will be deployed on EC2 instances in private subnets. The application will transfer sensitive data to and from an S3 bucket. Compliance requirements state that the data must not traverse the public Internet. Which solution meets the compliance requirement?\n",
        "id": 95
    },
    {
        "Correct": [
            "Enable AWS CloudTrail by creating a new trail and applying the trail to all regions. Specify a single Amazon S3 bucket as the storage location.\n"
        ],
        "Answers": [
            "Enable AWS Trusted Advisor security checks in the AWS Console, and report all security incidents for all regions.\n",
            "Enable AWS CloudTrail by creating individual trails for each region, and specify a single Amazon S3 bucket to receive log files for later analysis.\n",
            "Enable AWS CloudTrail by creating a new trail and applying the trail to all regions. Specify a single Amazon S3 bucket as the storage location.\n",
            "Enable Amazon CloudWatch logging for all AWS services across all regions, and aggregate them to a single Amazon S3 bucket for later analysis.\n"
        ],
        "Question": "A security team is responsible for reviewing AWS API call activity in the cloud environment for security violations. These events must be recorded and retained in a centralized location for both current and future AWS regions.What is the SIMPLEST way to meet these requirements?\n",
        "id": 96
    },
    {
        "Correct": [
            "Create an S3 bucket in a dedicated log account and grant the other accounts write only access. Deliver all log files from every account to this S3 bucket.\n",
            "Enable CloudTrail log file integrity validation.\n"
        ],
        "Answers": [
            "Create an S3 bucket in a dedicated log account and grant the other accounts write only access. Deliver all log files from every account to this S3 bucket.\n",
            "Write a Lambda function that queries the Trusted Advisor CloudTrail checks. Run the function every 10 minutes.\n",
            "Enable CloudTrail log file integrity validation.\n",
            "Use Systems Manager Configuration Compliance to continually monitor the access policies of S3 buckets containing CloudTrail logs.\n",
            "Create a Security Group that blocks all traffic except calls from the CloudTrail service. Associate the security group with all the CloudTrail destination S3 buckets.\n"
        ],
        "Question": "A company is using CloudTrail to log all AWS API activity for all regions in all of its accounts. The CISO has asked that additional steps be taken to protect the integrity of the log files. What combination of steps will protect the log files from intentional or unintentional alteration? (Select TWO.)\n",
        "id": 97
    },
    {
        "Correct": [
            "Amazon Cognito\n"
        ],
        "Answers": [
            "Amazon Cognito\n",
            "AssumeRoleWithWebIdentity API\n",
            "Amazon Cloud Directory\n",
            "Active Directory (AD) Connector\n"
        ],
        "Question": "The Security Engineer for a mobile game has to implement a method to authenticate users so that they can save their progress. Because most of the users are part of the same OpenID-Connect compatible social media website, the Security Engineer would like to use that as the identity provider. Which solution is the SIMPLEST way to allow the authentication of users using their social media identities?\n",
        "id": 98
    },
    {
        "Correct": [
            "Use Amazon S3 server-side encryption with AWS Key Management Service managed keys.\n",
            "Use Amazon S3 server-side encryption with customer-provided keys\n",
            "Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key\n"
        ],
        "Answers": [
            "Use Amazon S3 server-side encryption with AWS Key Management Service managed keys.\n",
            "Use Amazon S3 server-side encryption with customer-provided keys\n",
            "Use Amazon S3 server-side encryption with EC2 key pair.\n",
            "Use Amazon S3 bucket policies to restrict access to the data at rest.\n",
            "Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key\n",
            "Use SSL to encrypt the data while in transit to Amazon S3.\n"
        ],
        "Question": "A company is storing data on Amazon Simple Storage Service (S3). The company`s security policy mandates that data be encrypted at rest. Which of the following methods can achieve this? Choose 3 answers\n",
        "id": 99
    },
    {
        "Correct": [
            "Configure a web proxy server in your VPC and enforce URL-based rules for outbound access Remove default routes.\n"
        ],
        "Answers": [
            "Configure a web proxy server in your VPC and enforce URL-based rules for outbound access Remove default routes.\n",
            "Implement security groups and configure outbound rules to only permit traffic to software depots.\n",
            "Move all your instances into private VPC subnets remove default routes from all routing tables and add specific routes to the software depots and distributions only.\n",
            "Implement network access control lists to all specific destinations, with an Implicit deny as a rule.\n"
        ],
        "Question": "You are designing a data leak prevention solution for your VPC environment. You want your VPC Instances to be able to access software depots and distributions on the Internet for product updates. The depots and distributions are accessible via third party CDNs by their URLs. You want to explicitly deny any other outbound connections from your VPC instances to hosts on the Internet. Which of the following options would you consider?\n",
        "id": 100
    },
    {
        "Correct": [
            "Place each developer`s own public key into a private S3 bucket, use instance profiles and configuration management to create a user account for each developer on all instances, and place the user`s public keys into the appropriate account.\n"
        ],
        "Answers": [
            "Place the credentials provided by Amazon Elastic Compute Cloud (EC2) into a secure Amazon Sample Storage Service (S3) bucket with encryption enabled. Assign AWS Identity and Access Management (IAM) users to each developer so they can download the credentials file.\n",
            "Place an internally created private key into a secure S3 bucket with server-side encryption using customer keys and configuration management, create a service account on all the instances using this private key, and assign IAM users to each developer so they can download the file.\n",
            "Place each developer`s own public key into a private S3 bucket, use instance profiles and configuration management to create a user account for each developer on all instances, and place the user`s public keys into the appropriate account.\n",
            "Place the credentials provided by Amazon EC2 onto an MFA encrypted USB drive, and physically share it with each developer so that the private key never leaves the office.\n"
        ],
        "Question": "Your development team wants account-level access to production instances in order to do live debugging of a highly secure environment. Which of the following should you do?\n",
        "id": 101
    },
    {
        "Correct": [
            "Move all the files to an Amazon S3 bucket. Create a CloudFront distribution in front of the bucket and terminate the web server.\n"
        ],
        "Answers": [
            "Move all the files to an Amazon S3 bucket. Have the web server serve the files from the S3 bucket.\n",
            "Launch a second Amazon EC2 instance in a new subnet. Launch an Application Load Balancer in front of both instances.\n",
            "Launch an Application Load Balancer in front of the EC2 instance. Create an Amazon CloudFront distribution in front of the Application Load Balancer.\n",
            "Move all the files to an Amazon S3 bucket. Create a CloudFront distribution in front of the bucket and terminate the web server.\n"
        ],
        "Question": "A company recently experienced a DDoS attack that prevented its web server from serving content. The website is static and hosts only HTML, CSS, and PDF files that users download. Based on the architecture shown in the image, what is the BEST way to protect the site against future attacks while minimizing the ongoing operational overhead?\n",
        "id": 102
    },
    {
        "Correct": [
            "Configure a bucket policy and set Origin Access Identity (OAI)\n",
            "Add Trusted signers to a CloudFront behaviour\n"
        ],
        "Answers": [
            "Ensure the instance is using an IAM role; configure the S3 bucket policy to only allow access from this role.\n",
            "Configure a bucket policy and set Origin Access Identity (OAI)\n",
            "Add Trusted signers to a CloudFront behaviour\n",
            "Restrict based on application user name and the user-passthrough authentication type on the CloudFront IDP setting\n",
            "Integrate the CloudFront distribution with the application using web identity federation and Cognito\n"
        ],
        "Question": "You manage an application, which distributes media to a global audience. The application historically used local instance storage to store the media content and an EC2 instance to serve it to customers. A previous SA rearchitected the solution to use S3 for static content hosting with a CloudFront distribution for global content delivery. You have been called into a meeting to address an urgent issue. It appears that customers can now access content without paying or being logged into the application. What ways can you suggest to address the issue (Choose 2)\n",
        "id": 103
    },
    {
        "Correct": [
            "The CMK is to be used for encrypting and decrypting only when the principal is ExampleUser and the request comes from WorkMail or SES in the specified region.\n"
        ],
        "Answers": [
            "The Amazon WorkMail and Amazon SES services have delegated KMS encrypt and delegated KMS encrypt and decrypt permissions to the ExampleUser principal in the 111122223333 account.\n",
            "The ExampleUser principal can transparently encrypt and decrypt email exchanges specifically between ExampleUser and AWS.\n",
            "The CMK is to be used for encrypting and decrypting only when the principal is ExampleUser and the request comes from WorkMail or SES in the specified region.\n",
            "The key policy allows WorkMail or SES to encrypt or decrypt on behalf of the user for any CMK in the account.\n"
        ],
        "Question": "What is the function of the following AWS Key Management Service (KMS) key policy attached to a customer master key (CMK)?\n",
        "id": 104
    },
    {
        "Correct": [
            "Use KMS to decrypt source data and encrypt resulting output. Also, use Origin Access Identity on your CloudFront distribution, so content is only able to be served via CloudFront, not S3 URLs.\n"
        ],
        "Answers": [
            "Use AWS CloudHSM appliance with both physical and logical tamper detection and response mechanisms that trigger zeroization of the appliance.\n",
            "Set an API flag, or check a box in the AWS Management Console, to have data encrypted in Amazon S3.\n",
            "Use KMS to decrypt source data and encrypt resulting output. Also, use Origin Access Identity on your CloudFront distribution, so content is only able to be served via CloudFront, not S3 URLs.\n",
            "Encrypt your data using AES-256. After the object is encrypted, the encryption key you used needs to be stored on AWS CloudFront.\n"
        ],
        "Question": "You are setting up a video streaming service with the main components of the set up being S3, CloudFront and Transcoder. Your video content will be stored on AWS S3, and your first job is to upload 10 videos to S3 and make sure they are secure before you even begin to start thinking of streaming the videos. The 10 videos have just finished uploading to S3, so you now need to secure them with encryption at rest. Which of the following would be the best way to do this? Choose the correct answer:\n",
        "id": 105
    },
    {
        "Correct": [
            "Configure a SAML identity provider in Amazon Cognito to map attributes to the Amazon Cognito user pool attributes.\n",
            "Configure the SAML identity provider to add the Amazon Cognito user pool as a relying party.\n",
            "Update API Gateway to use an Amazon Cognito user pool authorizer.\n"
        ],
        "Answers": [
            "Create a custom authorization service using AWS Lambda.\n",
            "Configure a SAML identity provider in Amazon Cognito to map attributes to the Amazon Cognito user pool attributes.\n",
            "Configure the SAML identity provider to add the Amazon Cognito user pool as a relying party.\n",
            "Configure an Amazon Cognito identity pool to integrate with social login providers.\n",
            "Update DynamoDB to store the user email addresses and passwords.\n",
            "Update API Gateway to use an Amazon Cognito user pool authorizer.\n"
        ],
        "Question": "A Security Engineer is working with a Product team building a web application on AWS. The application uses Amazon S3 to host the static content, Amazon API Gateway to provide RESTful services, and Amazon DynamoDB as the backend data store. The users already exist in a directory that is exposed through a SAML identity provider. Which combination of the following actions should the Engineer take to enable users to be authenticated into the web application and call APIs? (Select THREE).\n",
        "id": 106
    },
    {
        "Correct": [
            "Build the application out using AWS Cognito and web identity federation to allow users to log in using Facebook or Google Accounts. Once they are logged in, the secret token passed to that user is used to directly access resources on AWS, like AWS S3.\n"
        ],
        "Answers": [
            "Build the application out using AWS Cognito and web identity federation to allow users to log in using Facebook or Google Accounts. Once they are logged in, the secret token passed to that user is used to directly access resources on AWS, like AWS S3.\n",
            "Use JWT or SAML compliant systems to build authorization policies. Users log in with a username and password, and are given a token they can use indefinitely to make calls against the photo infrastructure.\n",
            "Use AWS API Gateway with a constantly rotating API Key to allow access from the client-side. Construct a custom build of the SDK and include S3 access in it.\n",
            "Create an AWS OAuth Service Domain ad grant public signup and access to the domain. During setup, add at least one major social media site as a trusted Identity Provider for users.\n"
        ],
        "Question": "You are building a mobile app for consumers to post cat pictures online. You will be storing the images in AWS S3. You want to run the system very cheaply and simply. Which one of these options allows you to build a photo sharing application without needing to worry about scaling expensive uploads processes, authentication/authorization and so forth?\n",
        "id": 107
    },
    {
        "Correct": [
            "CloudWatch Events Rules, which trigger based on all AWS API calls, submitting all events to an AWS Kinesis Stream for arbitrary downstream analysis.\n"
        ],
        "Answers": [
            "Subscription to AWS Config via an SNS Topic. Use a Lambda Function to perform in-flight analysis and reactivity to changes as they occur.\n",
            "Global AWS CloudTrail setup delivering to S3 with an SNS subscription to the deliver notifications, pushing into a Lambda, which inserts records into an ELK stack for analysis.\n",
            "Use a CloudWatch Rule ScheduleExpression to periodically analyze IAM credential logs. Push the deltas for events into an ELK stack and perform ad-hoc analysis there.\n",
            "CloudWatch Events Rules, which trigger based on all AWS API calls, submitting all events to an AWS Kinesis Stream for arbitrary downstream analysis.\n"
        ],
        "Question": "You have a high security requirement for your AWS accounts. What is the most rapid and sophisticated setup you can use to react to AWS API calls to your account?\n",
        "id": 108
    },
    {
        "Correct": [
            "Launch the EC2 instances with an EC2 IAM role to access AWS services. Retrieve the database credentials from AWS Secrets Manager.\n"
        ],
        "Answers": [
            "Retrieve an access key from an AWS Systems Manager SecureString parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.\n",
            "Launch the EC2 instances with an EC2 IAM role to access AWS services. Retrieve the database credentials from AWS Secrets Manager.\n",
            "Retrieve an access key from an AWS Systems Manager plaintext parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.\n",
            "Launch the EC2 instances with an EC2 IAM role to access AWS services. Store the database passwords in an encrypted config file with the application artifacts.\n"
        ],
        "Question": "A large enterprise is deploying a web application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The application stores data in an Amazon RDS Oracle DB instance and Amazon DynamoDThere are separate environments for development, testing, and production. What is the MOST secure and flexible way to obtain password credentials during deployment?\n",
        "id": 109
    },
    {
        "Correct": [
            "Create a Service Control Policy that denies access to the services. Assemble all production accounts in an organizational unit. Apply the policy to that organizational unit.\n"
        ],
        "Answers": [
            "Create a Service Control Policy that denies access to the services. Assemble all production accounts in an organizational unit. Apply the policy to that organizational unit.\n",
            "Create a Service Control Policy that denies access to the services. Apply the policy to the root account.\n",
            "Create an IAM policy that denies access to the services. Associate the policy with an IAM group and enlist all users and the root users in this group.\n",
            "Create an IAM policy that denies access to the services. Create a Config Rule that checks that all users have the policy assigned. Trigger a Lambda function that adds the policy when found missing.\n"
        ],
        "Question": "Every application in a company's portfolio has a separate AWS account for development and production. The security team wants to prevent the root user and all IAM users in production accounts from accessing a specific set of unneeded services. How can they control this functionality?\n",
        "id": 110
    },
    {
        "Correct": [
            "Use IAM policies to restrict the ability of users or other automated entities to launch EC2 instances based on a specific set of pre-approved AMIs, such as those tagged in a specific way by Information Security.\n",
            "Use AWS Config rules to spot any launches of EC2 instances based on non-approved AMIs, trigger an AWS Lambda function to automatically terminate the instance, and publish a message to an Amazon SNS topic to inform Information Security that this occurred.\n",
            "Configure an Amazon CloudWatch Events rule that invokes an AWS Lambda function to secure the S3 bucket.\n",
            "Turn on object-level logging for Amazon S3. Configure a CloudWatch event to notify by using an SNS topic when a PutObject API call with public-read permission is detected in the AWS CloudTrail logs.\n"
        ],
        "Answers": [
            "Use IAM policies to restrict the ability of users or other automated entities to launch EC2 instances based on a specific set of pre-approved AMIs, such as those tagged in a specific way by Information Security.\n",
            "Use regular scans within Amazon Inspector with a custom assessment template to determine if the EC2 instance that the Amazon Inspector Agent is running on is based upon a pre-approved AMI. If it is not, shut down the instance and inform information Security by email that this occurred.\n",
            "Only allow launching of EC2 instances using a centralized DevOps team, which is given work packages via notifications from an internal ticketing system. Users make requests for resources using this ticketing tool, which has manual information security approval steps to ensure that EC2 instances are only launched from approved AMIs.\n",
            "Use AWS Config rules to spot any launches of EC2 instances based on non-approved AMIs, trigger an AWS Lambda function to automatically terminate the instance, and publish a message to an Amazon SNS topic to inform Information Security that this occurred.\n",
            "Use a scheduled AWS Lambda function to scan through the list of running instances within the virtual private cloud (VPC) and determine if any of these are based on unapproved AMIs. Publish a message to an SNS topic to inform Information Security that this occurred and then shut down the instance.\n",
            "Turn on object-level logging for Amazon S3. Turn on Amazon S3 event notifications to notify by using an Amazon SNS topic when a PutObject API call is made with a public-read permission.\n",
            "Configure an Amazon CloudWatch Events rule that invokes an AWS Lambda function to secure the S3 bucket.\n",
            "Use the S3 bucket permissions for AWS Trusted Advisor and configure a CloudWatch event to notify by using Amazon SNS.\n",
            "Turn on object-level logging for Amazon S3. Configure a CloudWatch event to notify by using an SNS topic when a PutObject API call with public-read permission is detected in the AWS CloudTrail logs.\n",
            "Schedule a recursive Lambda function to regularly change all object permissions inside the S3 bucket.\n"
        ],
        "Question": "A company prefers to limit running Amazon EC2 instances to those that were launched from AMIs pre-approved by the Information Security department. The Development team has an agile continuous integration and deployment process that cannot be stalled by the solution. Which method enforces the required controls with the LEAST impact on the development process? (Choose two.)\n",
        "id": 111
    },
    {
        "Correct": [
            "In SNS, ensure that the subscription used by these alerts has not been deleted.\n"
        ],
        "Answers": [
            "In CloudTrail, verify that the trail logging bucket has a log prefix configured.\n",
            "In Amazon SNS, determine whether the \"Account spend limit\" has been reached for this alert.\n",
            "In SNS, ensure that the subscription used by these alerts has not been deleted.\n",
            "In CloudWatch, verify that the alarm threshold \"consecutive periods\" value is equal to, or greater than 1.\n"
        ],
        "Question": "An organization is using AWS CloudTrail, Amazon CloudWatch Logs, and Amazon CloudWatch to send alerts when new access keys are created. However, the alerts are no longer appearing in the Security Operations mail box.Which of the following actions would resolve this issue?\n",
        "id": 112
    },
    {
        "Correct": [
            "Change the key policy permissions associated with the KMS CMK for each application when it must access the data in Amazon S3.\n"
        ],
        "Answers": [
            "Change the key policy permissions associated with the KMS CMK for each application when it must access the data in Amazon S3.\n",
            "Have each application assume an IAM role that provides permissions to use the AWS Certificate Manager CMK.\n",
            "Have each application use a grant on the KMS CMK to add or remove specific access controls on the KMS CMK.\n",
            "Have each application use an IAM policy in a user context to have specific access permissions on the KMS CMK.\n"
        ],
        "Question": "An organization has three applications running on AWS, each accessing the same data on Amazon S3. The data on Amazon S3 is server-side encrypted by using an AWS KMS Customer Master Key (CMK). What is the recommended method to ensure that each application has its own programmatic access control permissions on the KMS CMK?\n",
        "id": 113
    },
    {
        "Correct": [
            "Verify that a metric filter was created and then mapped to an alarm. Check the alarm notification action.\n"
        ],
        "Answers": [
            "Ensure that CloudTrail and S3 bucket access logging is enabled for the Analyst's AWS account.\n",
            "Verify that a metric filter was created and then mapped to an alarm. Check the alarm notification action.\n",
            "Check the CloudWatch dashboards to ensure that there is a metric configured with an appropriate dimension for security group changes.\n",
            "Verify that the Analyst's account is mapped to an IAM policy that includes permissions for cloudwatch:GetMetricStatistics and cloudwatch:ListMetrics.\n"
        ],
        "Question": "A Security Analyst attempted to troubleshoot the monitoring of suspicious security group changes. The Analyst was told that there is an Amazon CloudWatch alarm in place for these AWS CloudTrail log events. The Analyst tested the monitoring setup by making a configuration change to the security group but did not receive any alerts.Which of the following troubleshooting steps should the Analyst perform?\n",
        "id": 114
    },
    {
        "Correct": [
            "Create an AWS Lambda function that is triggered by Amazon S3 data events for object changes and that also checks the IAM user`s membership in an administrator`s IAM role.\n"
        ],
        "Answers": [
            "Create an AWS Lambda function that is triggered by Amazon S3 data events for object changes and that also checks the IAM user`s membership in an administrator`s IAM role.\n",
            "Create a periodic AWS Config rule to query Amazon S3 Logs for changes and to check the IAM user`s membership in an administrator`s IAM role.\n",
            "Create a metrics filter for Amazon CloudWatch logs to check for Amazon S3 bucket level permission changes and to check the IAM user`s membership in an administrator`s IAM role.\n",
            "Create a periodic AWS Config rule to query AWS CloudTrail logs for changes to the Amazon S3 bucket-level permissions and to check the IAM user`s membership in an administrator`s IAM role.\n"
        ],
        "Question": "According to Information Security Policy, changes to the contents of objects inside production Amazon S3 bucket that contain encrypted secrets should only be made by a trusted group of administrators. How should a Security Engineer create real-time, automated checks to meet this requirement?\n",
        "id": 115
    },
    {
        "Correct": [
            "Connect to the EC2 instances that are not sending the appropriate logs and verify that the CloudWatch Logs agent is running.\n",
            "Verify that the EC2 instances have a route to the public AWS API endpoints.\n"
        ],
        "Answers": [
            "Connect to the EC2 instances that are not sending the appropriate logs and verify that the CloudWatch Logs agent is running.\n",
            "Log in to the AWS account and select CloudWatch Logs. Check for any monitored EC2 instances that are in the \"Alerting\" state and restart them using the EC2 console.\n",
            "Verify that the EC2 instances have a route to the public AWS API endpoints.\n",
            "Connect to the EC2 instances that are not sending logs. Use the command prompt to verify that the right permission have been set for the Amazon SNS topic.\n",
            "Verify that the network access control lists and security groups of the EC2 instances have the access to send logs over SNMP.\n"
        ],
        "Question": "During a security event, it is discovered that some Amazon EC2 instances have not been sending Amazon CloudWatch logs.Which steps can the Security Engineer take to troubleshoot this issue? (Select two.)\n",
        "id": 116
    },
    {
        "Correct": [
            "Use a random and unique S3 object key, and create an S3 metadata index in Amazon DynamoDB using client-side encrypted attributes.\n"
        ],
        "Answers": [
            "Remove the sensitive data from the object name, and store the sensitive data using S3 userdefined metadata.\n",
            "Add an S3 bucket policy that denies the action s3:GetObject\n",
            "Use a random and unique S3 object key, and create an S3 metadata index in Amazon DynamoDB using client-side encrypted attributes.\n",
            "Store all sensitive objects in Binary Large Objects (BLOBS) in an encrypted Amazon RDS instance.\n"
        ],
        "Question": "The Security Engineer has discovered that a new application that deals with highly sensitive data is storing Amazon S3 objects with the following key pattern, which itself contains highly sensitive data.Pattern: \"randomID_datestamp_PII.csv\"Example: \"1234567_12302017_000-00-0000 csv\"The bucket where these objects are being stored is using server-side encryption (SSE).Which solution is the most secure and cost-effective option to protect the sensitive data?\n",
        "id": 117
    },
    {
        "Correct": [
            "Create tasks using the awsvpc network mode.\n",
            "Apply security groups to the tasks, and use IAM roles for tasks to access other resources.\n"
        ],
        "Answers": [
            "Create tasks using the bridge network mode.\n",
            "Create tasks using the awsvpc network mode.\n",
            "Apply security groups to Amazon EC2 instances, and use IAM roles for EC2 instances to access other resources.\n",
            "Apply security groups to the tasks, and pass IAM credentials into the container at launch time to access other resources.\n",
            "Apply security groups to the tasks, and use IAM roles for tasks to access other resources.\n"
        ],
        "Question": "A company wants to migrate its website from an on-premises data center onto AWS. At the same time, it wants to migrate the website to a containerized microservice-based architecture to improve the availability and cost efficiency. The company's security policy states that privileges and network permissions must be configured according to best practice, using least privilege.A Solutions Architect must create a containerized architecture that meets the security requirements and has deployed the application to an Amazon ECS cluster.What steps are required after the deployment to meet the requirements? (Choose two.)\n",
        "id": 118
    },
    {
        "Correct": [
            "Add a VPC endpoint. Configure endpoint policies on the VPC endpoint to allow access to the required S3 buckets only. Implement an S3 bucket policy that allows communication from the VPC endpoint only.\n"
        ],
        "Answers": [
            "Add a NAT gateway. Update the security groups on the EC2 instance to allow access to and from the S3 IP range only. Configure an S3 bucket policy that allows communication from the NAT gateway`s Elastic IP address only.\n",
            "Add a VPC endpoint. Configure endpoint policies on the VPC endpoint to allow access to the required Amazon S3 buckets only. Implement an S3 bucket policy that allows communication from the VPC`s source IP range only.\n",
            "Add a NAT gateway. Update the security groups on the EC2 instance to allow access to and from the S3 IP range only. Configure an S3 bucket policy that allows communication from the source public IP address of the on-premises network only.\n",
            "Add a VPC endpoint. Configure endpoint policies on the VPC endpoint to allow access to the required S3 buckets only. Implement an S3 bucket policy that allows communication from the VPC endpoint only.\n"
        ],
        "Question": "A company currently runs a secure application on Amazon EC2 that takes files from on-premises locations through AWS Direct Connect, processes them, and uploads them to a single Amazon S3 bucket. The application uses HTTPS for encryption in transit to Amazon S3, and S3 server-side encryption to encrypt at rest.Which of the following changes should the Solutions Architect recommend to make this solution more secure without impeding application`s performance?\n",
        "id": 119
    },
    {
        "Correct": [
            "Remove the instance from the load balancer, and shut down access to the instance by tightening the security group.\n"
        ],
        "Answers": [
            "Remove the instance from the load balancer and terminate it.\n",
            "Remove the instance from the load balancer, and shut down access to the instance by tightening the security group.\n",
            "Reboot the instance and check for any Amazon CloudWatch alarms.\n",
            "Stop the instance and make a snapshot of the root EBS volume.\n"
        ],
        "Question": "An organization receives an alert that indicates that an EC2 instance behind an ELB Classic Load Balancer has been compromised.What techniques will limit lateral movement and allow evidence gathering?\n",
        "id": 120
    },
    {
        "Correct": [
            "Copy the data directly from the EBS encrypted volume before the volume is detached from the EC2 instance.\n"
        ],
        "Answers": [
            "Copy the data directly from the EBS encrypted volume before the volume is detached from the EC2 instance.\n",
            "Recover the data from the EBS encrypted volume using an earlier version of the KMS backing key.\n",
            "Make a request to AWS Support to recover the S3 encrypted data.\n",
            "Make a request to AWS Support to restore the deleted CMK, and use it to recover the data.\n"
        ],
        "Question": "A company stores data on an Amazon EBS volume attached to an Amazon EC2 instance. The data is asynchronously replicated to an Amazon S3 bucket. Both the EBS volume and the S3 bucket are encrypted with the same AWS KMS Customer Master Key (CMK). A former employee scheduled a deletion of that CMK before leaving the company. The company's Developer Operations department learns about this only after the CMK has been deleted.Which steps must be taken to address this situation?\n",
        "id": 121
    },
    {
        "Correct": [
            "Use an Amazon S3 bucket configured for website hosting. Create an Amazon CloudFront distribution that refers to this S3 bucket with the origin response event set to trigger a Lambda@Edge Node.js function to add in the security headers\n"
        ],
        "Answers": [
            "Use an Amazon S3 bucket configured for website hosting, then set up server access logging on the S3 bucket to track user activity. Then configure the static website hosting and execute a scheduled AWS Lambda function to verify, and if missing, add security headers to the metadata\n",
            "Use an Amazon S3 bucket configured for website hosting, then set up server access logging on the S3 bucket to track user activity. Configure the static website hosting to return the required security headers.\n",
            "Use an Amazon S3 bucket configured for website hosting. Create an Amazon CloudFront distribution that refers to this S3 bucket with the origin response event set to trigger a Lambda@Edge Node.js function to add in the security headers\n",
            "Use an Amazon S3 bucket configured for website hosting. Create an Amazon CloudFront distribution that refers to this S3 bucket. Set \"Cache Based on Selected Request Headers\" to \"Whitelist\" and add the security headers into the whitelist\n"
        ],
        "Question": "A company's web application will be migrated to AWS. The application is designed so that there is no server-side code required. As part of the Migration, the company would like to improve the security of the application by adding HTTP response headers, following the Open Web Application Security Project (OWASP) secure headers recommendations. How can this solution be implemented to meet the security requirements using best practices?\n",
        "id": 122
    },
    {
        "Correct": [
            "Create a service control policy that denies access to the services. Add all of the new accounts to a single organizational unit (OU), and apply the policy to that OU.\n"
        ],
        "Answers": [
            "Create an IAM policy in each account that denies access to the services. Associate the policy with an IAM group and add all IAM users to the group\n",
            "Create a service control policy that denies access to the services. Add all of the new accounts to a single organizational unit (OU), and apply the policy to that OU.\n",
            "Create an IAM policy in each account that denies access to the services. Associate the policy with an IAM role and instruct users to log in using their corporate credentials and assume the lAM role.\n",
            "Create a service control policy that denies access to the services, and apply the policy to the root of the organization.\n"
        ],
        "Question": "A company has implemented AWS Organizations. It has recently set up a number of new accounts and wants to deny access to a specific set of AWS services in these new accounts. How can this be controlled MOST efficiently?\n",
        "id": 123
    },
    {
        "Correct": [
            "Use the DynamoDB Java encryption client to encrypt data prior to uploading it to DynamoDB.\n"
        ],
        "Answers": [
            "Use AWS Certificate Manager to request a certificate. Use that certificate to encrypt data prior to uploading it to DynamoDB.\n",
            "Enable S3 server-side encryption with the customer-provided keys. Upload the data to Amazon S3, and then use S3Copy to move all data to DynamoDB\n",
            "Create a KMS master key. Generate per-record data keys and use them to encrypt data prior to uploading it to DynamoDDispose of the cleartext and encrypted data keys after encryption without storing.\n",
            "Use the DynamoDB Java encryption client to encrypt data prior to uploading it to DynamoDB.\n"
        ],
        "Question": "Due to new compliance requirements, a Security Engineer must enable encryption with customer provided keys on corporate data that is stored in DynamoDThe company wants to retain full control of the encryption keys.Which DynamoDB feature should the Engineer use to achieve compliance?\n",
        "id": 124
    },
    {
        "Correct": [
            "Change \"Resource\": \"*\" to \"Resource\": \"arn:aws:ec2:*:*:instance/*\"\n",
            "Add the following conditional expression:\"Condition\": { \"StringEquals\": { \"ec2:ResourceTag/Environment\": \"NonProduction\" } }\n",
            "Change \"Action\": \"ec2:*\" to \"Action\": \"ec2:StopInstances\"\n"
        ],
        "Answers": [
            "Add the following conditional expression:\"Condition\": { \"StringEquals\": { \"aws:principaltype\": \"lambda.amazonaws.com\" } }\n",
            "Change \"Resource\": \"*\" to \"Resource\": \"arn:aws:ec2:*:*:instance/*\"\n",
            "Add the following conditional expression:\"Condition\": { \"StringNotEquals\": { \"ec2:ResourceTag/Environment\": \"Production<span id=\"selection-marker-1\" class=\"redactor-selection-marker\"></span>\" } }\n",
            "Add the following conditional expression:\"Condition\": { \"StringEquals\": { \"ec2:ResourceTag/Environment\": \"NonProduction\" } }\n",
            "Change \"Action\": \"ec2:*\" to \"Action\": \"ec2:StopInstances\"\n",
            "Add the following conditional expression:\"Condition\": { \"DateGreaterThan\": { \"aws:currentTime\": \"${aws:DateTime:Friday}\" }, \"DateLessThan\": { \"aws:currentTime\": \"${aws:DateTime:Monday}\" } }\n"
        ],
        "Question": "A company is reviewing its IAM policies. One policy written by the DevOps Engineer has been flagged as too permissive. The policy is used by an AWS Lambda function that issues a stop command to Amazon EC2 instances tagged with Environment: NonProduction over the weekend. The current policy is: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"ec2:*\", \"Resource\": \"*\", } ] } What changes should the Engineer make to achieve a policy of least permission? (Select THREE.)\n",
        "id": 125
    },
    {
        "Correct": [
            "VPN Gateway over AWS Direct Connect\n"
        ],
        "Answers": [
            "VPN and a cached storage gateway\n",
            "AWS Snowball Edge\n",
            "VPN Gateway over AWS Direct Connect\n",
            "AWS Direct Connect\n"
        ],
        "Question": "An organization is moving non-business-critical applications to AWS while maintaining a mission critical application in an on-premises data center. An on-premises application must share limited confidential information with the applications in AWS. The internet performance is unpredictable. Which configuration will ensure continued connectivity between sites MOST securely?\n",
        "id": 126
    },
    {
        "Correct": [
            "Amazon S3 client-side encryption with a client-side master key\n"
        ],
        "Answers": [
            "Amazon S3 client-side encryption with an AWS KMS-managed customer master key (CMK)\n",
            "Amazon S3 server-side encryption with an AWS KMS-managed key\n",
            "Amazon S3 client-side encryption with a client-side master key\n",
            "Amazon S3 server-side encryption with a customer-provided key\n"
        ],
        "Question": "A Solutions Architect is designing a system that will store Personally Identifiable Information (PII) in an Amazon S3 bucket. Due to compliance and regulatory requirements, both the master keys and unencrypted data should never be sent to AWS.What Amazon S3 encryption technique should the Architect choose?\n",
        "id": 127
    },
    {
        "Correct": [
            "Use AWS Config to detect whether an Internet Gateway is added and use an AWS Lambda function to provide auto-remediation.\n"
        ],
        "Answers": [
            "Use AWS Config to detect whether an Internet Gateway is added and use an AWS Lambda function to provide auto-remediation.\n",
            "Within the Amazon VPC configuration, mark the VPC as private and disable Elastic IP addresses.\n",
            "Use IPv6 addressing exclusively on the EC2 hosts, as this prevents the hosts from being accessed from the internet.\n",
            "Move the workload to a Dedicated Host, as this provides additional network security controls and monitoring.\n"
        ],
        "Question": "Some highly sensitive analytics workloads are to be moved to Amazon EC2 hosts. Threat modeling has found that a risk exists where a subnet could be maliciously or accidentally exposed to the internet.Which of the following mitigations should be recommended?\n",
        "id": 128
    },
    {
        "Correct": [
            "Create a multi-account strategy with an account per company. Use consolidated billing to ensure that AnyCompany needs to pay a single bill only.\n",
            "Create a federated identity store against the company's Active Directory. Create IAM rules with appropriate permissions and set the trust relationships with AWS and the identity store. Use AWS STS to grant users access based on the groups they belong to in the identity store.\n"
        ],
        "Answers": [
            "Create a multi-account strategy with an account per company. Use consolidated billing to ensure that AnyCompany needs to pay a single bill only.\n",
            "Create a single account strategy with a virtual private cloud (VPC) for each company. Reduce impact across companies by not creating any VPC peering links. As everything is in a single account, there will be a single invoice. Use tagging to create a detailed bill for each company.\n",
            "Create IAM users for each Developer in the account to which they require access. Create policies that allow the users access to all resources on that account. Attach the policies to the lAM user\n",
            "Create a federated identity store against the company's Active Directory. Create IAM rules with appropriate permissions and set the trust relationships with AWS and the identity store. Use AWS STS to grant users access based on the groups they belong to in the identity store.\n",
            "Create a multi account strategy with an account per company. For billing purposes use a tagging solution that uses a tag to identify the company that creates each resource.\n"
        ],
        "Question": "AnyCompany has acquired numerous companies over the past two years. The CIO for AnyCompany would like to keep the resources for each acquired company separate. The CIO also would like to enforce a chargeback model where each company pays for the AWS services it uses. The Solutions Architect is tasked with designing an AWS architecture that allows AnyCompany to achieve the following Implementing a detailed chargeback mechanism to ensure that each company pays for the resources it uses AnyCompany can pay for AWS services for all its companies through a single invoice Developers in each acquired company have access to resources in their company only Developers in an acquired company should not be able to affect resources in any other company A single identity store is used to authenticate Developers across all companies Which of the following approaches would meet these requirements? (Select TWO )\n",
        "id": 129
    },
    {
        "Correct": [
            "Disable the Network Source/Destination check on the security appliance's elastic network interface\n"
        ],
        "Answers": [
            "Disable network ACLs.\n",
            "Configure the security appliance's elastic network interlace for promiscuous mode.\n",
            "Disable the Network Source/Destination check on the security appliance's elastic network interface\n",
            "Place the security appliance in the public subnet with the internet gateway\n"
        ],
        "Question": "A Systems Engineer is troubleshooting the connectivity of a test environment that includes a virtual security appliance deployed inline. In addition to using the virtual security appliance, the Development team wants to use security groups and network ACLs to accomplish various security requirements in the environment.What configuration is necessary to allow the virtual security appliance to route the traffic?\n",
        "id": 130
    },
    {
        "Correct": [
            "Use AWS Organizations in a centralized account to define Service Control Polices (SCPs). Create a SAML based identity management provider in each account and map users in the on-premises groups to the IAM roles.\n"
        ],
        "Answers": [
            "Define AWS IAM roles based on the functional responsibilities of the users in a central account. Create a SAML based identity management provider. Map users in the on-premises groups to IAM roles. Establish trust relationships between the other accounts and the central account.\n",
            "Deploy a common set of AWS IAM users groups, roles and policies in all of the AWS accounts using AWS Organizations. Implement federation between the on-premises identity provider and the AWS accounts.\n",
            "Use AWS Organizations in a centralized account to define Service Control Polices (SCPs). Create a SAML based identity management provider in each account and map users in the on-premises groups to the IAM roles.\n",
            "Perform a thorough analysis of the user base and create AWS IAM users accounts that have the necessary permissions. Set up a process to provision and deprovision accounts based on the data in the on-premises solution.\n"
        ],
        "Question": "The CISO of a large enterprise with multiple IT departments, each with its own AWS account, wants one central place where AWS permissions for users can be managed and users authentication credentials can be synchronized with the company on-premises solution. Which solution will meet the CISO requirements?\n",
        "id": 131
    },
    {
        "Correct": [
            "Create primary and secondary Amazon S3 buckets in two separate AWS Regions that are at least 500 miles apart. Use a bucket policy to enforce access to the buckets only through HTTPS. Use a bucket policy to enforce S3-Managed Keys (SSE-S3) on all objects uploaded to the bucket. Configure cross-region replication between the two buckets.\n"
        ],
        "Answers": [
            "Create primary and secondary Amazon S3 buckets in two separate Availability Zones that are at least 500 miles apart. Use a bucket policy to enforce access to the buckets only through HTTPS. Use a bucket policy to enforce Amazon S3 SSE-C on all objects uploaded to the bucket. Configure cross-region replication between the two buckets.\n",
            "Create primary and secondary Amazon S3 buckets in two separate AWS Regions that are at least 500 miles apart. Use a bucket policy to enforce access to the buckets only through HTTPS. Use a bucket policy to enforce S3-Managed Keys (SSE-S3) on all objects uploaded to the bucket. Configure cross-region replication between the two buckets.\n",
            "Create primary and secondary Amazon S3 buckets in two separate AWS Regions that are at least 500 miles apart. Use an IAM role to enforce access to the buckets only through HTTPS. Use a bucket policy to enforce Amazon S3-Managed Keys (SSE-S3) on all objects uploaded to the bucket. Configure cross-region replication between the two buckets.\n",
            "Create primary and secondary Amazon S3 buckets in two separate Availability Zones that are at least 500 miles apart. Use a bucket policy to enforce access to the buckets only through HTTPS. Use a bucket policy to enforce AWS KMS encryption on all objects uploaded to the bucket. Configure cross- region replication between the two buckets. Create a KMS Customer Master Key (CMK) in the primary region for encrypting objects.\n"
        ],
        "Question": "A company is building a solution for storing files containing Personally Identifiable Information (PII) on AWS. Requirements state: All data must be encrypted at rest and in transit. Al data must be replicated in at least two locations that are at least 500 miles apart. Which solution meets these requirements?\n",
        "id": 132
    },
    {
        "Correct": [
            "Update the AWS Lambda function to block malicious IPs in AWS WAF attached to the Application Load Balancer\n"
        ],
        "Answers": [
            "Update the AWS Lambda function to remove blocked entries from the network ACL after 2 hours\n",
            "Update the AWS Lambda function to block malicious IPs in security groups rather than the network ACL\n",
            "Update the AWS Lambda function to block malicious IPs in AWS WAF attached to the Application Load Balancer\n",
            "Update the AWS lambda function to add an additional network ACL to the subnets once the limit for the previous ones has been reached\n"
        ],
        "Question": "A company's web application is deployed on Amazon EC2 instances behind a public Application Load Balancer. The application flags malicious requests and uses an AWS Lambda function to add the offending IP addresses to the network ACL to block any further requests for 24 hours. Recently, the application has been receiving more malicious request, which causes the network ACL to reach its limit of allowed entries. Which action should be taken to block more IP addresses, without compromising the existing security requirements?\n",
        "id": 133
    },
    {
        "Correct": [
            "Create a rule in AWS WAF rules with conditions that block requests based on the presence of ExampleGame/1.22 in the User-Agent header\n"
        ],
        "Answers": [
            "Create a rule in AWS WAF rules with conditions that block requests based on the presence of ExampleGame/1.22 in the User-Agent header\n",
            "Create a geographic restriction on the CloudFront distribution to prevent access to the application from most geographic regions\n",
            "Create a rate-based rule in AWS WAF to limit the total number of requests that the web application services.\n",
            "Create an IP-based blacklist in AWS WAF to block the IP addresses that are originating from requests that contain ExampleGame/1.22 in the User-Agent header.\n"
        ],
        "Question": "An organization operates a web application that serves users globally. The application runs on Amazon EC2 instances behind an Application Load Balancer. There is an Amazon CloudFront distribution in front of the load balancer, and the organization uses AWS WAThe application is currently experiencing a volumetric, attack whereby the attacker is exploiting a bug in a popular mobile game.The application is being flooded with HTTP requests from all over the world with the User-Agent set to the following string: Mozilla/5.0 (compatible; ExampleCorp; ExampleGame/1.22; Mobile/1.0) What mitigation can be applied to block attacks resulting from this bug while continuing to service legitimate requests?\n",
        "id": 134
    },
    {
        "Correct": [
            "Review the application security groups to ensure that only the necessary ports are open.\n",
            "Use Amazon Inspector to periodically scan the backend instances.\n"
        ],
        "Answers": [
            "Use AWS Certificate Manager to encrypt all traffic between the client and application servers.\n",
            "Review the application security groups to ensure that only the necessary ports are open.\n",
            "Use Elastic Load Balancing to offload Secure Sockets Layer encryption.\n",
            "Use Amazon Inspector to periodically scan the backend instances.\n",
            "Use AWS Key Management Services to encrypt all the traffic between the backend application servers.\n"
        ],
        "Question": "The Security Engineer is managing a traditional three-tier web application that is running on Amazon EC2 instances. The application has become the target of increasing numbers of malicious attacks from the Internet.What steps should the Security Engineer take to check for known vulnerabilities and limit the attack surface? (Choose two.)\n",
        "id": 135
    },
    {
        "Correct": [
            "Use AWS Step Functions to create a function to delete the IAM access key, and then use Amazon SNS to send a notification to the Security team. Create an Amazon CloudWatch Events rule with an aws.health event source and the AWS_RISK_CREDENTIALS_EXPOSED event, set the target of the CloudWatch Events rule to Step Functions.\n"
        ],
        "Answers": [
            "Create an AWS Lambda function to delete the IAM access key. Send AWS CloudTrail logs to AWS CloudWatch logs. Create a CloudWatch Logs metric filter for the AWS_RISK_CREDENTIALS_EXPOSED event with two actions: first, run the Lambda function; second, use Amazon SNS to send a notification to the Security team.\n",
            "Create an AWS Lambda function to delete the IAM access key. Create an AWS Config rule for changes to aws.health and the AWS_RISK_CREDENTIALS_EXPOSED event with two actions: first, run the Lambda function; second, use Amazon SNS to send a notification to the Security team.\n",
            "Use AWS Step Functions to create a function to delete the IAM access key, and then use Amazon SNS to send a notification to the Security team. Create an AWS Personal Health Dashboard rule for the AWS_RISK_CREDENTIALS_EXPOSED event; set the target of the Personal Health Dashboard rule to Step Functions.\n",
            "Use AWS Step Functions to create a function to delete the IAM access key, and then use Amazon SNS to send a notification to the Security team. Create an Amazon CloudWatch Events rule with an aws.health event source and the AWS_RISK_CREDENTIALS_EXPOSED event, set the target of the CloudWatch Events rule to Step Functions.\n"
        ],
        "Question": "The Development team at an online retailer has moved to Business support and want to take advantage of the AWS Health Dashboard and the AWS Health API to automate remediation actions for issues with the health of AWS resources. The first use case is to respond to AWS detecting an IAM access key that is listed on a public code repository site. The automated response will be to delete the IAM access key and send a notification to the Security team. How should this be achieved?\n",
        "id": 136
    },
    {
        "Correct": [
            "Use AWS Trusted Advisor to identify compromised access keys. Create an Amazon CloudWatch Events rule with Trusted Advisor as the event source, and AWS Lambda and Amazon SNS as targets. Use AWS Lambda to delete compromised IAM access keys and Amazon SNS to notify the Security team\n"
        ],
        "Answers": [
            "Use the AWS Trusted Advisor generated security report for access keys. Use Amazon EMR to run analytics on the report. Identify compromised IAM access keys and delete them. Use Amazon CloudWatch with an EMR Cluster State change event to notify the Security team\n",
            "Use AWS Trusted Advisor to identify compromised access keys. Create an Amazon CloudWatch Events rule with Trusted Advisor as the event source, and AWS Lambda and Amazon SNS as targets. Use AWS Lambda to delete compromised IAM access keys and Amazon SNS to notify the Security team\n",
            "Use AWS Trusted Advisor generated security report for access keys. Use AWS Lambda to scan through report. Use scan result inside AWS Lambda and delete compromised IAM access keys. Use Amazon SNS to notify the Security team\n",
            "Use AWS Lambda with a third-party library to scan for compromised access keys. Use scan result inside AWS Lambda and delete compromised IAM access keys. Create Amazon CloudWatch custom metrics for compromised keys. Cretae a CloudWatch alarm on the metrics to notify the Security team\n"
        ],
        "Question": "A company wants to adopt a methodology for handling security threats from leaked and compromised IAM access keys. The DevOps Engineer has been asked to automate the process of acting upon compromised access keys, which includes identifying users, revoking their permissions, and sending a notification to the Security team. Which of the following would achieve this goal?\n",
        "id": 137
    },
    {
        "Correct": [
            "Store the encrypted data key alongside the encrypted data. Use the Decrypt API to retrieve the data key to decrypt the data when required.\n"
        ],
        "Answers": [
            "Request KMS to provide the stored unencrypted data key and then use the retrieved data key to decrypt the data.\n",
            "Keep the plaintext data key stored in Amazon DynamoDB protected with IAM policies. Query DynamoDB to retrieve the data key to decrypt the data\n",
            "Use the Encrypt API to store an encrypted version of the data key with another customer managed key. Decrypt the data key and use it to decrypt the data when required.\n",
            "Store the encrypted data key alongside the encrypted data. Use the Decrypt API to retrieve the data key to decrypt the data when required.\n"
        ],
        "Question": "A Developer who is following AWS best practices for secure code development requires an application to encrypt sensitive data to be stored at rest, locally in the application, using AWS KMS. What is the simplest and most secure way to decrypt this data when required?\n",
        "id": 138
    },
    {
        "Correct": [
            "Verify that the SQS resource policy does not explicitly deny access to the role used by the instances.\n",
            "Verify that the role attached to the instances contains policies that allow access to the queue.\n"
        ],
        "Answers": [
            "Configure and assign an MFA device to the role used by the instances.\n",
            "Verify that the SQS resource policy does not explicitly deny access to the role used by the instances.\n",
            "Verify that the access key attached to the role used by the instances is active.\n",
            "Attach the AmazonSQSFullAccess managed policy to the role used by the instances.\n",
            "Verify that the role attached to the instances contains policies that allow access to the queue.\n"
        ],
        "Question": "An application has been built with Amazon EC2 instances that retrieve messages from Amazon SQS. Recently, IAM changes were made and the instances can no longer retrieve messages. What actions should be taken to troubleshoot the issue while maintaining least privilege? (Select two.)\n",
        "id": 139
    },
    {
        "Correct": [
            "Initiate an Amazon Elastic Block Store volume snapshots of all volumes on the EC2 instance.\n",
            "De-register the EC2 instance from the ALB and detach it from the Auto Scaling group.\n",
            "Attach a security group that has restrictive ingress and egress rules to the EC2 instance.\n"
        ],
        "Answers": [
            "Detach the elastic network interface from the EC2 instance.\n",
            "Initiate an Amazon Elastic Block Store volume snapshots of all volumes on the EC2 instance.\n",
            "Disable any Amazon Route 53 health checks associated with the EC2 instance.\n",
            "De-register the EC2 instance from the ALB and detach it from the Auto Scaling group.\n",
            "Attach a security group that has restrictive ingress and egress rules to the EC2 instance.\n",
            "Add a rule to an AWS WAF to block access to the EC2 instance.\n"
        ],
        "Question": "An Amazon EC2 instance is part of an EC2 Auto Scaling group that is behind an Application Load Balancer (ALB). It is suspected that the EC2 has been compromised. Which steps should be taken to investigate the suspected compromise? (Choose three.)\n",
        "id": 140
    },
    {
        "Correct": [
            "Create an Amazon CloudWatch Events rule that matches each time an EC2 instance is launched, and associate it with the Lambda function as the target.\n"
        ],
        "Answers": [
            "Create an Amazon CloudWatch Events rule that matches each time an EC2 instance is launched using one of the allowed AMIs, and associate it with the Lambda function as the target.\n",
            "For the Amazon S3 bucket receiving the AWS CloudTrail logs, create an S3 event notification configuration with a filter to match when logs contain the ec2:RunInstances action, and associate it with the Lambda function as the target.\n",
            "Enable AWS CloudTrail and configure it to stream to an Amazon CloudWatch Logs group. Create a metric filter in CloudWatch to match when the ec2:RunInstances action occurs, and trigger the Lambda function when the metric is greater than 0.\n",
            "Create an Amazon CloudWatch Events rule that matches each time an EC2 instance is launched, and associate it with the Lambda function as the target.\n"
        ],
        "Question": "A company has a requirement that only allows specially hardened AMIs to be launched into public subnets in a VPC, and for the AMIs to be associated with a specific security group. Allowing non-compliant instances to launch into the public subnet could present a significant security risk if they are allowed to operate.A mapping of approved AMIs to subnets to security groups exists in an Amazon DynamoDB table in the same AWS account. The company created an AWS Lambda function that, when invoked, will terminate a given Amazon EC2 instance if the combination of AMI, subnet, and security group are not approved in the DynamoDB table.What should the Solutions Architect do to MOST quickly mitigate the risk of compliance deviations?\n",
        "id": 141
    },
    {
        "Correct": [
            "Implement ip tables-based restrictions on the instances.\n"
        ],
        "Answers": [
            "Disable the EC2 instance metadata service.\n",
            "Log all student SSH interactive session activity.\n",
            "Implement ip tables-based restrictions on the instances.\n",
            "Install the Amazon Inspector agent on the instances.\n"
        ],
        "Question": "A Security Administrator at a university is configuring a fleet of Amazon EC2 instances. The EC2 instances are shared among students, and non-root SSH access is allowed. The Administrator is concerned about students attacking other AWS account resources by using the EC2 instance metadata service. What can the Administrator do to protect against this potential attack?\n",
        "id": 142
    },
    {
        "Correct": [
            "Enable Amazon GuardDuty in every account. Configure the security account as the GuardDuty Administrator for every member account using invitation/acceptance. Create an Amazon CloudWatch rule in the security account to send all findings to Amazon Kinesis Data Firehouse, which will push the findings to the S3 bucket.\n"
        ],
        "Answers": [
            "Enable Amazon Macie in every account. Configure the security account as the Macie Administrator for every member account using invitation/acceptance. Create an Amazon CloudWatch Events rule in the security account to send all findings to Amazon Kinesis Data Firehouse, which should push the findings to the S3 bucket.\n",
            "Enable Amazon Macie in the security account only. Configure the security account as the Macie Administrator for every member account using invitation/acceptance. Create an Amazon CloudWatch Events rule in the security account to send all findings to Amazon Kinesis Data Streams. Write and application using KCL to read data from the Kinesis Data Streams and write to the S3 bucket.\n",
            "Enable Amazon GuardDuty in every account. Configure the security account as the GuardDuty Administrator for every member account using invitation/acceptance. Create an Amazon CloudWatch rule in the security account to send all findings to Amazon Kinesis Data Firehouse, which will push the findings to the S3 bucket.\n",
            "Enable Amazon GuardDuty in the security account only. Configure the security account as the GuardDuty Administrator for every member account using invitation/acceptance. Create an Amazon CloudWatch rule in the security account to send all findings to Amazon Kinesis Data Streams. Write and application using KCL to read data from Kinesis Data Streams and write to the S3 bucket.\n"
        ],
        "Question": "A government agency has multiple AWS accounts, many of which store sensitive citizen information. A Security team wants to detect anomalous account and network activities (such as SSH brute force attacks) in any account and centralize that information in a dedicated security account. Event information should be stored in an Amazon S3 bucket in the security account, which is monitored by the department`s Security Information and Even Manager (SIEM) system.How can this be accomplished?\n",
        "id": 143
    },
    {
        "Correct": [
            "Create a service role in IAM to be assumed by CodeBuild with a policy attached to allow the actions on AWS services. Configure the build project to use the role created.\n"
        ],
        "Answers": [
            "Generate credentials for an IAM user with a policy attached to allow the actions on AWS services. Store credentials as encrypted environment variables for the build project. As part of the build script, obtain the credentials to run the integration tests.\n",
            "Have CodeBuild run only the integration tests as a build job on a Jenkins server. Create a role that has a policy attached to allow the actions on AWS services. Generate credentials for an IAM user that is allowed to assume the role. Configure the credentials as secrets in Jenkins, and allow the build job to use them to run the integration tests.\n",
            "Create a service role in IAM to be assumed by CodeBuild with a policy attached to allow the actions on AWS services. Configure the build project to use the role created.\n",
            "Use AWS managed credentials. Encrypt the credentials with AWS KMS. As part of the build script, decrypt with AWS KMS and use these credentials to run the integration tests.\n"
        ],
        "Question": "A Development team creates a build project in AWS CodeBuild. The build project invokes automated tests of modules that access AWS services.Which of the following will enable the tests to run the MOST securely?\n",
        "id": 144
    },
    {
        "Correct": [
            "Develop an alerting mechanism based on processing AWS CloudTrail logs.\n"
        ],
        "Answers": [
            "Develop an alerting mechanism based on processing AWS CloudTrail logs.\n",
            "Monitor Amazon S3 Event Notifications for objects stored in buckets in unapproved regions.\n",
            "Analyze Amazon CloudWatch Logs for activities in unapproved regions.\n",
            "Use AWS Trusted Advisor to alert on all resources being created.\n"
        ],
        "Question": "For compliance reasons, an organization limits the use of resources to three specific AWS regions. It wants to be alerted when any resources are launched in unapproved regions. Which of the following approaches will provide alerts on any resources launched in an unapproved region?\n",
        "id": 145
    },
    {
        "Correct": [
            "Install the host-based IDS software to check for file integrity. Export the logs to Amazon CloudWatch Logs for monitoring and alerting.\n"
        ],
        "Answers": [
            "Install antivirus software and ensure that signatures are up-to-date. Configure Amazon CloudWatch alarms to send alerts for security events.\n",
            "Install the host-based IDS software to check for file integrity. Export the logs to Amazon CloudWatch Logs for monitoring and alerting.\n",
            "Export system log files to Amazon S3. Parse the log files using an AWS Lambda function that will send alerts of any unauthorized system login attempts through Amazon SNS.\n",
            "Use Amazon CloudWatch Logs to detect file system changes. If a change is detected, automatically terminate and recreate the instance from the most recent AMI. Use Amazon SNS to send notification of the event.\n"
        ],
        "Question": "A Security Engineer must design a system that can detect whether a file on an Amazon EC2 host has been modified. The system must then alert the Security Engineer of the modification. What is the most efficient way to meet these requirements?\n",
        "id": 146
    },
    {
        "Correct": [
            "Use Amazon EC2 Run Command to issue a package update command to all running production instances, and update the AMI for future deployments.\n"
        ],
        "Answers": [
            "Use AWS CodePipeline and AWS CodeBuild to generate new copies of these packages, and update the Auto Scaling group`s launch configuration.\n",
            "Use AWS Inspector to run \"yum upgrade\" on all running production instances, and manually update the AMI for the next maintenance window.\n",
            "Use Amazon EC2 Run Command to issue a package update command to all running production instances, and update the AMI for future deployments.\n",
            "Define a new AWS OpsWorks layer to match the running production instances, and use a recipe to issue a package update command to all running production instances.\n"
        ],
        "Question": "A new zero-day vulnerability was found in OpenSSL requiring the immediate patching of a production web fleet running on Amazon Linux. Currently, OS updates are performed manually on a monthly basis and deployed using updates to the production Auto Scaling Group`s launch configuration. Which method should a DevOps Engineer use to update packages in-place without downtime?\n",
        "id": 147
    },
    {
        "Correct": [
            "Migrate the DNS to Amazon Route 53 and use AWS Shield\n",
            "Create and use an Amazon CloudFront distribution and configure AWS WAF on it\n"
        ],
        "Answers": [
            "Put the EC2 instances behind a Network Load Balancer and configure AWS WAF on it\n",
            "Migrate the DNS to Amazon Route 53 and use AWS Shield\n",
            "Put the EC2 instances in an Auto Scaling group and configure AWS WAF on it\n",
            "Create and use an Amazon CloudFront distribution and configure AWS WAF on it\n",
            "Create and use an internet gateway in the VPC and use AWS Shield\n"
        ],
        "Question": "What combination of steps could a Solutions Architect take to protect a web workload running on Amazon EC2 from DDoS and application layer attacks? (Select TWO.)\n",
        "id": 148
    },
    {
        "Correct": [
            "Set up a CloudFront origin access identity (OAI), and change the S3 bucket/object permission so that only the OAI has access.\n"
        ],
        "Answers": [
            "Change the S3 bucket/object permission so that only the bucket owner has access.\n",
            "Set up a CloudFront origin access identity (OAI), and change the S3 bucket/object permission so that only the OAI has access.\n",
            "Create IAM roles for CloudFront, and change the S3 bucket/object permission so that only the IAM role has access.\n",
            "Redirect S3 bucket access to the corresponding CloudFront distribution.\n"
        ],
        "Question": "In response to the past DDoS attack experiences, a Security Engineer has set up an Amazon CloudFront distribution for an Amazon S3 bucket. There is concern that some users may bypass the CloudFront distribution and access the S3 bucket directly.What must be done to prevent users from accessing the S3 objects directly by using URLs?\n",
        "id": 149
    },
    {
        "Correct": [
            "Create an Amazon CloudWatch Events rule for the CloudTrail StopLogging event. Create an AWS Lambda function that uses the AWS SDK to call StartLogging on the ARN of the resource in which StopLogging was called. Add the Lambda function ARN as a target to the CloudWatch Events rule.\n"
        ],
        "Answers": [
            "Create an Amazon CloudWatch Events rule for the CloudTrail StopLogging event. Create an AWS Lambda function that uses the AWS SDK to call StartLogging on the ARN of the resource in which StopLogging was called. Add the Lambda function ARN as a target to the CloudWatch Events rule.\n",
            "Deploy the AWS-managed CloudTrail-enabled AWS Config rule, set with a periodic interval of 1 hour. Create an Amazon CloudWatch Events rule for AWS Config rules compliance change. Create an AWS Lambda function that uses the AWS SDK to call StartLogging on the ARN of the resource in which StopLogging was called. Add the Lambda function ARN as a target to the CloudWatch Events rule.\n",
            "Create an Amazon CloudWatch Events rule for a scheduled event every 5 minutes. Create an AWS Lambda function that uses the AWS SDK to call StartLogging on an CloudTrail trail in the AWS account. Add the Lambda function ARN as a target to the CloudWatch Events rule.\n",
            "Launch a t2.nano instance with a script running every 5 minutes that uses the AWS SDK to query CloudTrail in the current account. If the CloudTrail trail is disabled, have the script re-enable the trail.\n"
        ],
        "Question": "The Security team depends on AWS CloudTrail to detect sensitive security issues in the company`s AWS account. The DevOps Engineer needs a solution to auto-remediate CloudTrail being turned off in an AWS account.What solution ensures the LEAST amount of downtime for the CloudTrail log deliveries?\n",
        "id": 150
    },
    {
        "Correct": [
            "Create Amazon Kinesis Data Streams in the logging account, subscribe the stream to CloudWatch Logs streams in each application AWS account, configure an Amazon Kinesis Data Firehose delivery stream with the Data Streams as its source, and persist the log data in an Amazon S3 bucket inside the logging AWS account.\n"
        ],
        "Answers": [
            "Create a Log Audit IAM role in each application AWS account with permissions to view CloudWatch Logs, configure an AWS Lambda function to assume the Log Audit role, and perform an hourly export of CloudWatch Logs data to an Amazon S3 bucket in the logging AWS account.\n",
            "Configure CloudWatch Logs streams in each application AWS account to forward events to CloudWatch Logs in the logging AWS account. In the logging AWS account, subscribe an Amazon Kinesis Data Firehose stream to Amazon CloudWatch Events, and use the stream to persist log data in Amazon S3.\n",
            "Create Amazon Kinesis Data Streams in the logging account, subscribe the stream to CloudWatch Logs streams in each application AWS account, configure an Amazon Kinesis Data Firehose delivery stream with the Data Streams as its source, and persist the log data in an Amazon S3 bucket inside the logging AWS account.\n",
            "Configure CloudWatch Logs agents to publish data to an Amazon Kinesis Data Firehose stream in the logging AWS account, use an AWS Lambda function to read messages from the stream and push messages to Data Firehose, and persist the data in Amazon S3.\n"
        ],
        "Question": "A company has multiple AWS accounts hosting IT applications. An Amazon CloudWatch Logs agent is installed on all Amazon EC2 instances. The company wants to aggregate all security events in a centralized AWS account dedicated to log storage.Security Administrators need to perform near-real-time gathering and correlating of events across multiple AWS accounts.Which solution satisfies these requirements?\n",
        "id": 151
    },
    {
        "Correct": [
            "Use Amazon S3 server-side encryption with AWS KMS-managed keys, create multiple customer master keys, and use key policies to control access to them.\n",
            "Use Amazon S3 server-side encryption with customer-managed keys, and use two AWS CloudHSM instances configured in high-availability mode to manage the keys. Use the Cloud HSM client software to control access to the keys that are generated.\n"
        ],
        "Answers": [
            "Use Amazon S3 server-side encryption with Amazon S3-managed keys. Allow Amazon S3 to generate an AWS/S3 master key, and use IAM to control access to the data keys that are generated.\n",
            "Use Amazon S3 server-side encryption with AWS KMS-managed keys, create multiple customer master keys, and use key policies to control access to them.\n",
            "Use Amazon S3 server-side encryption with customer-managed keys, and use AWS CloudHSM to manage the keys. Use CloudHSM client software to control access to the keys that are generated.\n",
            "Use Amazon S3 server-side encryption with customer-managed keys, and use two AWS CloudHSM instances configured in high-availability mode to manage the keys. Use the Cloud HSM client software to control access to the keys that are generated.\n",
            "Use Amazon S3 server-side encryption with customer-managed keys, and use two AWS CloudHSM instances configured in high-availability mode to manage the keys. Use IAM to control access to the keys that are generated in CloudHSM.\n"
        ],
        "Question": "The company Security team queries that all data uploaded into an Amazon S3 bucket must be encrypted. The encryption keys must be highly available and the company must be able to control access on a per-user basis, with different users having access to different encryption keys.Which of the following architectures will meet these requirements? (Choose two.)\n",
        "id": 152
    },
    {
        "Correct": [
            "Create a Proxy Server with user authentication and an Elastic IP address, and restrict access of the Amazon ES endpoint to the IP address\n",
            "Use Amazon Cognito to offer user name and password protection for Kibana\n"
        ],
        "Answers": [
            "Create a Proxy Server with user authentication in an Auto Scaling Group, and restrict access of the Amazon ES endpoint to an Auto Scaling group tag\n",
            "Create a Proxy Server with user authentication and an Elastic IP address, and restrict access of the Amazon ES endpoint to the IP address\n",
            "Create a Proxy Server with AWS IAM user, and restrict access of the Amazon ES endpoint to the IAM user\n",
            "Use AWS SSO to offer user name and password protection for Kibana\n",
            "Use Amazon Cognito to offer user name and password protection for Kibana\n"
        ],
        "Question": "A company indexes all of its Amazon CloudWatch Logs on Amazon ES and uses Kibana to view a dashboard for actionable insight. The company wants to restrict user access to Kibana by user. Which actions can a Security Engineer take to meet this requirement? (Select TWO)\n",
        "id": 153
    },
    {
        "Correct": [
            "Only principals from account 111122223333 that have an IAM policy applied that grants access to this key to use the key.\n"
        ],
        "Answers": [
            "All principals from all AWS accounts to use the key.\n",
            "Only the root user from account 111122223333 to use the key.\n",
            "All principals from account 111122223333 to use the key but only on Amazon S3.\n",
            "Only principals from account 111122223333 that have an IAM policy applied that grants access to this key to use the key.\n"
        ],
        "Question": "A Security Engineer who was reviewing AWS Key Management Service (AWS KMS) key policies found this statement in each key policy in the company AWS account. { \"Sid\": \"Enable IAM User Permissions\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::111122223333:root\" }, \"Action\": \"kms:*\", \"Resource\": \"*\" } What does the statement allow?\n",
        "id": 154
    },
    {
        "Correct": [
            "Create an IAM Role and ensure the EC2 Instances use the IAM Role to access the data in the bucket.\n",
            "Configure S3 to use versioning and enable Multi-Factor Authentication (MFA) protected access\n"
        ],
        "Answers": [
            "Create an IAM user and ensure the EC2 Instances use the IAM user credentials to access the data in the bucket.\n",
            "Create an IAM Role and ensure the EC2 Instances use the IAM Role to access the data in the bucket.\n",
            "Use S3 Cross-Region Replication to replicate the objects so that the integrity of data is maintained.\n",
            "Use a S3 bucket policy that prevents accidental deletions\n",
            "Configure S3 to use versioning and enable Multi-Factor Authentication (MFA) protected access\n"
        ],
        "Question": "Your company has a set of EC2 Instances that access data objects stored in an S3 bucket. Your IT Security department is concerned about the security of this architecture and wants you to implement the following: 1) Ensure that the EC2 Instance securely accesses the data objects stored in the S3 bucket 2) Prevent accidental deletion of objects Which of the following would help fulfill the requirements of the IT Security department in a cost-effective way? Choose 2 answers\n",
        "id": 155
    },
    {
        "Correct": [
            "Call the abort-vault-lock operation, fix the typo, and call the initiate-vault-lock again.\n"
        ],
        "Answers": [
            "Call the abort-vault-lock operation, fix the typo, and call the initiate-vault-lock again.\n",
            "Copy the vault data to Amazon S3, delete the vault, and create a new vault with the data.\n",
            "Update the policy, keeping the vault lock in place.\n",
            "Update the policy and call initiate-vault-lock again to apply the new policy.\n"
        ],
        "Question": "The Security Engineer implemented a new vault lock policy for 10TB of data and called initiate-vault-lock 12 hours ago. The Audit team identified a typo that is allowing incorrect access to the vault.What is the MOST cost-effective way to correct this?\n",
        "id": 156
    },
    {
        "Correct": [
            "An outbound rule must be added to the network ACL to allow the response to be sent to the client on the ephemeral port range.\n"
        ],
        "Answers": [
            "The outbound rules on the security group do not allow the response to be sent to the client on the ephemeral port range.\n",
            "The outbound rules on the security group do not allow the response to be sent to the client on the HTTP port.\n",
            "An outbound rule must be added to the network ACL to allow the response to be sent to the client on the ephemeral port range.\n",
            "An outbound rule must be added to the network ACL to allow the response to be sent to the client on the HTTP port.\n"
        ],
        "Question": "A Software Engineer is trying to figure out why network connectivity to an Amazon EC2 instance does not appear to be working correctly. Its security group allows inbound HTTP traffic from 0.0.0.0/0, and the outbound rules have not been modified from the default. A custom network ACL associated with its subnet allows inbound HTTP traffic from 0.0.0.0/0 and has no outbound rules.What would resolve the connectivity issue?\n",
        "id": 157
    },
    {
        "Correct": [
            "Use AWS Certificate Manager to provision a certificate on an Elastic Load Balancing in front of the web service`s servers.\n"
        ],
        "Answers": [
            "Upload an SSL certificate to IAM, and configure Amazon CloudFront with the passphrase for the private key.\n",
            "Call KMS.Encrypt() in the client, passing in the data file contents, and call KMS.Decrypt() server-side.\n",
            "Use AWS Certificate Manager to provision a certificate on an Elastic Load Balancing in front of the web service`s servers.\n",
            "Create a new VPC with an Amazon VPC VPN endpoint, and update the web service`s DNS record.\n"
        ],
        "Question": "An organization has a system in AWS that allows a large number of remote workers to submit data files. File sizes vary from a few kilobytes to several megabytes. A recent audit highlighted a concern that data files are not encrypted while in transit over untrusted networks. Which solution would remediate the audit finding while minimizing the effort required?\n",
        "id": 158
    },
    {
        "Correct": [
            "kms:CreateGrant\n",
            "\"Condition\": { \"Bool\": { \"kms:GrantIsForAWSResource\": true }\n"
        ],
        "Answers": [
            "kms:GenerateDataKey\n",
            "kms:Decrypt\n",
            "kms:CreateGrant\n",
            "\"Condition\": { \"Bool\": { \"kms:ViaService\": \"ec2.us-west-2.amazonaws.com\" } }\n",
            "\"Condition\": { \"Bool\": { \"kms:GrantIsForAWSResource\": true }\n"
        ],
        "Question": "An IAM user with full EC2 permissions could not start an Amazon EC2 instance after it was stopped for a maintenance task. Upon starting the instance, the instance state would change to \"Pending\", but after a few seconds, it would switch back to \"Stopped\".An inspection revealed that the instance has attached Amazon EBS volumes that were encrypted by using a Customer Master Key (CMK). When these encrypted volumes were detached, the IAM user was able to start the EC2 instances.The IAM user policy is as follows:What additional items need to be added to the IAM user policy? (Choose two.)\n",
        "id": 159
    },
    {
        "Correct": [
            "Use an API Gateway custom authorizer to invoke an AWS Lambda function to validate each user`s identity.\n"
        ],
        "Answers": [
            "Use AWS IAM authorization and add least-privileged permissions to each respective IAM role\n",
            "Use an API Gateway custom authorizer to invoke an AWS Lambda function to validate each user`s identity.\n",
            "Use Amazon Cognito user pools to provide built-in user management\n",
            "Use Amazon Cognito user pools to integrate with external identity providers.\n"
        ],
        "Question": "As part of securing an API layer built on Amazon API Gateway, a Solutions Architect has to authorize users who are currently authenticated by an existing identity provider. The users must be denied access for a period of one hour after these unsuccessful attempts. How can the authentication be implemented?\n",
        "id": 160
    },
    {
        "Correct": [
            "Store the database credentials in AWS Secrets Manager. Create an IAM role with access to Secrets Manager by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances. Set up Lambda to use the new role for execution.\n"
        ],
        "Answers": [
            "Store the database credentials in AWS Key Management Service (AWS KMS). Create an IAM role with access to AWS KMS by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances. Set up Lambda to use the new role for execution.\n",
            "Store the database credentials in AWS KMS. Create an IAM role with access to KMS by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances and the Lambda function.\n",
            "Store the database credentials in AWS Secrets Manager. Create an IAM role with access to Secrets Manager by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances and the Lambda function.\n",
            "Store the database credentials in AWS Secrets Manager. Create an IAM role with access to Secrets Manager by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances. Set up Lambda to use the new role for execution.\n"
        ],
        "Question": "An organization wants to deploy a three-tier web application whereby the application servers run on Amazon EC2 instances. These EC2 instances need access to credentials that they will use to authenticate their SQL connections to an Amazon RDS DB instance. Also, AWS Lambda functions must issue queries to the RDS database by using the same database credentials. The credentials must be stored so that the EC2 instances and the Lambda functions can access them. No other access is allowed. The access logs must record when the credentials were accessed and by whom. What should the Security Engineer do to meet these requirements?\n",
        "id": 161
    },
    {
        "Correct": [
            "Create a new CMK, import new key material to it, and point the key alias to the new CMK.\n"
        ],
        "Answers": [
            "Enable automatic key rotation annually for the CMK.\n",
            "Use AWS Command Line interface to create an AWS Lambda function to rotate the existing CMK annually.\n",
            "Import new key material to the existing CMK and manually rotate the CMK.\n",
            "Create a new CMK, import new key material to it, and point the key alias to the new CMK.\n"
        ],
        "Question": "A company has a customer master key (CMK) with imported key materials. Company policy requires that all encryption keys must be rotated every year. What can be done to implement the above policy?\n",
        "id": 162
    },
    {
        "Correct": [
            "Use CloudTrail Log File Integrity Validation.\n"
        ],
        "Answers": [
            "Use CloudTrail Log File Integrity Validation.\n",
            "Use AWS Config SNS Subscriptions and process events in real time.\n",
            "Use CloudTrail backed up to AWS S3 and Glacier.\n",
            "Use AWS Config Timeline forensics.\n"
        ],
        "Question": "Your CTO thinks your AWS account was hacked. What is the only way to know for certain if there was unauthorized access and what they did, assuming your hackers are very sophisticated AWS engineers and doing everything they can to cover their tracks?\n",
        "id": 163
    },
    {
        "Correct": [
            "Using security groups that reference the security groups of the other application.\n"
        ],
        "Answers": [
            "Using security groups that reference the security groups of the other application.\n",
            "Using security groups that reference the application servers IP address.\n",
            "Using Network Access Control Lists to allow/deny traffic based on application IP address.\n",
            "Migrating the applications to separate subnets from each other.\n"
        ],
        "Question": "Two Auto Scaling applications, Application A and Application B currently run within a shared set of subnets. A solution architect wants to make sure that Application A can make request to Application B, but Application B should be denied from making request to Application Which is the SIMPLEST solution to achieve this policy?\n",
        "id": 164
    },
    {
        "Correct": [
            "Configure the CloudTrail service in each AWS account and have the logs delivered to a single AWS bucket in the primary account and grant the auditor access to that single bucket in the primary account.\n"
        ],
        "Answers": [
            "Configure the CloudTrail service in each AWS account, and have the logs delivered to an AWS bucket on each account, while granting the auditor permissions to the bucket via roles in the secondary accounts and a single primary IAM account that can assume a read-only role in the secondary AWS accounts.\n",
            "Configure the CloudTrail service in the primary AWS account and configure consolidated billing for all the secondary accounts. Then grant the auditor access to the S3 bucket that receives the CloudTrail log files.\n",
            "Configure the CloudTrail service in each AWS account and enable consolidated logging inside of CloudTrail.\n",
            "Configure the CloudTrail service in each AWS account and have the logs delivered to a single AWS bucket in the primary account and grant the auditor access to that single bucket in the primary account.\n"
        ],
        "Question": "An auditor needs access to logs that record all API events on AWS. The auditor only needs read-only access to the log files and does not need access to each AWS account. The company has multiple AWS accounts, and the auditor needs access to all the logs for all the accounts. What is the best way to configure access for the auditor to view event logs from all accounts? Choose the correct answer from the options below\n",
        "id": 165
    },
    {
        "Correct": [
            "Create EBS Snapshots of each of the volumes attached to the compromised instances.\n",
            "Capture a memory dump.\n",
            "Revoke all network ingress and egress except for to/from a forensics.\n"
        ],
        "Answers": [
            "Use AWS Artifact to capture an exact image of the state of each instance.\n",
            "Create EBS Snapshots of each of the volumes attached to the compromised instances.\n",
            "Capture a memory dump.\n",
            "Log in to each instance with administrative credentials to restart the instance.\n",
            "Revoke all network ingress and egress except for to/from a forensics.\n",
            "Run Auto Recovery for Amazon EC2.\n"
        ],
        "Question": "A Security Engineer received an AWS Abuse Notice listing EC2 instance IDs that are reportedly abusing other hosts.Which action should the Engineer take based on this situation? (Choose three.)\n",
        "id": 166
    },
    {
        "Correct": [
            "Install and configure the Amazon CloudWatch Logs agent on the application`s EC2 instance. Create a CloudWatch metric filter to monitor the application logs. Set up CloudWatch alerts based on the metrics.\n"
        ],
        "Answers": [
            "Create a scheduled process to copy the component`s logs into Amazon S3. Use S3 events to trigger a Lambda function that updates Amazon CloudWatch metrics with the log data. Set up CloudWatch alerts based on the metrics.\n",
            "Install and configure the Amazon CloudWatch Logs agent on the application`s EC2 instance. Create a CloudWatch metric filter to monitor the application logs. Set up CloudWatch alerts based on the metrics.\n",
            "Create a scheduled process to copy the application log files to AWS CloudTrail. Use S3 events to trigger Lambda functions that update CloudWatch metrics with the log data. Set up CloudWatch alerts based on the metrics.\n",
            "Create a file watcher that copies data to Amazon Kinesis when the application writes to the log file. Have Kinesis trigger a Lambda function to update Amazon CloudWatch metrics with the log data. Set up CloudWatch alerts based on the metrics.\n"
        ],
        "Question": "An application outputs logs to a text file. The logs must be continuously monitored for security incidents.Which design will meet the requirements with MINIMUM effort?\n",
        "id": 167
    },
    {
        "Correct": [
            "Store the data in S3 with Server Side Encryption. Launch an encrypted Redshift cluster and copy the data to the cluster.\n"
        ],
        "Answers": [
            "Store the data in S3 with Server Side Encryption and copy the data over to Redshift cluster\n",
            "Store the data in S3. Launch an encrypted Redshift cluster, copy the data to the Redshift cluster and store back in S3 in encrypted format\n",
            "Store the data in S3 with Server Side Encryption. Launch an encrypted Redshift cluster and copy the data to the cluster.\n",
            "Store the data in S3 with Server Side Encryption. Launch a Redshift cluster, copy the data to cluster and enable encryption on the cluster.\n"
        ],
        "Question": "A company wants to use Redshift cluster for petabyte-scale data warehousing. Data for processing would be stored on Amazon S3. As a security requirement, the company wants the data to be encrypted at rest. As a solution architect how would you implement the solution?\n",
        "id": 168
    },
    {
        "Correct": [
            "Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the proper API key. Launch each Amazon EC2 instance with the proper IAM role.\n"
        ],
        "Answers": [
            "Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM user with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the API key for the environment. Store an access key for that user in a credential store on each Amazon EC2 instance.\n",
            "Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the proper API key. Launch each Amazon EC2 instance with the proper IAM role.\n",
            "Create an Amazon DynamoDB table encrypted with an AWS KMS customer master key (CMK). Store each API key in a different item in the table. Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the dynamodb:getitem action for the correct item. Launch each Amazon EC2 instance with the proper IAM role.\n",
            "Pass the proper API key to each Amazon EC2 instance upon launch utilizing user data. Assign an IAM role to each EC2 instance with permissions to the kms:encrypt and the kms:decrypt actions for a customer-managed AWS KMS customer master key (CMK). In the user data script, encrypt the API key using the CMK. Store the encrypted API key on each EC2 instance.\n"
        ],
        "Question": "A company is migrating an application from its data center to AWS. The application currently stores an API key used to access a third-party service in a local file. When deployed on AWS, the application will run on Amazon EC2 instances. As part of the migration, the application must make the API key more secure. Specifically: Each environment (such as development, test, and production) must have its own API key. All API key access requests should be logged for auditing purposes. The API keys must be encrypted at rest using a customer-managed key. Access permissions must be granular; the development environment cannot access the production API key, for example. What is the MOST secure way to meet these requirements?\n",
        "id": 169
    },
    {
        "Correct": [
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to encrypt and decrypt customer data.\n"
        ],
        "Answers": [
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to decrypt the customer data, and the master keys are used to encrypt the customer data.\n",
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to encrypt the customer data and the master keys are used to decrypt the customer data.\n",
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The master keys are then used to encrypt and decrypt customer data.\n",
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to encrypt and decrypt customer data.\n"
        ],
        "Question": "Once again your security officer is on your case and this time is asking you to make sure the AWS Key Management Service (AWS KMS) is working as it is supposed to. You are initially not too sure how KMS even works, however after some intense late night reading you think you have come up with a reasonable definition. Which of the following best describes how the AWS Key Management Service works? Choose the correct answer:\n",
        "id": 170
    },
    {
        "Correct": [
            "Configure CloudFront to use a custom header and configure an AWS WAF rule on the origin`s Application Load Balancer to accept only traffic that contains that header.\n"
        ],
        "Answers": [
            "Use an IP whitelist rule in AWS WAF within CloudFront to ensure that only known client IPs are able to access the application.\n",
            "Configure CloudFront to use a custom header and configure an AWS WAF rule on the origin`s Application Load Balancer to accept only traffic that contains that header.\n",
            "Configure an AWS Lambda@Edge function to validate that the traffic to the Application Load Balancer originates from CloudFront.\n",
            "Attach an origin access identity to the CloudFront origin that allows traffic to the origin that originates from only CloudFront.\n"
        ],
        "Question": "A Network Engineer is designing a new system on AWS that will take advantage of Amazon CloudFront for both content caching and for protecting the underlying origin. There is concern that an external agency might be able to access the IP addresses for the application`s origin and then attack the origin despite it being served by CloudFront. Which of the following solutions provides the strongest level of protection to the origin?\n",
        "id": 171
    },
    {
        "Correct": [
            "Design network security in a single layer within the perimeter network (also known as DMZ, demilitarized zone, and screened subnet) to facilitate quicker responses to threats.\n"
        ],
        "Answers": [
            "Use security groups to provide stateful firewalls for Amazon EC2 instances at the hypervisor level.\n",
            "Use network ACLs to provide stateful firewalls at the VPC level to prevent access to any specific AWS resource.\n",
            "Use AWS Direct Connect for secure trusted connections between EC2 instances within private subnets.\n",
            "Design network security in a single layer within the perimeter network (also known as DMZ, demilitarized zone, and screened subnet) to facilitate quicker responses to threats.\n"
        ],
        "Question": "Which of the following minimizes the potential attack surface for applications?\n",
        "id": 172
    },
    {
        "Correct": [
            "Use AWS Artifact to access AWS compliance reports.\n"
        ],
        "Answers": [
            "Read the AWS Customer Agreement.\n",
            "Use AWS Artifact to access AWS compliance reports.\n",
            "Post the question on the AWS Discussion Forums.\n",
            "Run AWS Config and evaluate the configuration outputs.\n"
        ],
        "Question": "A Security Engineer is trying to determine whether the encryption keys used in an AWS service are in compliance with certain regulatory standards.Which of the following actions should the Engineer perform to get further guidance?\n",
        "id": 173
    },
    {
        "Correct": [
            "Enable Encryption during the DynamoDB table creation\n"
        ],
        "Answers": [
            "Enable Encryption during the DynamoDB table creation\n",
            "Enable Encryption on the existing table\n",
            "DynamoDB does not support encryption at rest, use AWS RDS service instead\n",
            "DynamoDB does not support encryption at rest, use AWS Redshift service instead\n"
        ],
        "Question": "Your company is going to develop an application in .Net Core which is going to store the data in a DynamoDB table. Security team mandates that all the data needs to be encrypted at rest. How can you achieve this?\n",
        "id": 174
    },
    {
        "Correct": [
            "Create an IAM role with the proper permission policy to communicate with the DynamoDB table. Use web identity federation, which assumes the IAM role using AssumeRoleWithWebldentity, when the user signs in, granting temporary security credentials using STS.\n"
        ],
        "Answers": [
            "During the install and game configuration process, have each user create an IAM credential and assign the IAM user to a group with proper permissions to communicate with DynamoDB.\n",
            "Create an IAM group that only gives access to your application and to the DynamoDB tables. Then, when writing to DynamoDB, simply include the unique device ID to associate the data with that specific user.\n",
            "Create an IAM role with the proper permission policy to communicate with the DynamoDB table. Use web identity federation, which assumes the IAM role using AssumeRoleWithWebldentity, when the user signs in, granting temporary security credentials using STS.\n",
            "Create an Active Directory server and an AD user for each mobile application user. When the user signs in to the AD sign-on, allow the AD server to federate using SAML 2.0 to IAM and assign a role to the AD user which is the assumed with AssumeRoleWithSAML.\n"
        ],
        "Question": "You're building a mobile application game. The application needs permissions for each user to communicate and store data in DynamoDB tables. What is the best method for granting each mobile device that installs your application to access DynamoDB tables for storage when required? Choose the correct answer from the options below\n",
        "id": 175
    },
    {
        "Correct": [
            "Change the security policy on the ELB to disable vulnerable protocols and ciphers.\n"
        ],
        "Answers": [
            "Generate new SSL certificates for all web servers and replace current certificates.\n",
            "Change the security policy on the ELB to disable vulnerable protocols and ciphers.\n",
            "Generate new SSL certificates and use ELB to front-end the encrypted traffic for all web servers.\n",
            "Leverage your current configuration management system to update SSL policy on all web servers.\n"
        ],
        "Question": "Your organization runs a popular e-commerce application deployed on AWS that uses Auto Scaling in conjunction with an Elastic Load balancing (ELB) service with an HTTPS. Your security team reports that an exploitable vulnerability has been discovered in the encryption protocol and cipher that your site uses. Which step should you take to fix this problem?\n",
        "id": 176
    },
    {
        "Correct": [
            "Enable AWS CloudTrail logging across all accounts to a centralized Amazon S3 bucket. Set a lifecycle policy to move the data to Amazon Glacier after 90 days, and expire the data after 7 years.\n"
        ],
        "Answers": [
            "Enable AWS CloudTrail logging across all accounts to a centralized Amazon S3 bucket with versioning enabled. Set a lifecycle policy to move the data to Amazon Glacier daily, and expire the data after 90 days.\n",
            "Enable AWS CloudTrail logging across all accounts to S3 buckets. Set a lifecycle policy to expire the data in each bucket after 7 years.\n",
            "Enable AWS CloudTrail logging across all accounts to Amazon Glacier. Set a lifecycle policy to expire the data after 7 years.\n",
            "Enable AWS CloudTrail logging across all accounts to a centralized Amazon S3 bucket. Set a lifecycle policy to move the data to Amazon Glacier after 90 days, and expire the data after 7 years.\n"
        ],
        "Question": "A Security Engineer must ensure that all API calls are collected across all company accounts, and that they are preserved online and are instantly available for analysis for 90 days. For compliance reasons, this data must be restorable for 7 years.Which steps must be taken to meet the retention needs in a scalable, cost-effective way?\n",
        "id": 177
    },
    {
        "Correct": [
            "Enable Amazon Macie on the S3 buckets that were impacted, then perform data classification. For identified objects that contain PII, use the research function for auditing AWS CloudTrail logs and S3 bucket logs for GET operations.\n"
        ],
        "Answers": [
            "Using Amazon Athena, query the impacted S3 buckets by using the PII query identifier function. Then, create a new Amazon CloudWatch metric for Amazon S3 object access to alert when the objects are accessed.\n",
            "Enable Amazon Macie on the S3 buckets that were impacted, then perform data classification. For identified objects that contain PII, use the research function for auditing AWS CloudTrail logs and S3 bucket logs for GET operations.\n",
            "Enable Amazon GuardDuty and enable the PII rule set on the S3 buckets that were impacted, then perform data classification. Using the PII findings report from GuardDuty, query the S3 bucket logs by using Athena for GET operations.\n",
            "Enable Amazon Inspector on the S3 buckets that were impacted, then perform data classification. For identified objects that contain PII, query the S3 bucket logs by using Athena for GET operations.\n"
        ],
        "Question": "During a recent security audit, it was discovered that multiple teams in a large organization have placed restricted data in multiple Amazon S3 buckets, and the data may have been exposed. The auditor has requested that the organization identify all possible objects that contain personally identifiable information (PII) and then determine whether this information has been accessed. What solution will allow the Security team to complete this request?\n",
        "id": 178
    },
    {
        "Correct": [
            "Manage encryption keys in amazon Key Management Service (KMS), upload to amazon simple storage service (s3) with client-side encryption using a KMS customer master key ID and configure Amazon S3 lifecycle policies to store each object using the amazon glacier storage tier.\n"
        ],
        "Answers": [
            "Manage encryption keys on-premise in an encrypted relational database. Set up an on-premises server with sufficient storage to temporarily store files and then upload them to Amazon S3, providing a client-side master key.\n",
            "Manage encryption keys in a Hardware Security Module (HSM) appliance on-premise server with sufficient storage to temporarily store, encrypt, and upload files directly into amazon Glacier.\n",
            "Manage encryption keys in amazon Key Management Service (KMS), upload to amazon simple storage service (s3) with client-side encryption using a KMS customer master key ID and configure Amazon S3 lifecycle policies to store each object using the amazon glacier storage tier.\n",
            "Manage encryption keys in an AWS CloudHSM appliance. Encrypt files prior to uploading on the employee desktop and then upload directly into amazon glacier\n"
        ],
        "Question": "You are designing a personal document-archiving solution for your global enterprise with thousands of employee. Each employee has potentially gigabytes of data to be backed up in this archiving solution. The solution will be exposed to the employees as an application, where they can just drag and drop their files to the archiving system. Employees can retrieve their archives through a web interface. The corporate network has high bandwidth AWS DirectConnect connectivity to AWS. You have regulatory requirements that all data needs to be encrypted before being uploaded to the cloud. How do you implement this in a highly available and cost efficient way?\n",
        "id": 179
    },
    {
        "Correct": [
            "Enable the CloudTrail file integrity feature on the trail. Use the digest file created by CloudTrail to verify the integrity of the delivered CloudTrail files.\n"
        ],
        "Answers": [
            "Create an Amazon CloudWatch Events rule that triggers an AWS Lambda function when a new file is delivered. Configure the Lambda function to perform an MD5 hash check on the file, store the name and location of the file, and post the returned hash to an Amazon DynamoDB table. The Security team can use the values stored in DynamoDB to verify the file authenticity.\n",
            "Enable the CloudTrail file integrity feature on an Amazon S3 bucket. Create an IAM policy that grants the Security team access to the file integrity logs stored in the S3 bucket.\n",
            "Enable the CloudTrail file integrity feature on the trail. Use the digest file created by CloudTrail to verify the integrity of the delivered CloudTrail files.\n",
            "Create an AWS Lambda function that is triggered each time a new file is delivered to the CloudTrail bucket. Configure the Lambda function to execute an MD5 hash check on the file, and store the result on a tag in an Amazon S3 object. The Security team can use the information on the tag to verify the integrity of the file.\n"
        ],
        "Question": "Security team wants to ensure that AWS CloudTrail files are not tampered with after being created. Currently, there is a process with multiple trails, using AWS IAM to restrict access to specific trails. The Security team wants to ensure they can trace the integrity of each file and make sure there has been no tampering. Which option will require the LEAST effort to implement and ensure the legitimacy of the file while allowing the Security team to prove the authenticity of the logs?\n",
        "id": 180
    },
    {
        "Correct": [
            "Add the Elastic IP addresses of the Security team`s EC2 instances to a trusted IP list in Amazon GuardDuty.\n"
        ],
        "Answers": [
            "Use a filter in AWS CloudTrail to exclude the IP addresses of the Security team`s EC2 instances.\n",
            "Add the Elastic IP addresses of the Security team`s EC2 instances to a trusted IP list in Amazon GuardDuty.\n",
            "Install the Amazon Inspector agent on the EC2 instances that the Security team uses.\n",
            "Grant the Security team`s EC2 instances a role with permissions to call Amazon GuardDuty API operations.\n"
        ],
        "Question": "An organization wants to be alerted when an unauthorized Amazon EC2 instance in its VPC performs a network port scan against other instances in the VPWhen the Security team performs its own internal tests in a separate account by using pre-approved third-party scanners from the AWS Marketplace, the Security team also then receives multiple Amazon GuardDuty events from Amazon CloudWatch alerting on its test activities. How can the Security team suppress alerts about authorized security tests while still receiving alerts about the unauthorized activity?\n",
        "id": 181
    },
    {
        "Correct": [
            "Change the resource section to \"arn:aws:s3:::appbucket/*\".\n"
        ],
        "Answers": [
            "Change the IAM permissions by applying PutBucketPolicy permissions.\n",
            "Verify that the policy has the same name as the bucket name. If not, make it the same.\n",
            "Change the resource section to \"arn:aws:s3:::appbucket/*\".\n",
            "Add an s3:ListBucket action.\n"
        ],
        "Question": "A company is hosting a web application on AWS and is using an Amazon S3 bucket to store images. Users should have the ability to read objects in the bucket. A Security Engineer has written the following bucket policy to grant public read access:{ \"ID\":\"Policy1502987489630\", \"Version\":\"2012-10-17\", \"Statement\":[ { \"Sid\":\"Stmt1502987487640\", \"Action\":[ \"s3:GetObject\", \"s3:GetObjectVersion\" ], \"Effect\":\"Allow\", \"Resource\":\"arn:aws:s3:::appbucket\", \"Principal\":\"*\" } ] } Attempts to read an object, however, receive the error: \"Action does not apply to any resource(s) in statement.\" What should the Engineer do to fix the error?\n",
        "id": 182
    },
    {
        "Correct": [
            "Create an IAM role for EC2 that allows list access to objects in the S3 bucket. Launch the instance with the role, and retrieve the role`s credentials from the EC2 Instance metadata\n"
        ],
        "Answers": [
            "Use the AWS account access keys the application retrieves the credentials from the source code of the application.\n",
            "Create a IAM user for the application with permissions that allow list access to the S3 bucket launch the instance as the IAM user and retrieve the IAM user`s credentials from the EC2 instance user data.\n",
            "Create an IAM role for EC2 that allows list access to objects in the S3 bucket. Launch the instance with the role, and retrieve the role`s credentials from the EC2 Instance metadata\n",
            "Create an IAM user for the application with permissions that allow list access to the S3 bucket. The application retrieves the IAM user credentials from a temporary directory with permissions that allow read access only to the application user.\n"
        ],
        "Question": "You have an application running on an EC2 Instance, which will allow users to download files from a private S3 bucket using a pre-signed URL. Before generating the URL the application should verify the existence of the file in S3. How should the application use AWS credentials to access the S3 bucket securely?\n",
        "id": 183
    },
    {
        "Correct": [
            "Digitized files -> Amazon Kinesis Data Streams -> Kinesis Client Library consumer -> Amazon S3 -> Athena\n"
        ],
        "Answers": [
            "Digitized files -> Amazon Kinesis Data Analytics\n",
            "Digitized files -> Amazon Kinesis Data Firehose -> Amazon S3 -> Amazon Athena\n",
            "Digitized files -> Amazon Kinesis Data Streams -> Kinesis Client Library consumer -> Amazon S3 -> Athena\n",
            "Digitized files -> Amazon Kinesis Data Firehose -> Amazon Elasticsearch\n"
        ],
        "Question": "A pharmaceutical company has digitized versions of historical prescriptions stored on premises. The company would like to move these prescriptions to AWS and perform analytics on the data in them. Any operation with this data requires that the data be encrypted in transit and at rest. Which application flow would meet the data protection requirements on AWS?\n",
        "id": 184
    },
    {
        "Correct": [
            "Use AWS Systems Manager to store the credentials as Secure Strings Parameters. Secure by using an AWS KMS key.\n"
        ],
        "Answers": [
            "Use AWS Systems Manager to store the credentials as Secure Strings Parameters. Secure by using an AWS KMS key.\n",
            "Use AWS Key Management System to store a master key, which is used to encrypt the credentials. The encrypted credentials are stored in an Amazon RDS instance.\n",
            "Use AWS Secrets Manager to store the credentials.\n",
            "Store the credentials in a JSON file on Amazon S3 with server-side encryption.\n"
        ],
        "Question": "A water utility company uses a number of Amazon EC2 instances to manage updates to a fleet of 2,000 Internet of Things (IoT) field devices that monitor water quality. These devices each have unique access credentials. An operational safety policy requires that access to specific credentials is independently auditable. What is the MOST cost-effective way to manage the storage of credentials?\n",
        "id": 185
    },
    {
        "Correct": [
            "Enable VPC Flow Logs for the production VPC\n"
        ],
        "Answers": [
            "Enable CloudTrail for the production VPC\n",
            "Enable VPC Flow Logs for the production VPC\n",
            "Enable both CloudTrail and VPC Flow Logs for the production VPC\n",
            "Enable both CloudTrail and VPC Flow Logs for the AWS account\n"
        ],
        "Question": "A customer`s security team requires the logging of all network access attempts to Amazon EC2 instances in their production VPC on AWS. Which configuration will meet the security team`s requirement?\n",
        "id": 186
    },
    {
        "Correct": [
            "Use AWS Config to review the IAM policy assigned to users before and after the incident.\n"
        ],
        "Answers": [
            "Use AWS Config to review the IAM policy assigned to users before and after the incident.\n",
            "Run the GenerateCredentialReport via the AWS CLI, and copy the output to Amazon S3 daily for auditing purposes.\n",
            "Copy AWS CloudFormation templates to S3, and audit for changes from the template.\n",
            "Use Amazon EC2 Systems Manager to deploy images, and review AWS CloudTrail logs for changes.\n"
        ],
        "Question": "A Security Engineer must design a solution that enables the incident Response team to audit for changes to a user`s IAM permissions in the case of a security incident. How can this be accomplished?\n",
        "id": 187
    },
    {
        "Correct": [
            "Create an IAM role with read-only permissions to all AWS services in each AWS account. Create one auditor IAM account and add a permissions policy that allows the auditor to assume the ARN role for each AWS account that has an assigned role.\n"
        ],
        "Answers": [
            "Create an IAM user for each AWS account with read-only permission policies for the auditor, and disable each account when the audit is complete.\n",
            "Configure an on-premise AD server and enable SAML and identify federation for single sign-on to each AWS account.\n",
            "Create an IAM role with read-only permissions to all AWS services in each AWS account. Create one auditor IAM account and add a permissions policy that allows the auditor to assume the ARN role for each AWS account that has an assigned role.\n",
            "Create a custom identity broker application that allows the auditor to use existing Amazon credentials to Log into the AWS environments.\n"
        ],
        "Question": "A third party auditor is being brought in to review security processes and configurations for all of a company's AWS accounts. Currently, the company does not use any on-premise identity provider. Instead, they rely on IAM accounts in each of their AWS accounts. The auditor needs read-only access to all AWS resources for each AWS account. Given the requirements, what is the best security method for architecting access for the security auditor? Choose the correct answer from the options below\n",
        "id": 188
    },
    {
        "Correct": [
            "Using AWS Config, create a config rule that detects when AWS CloudTrail is disabled, as well as any calls to the root user create-api-key. Then use a Lambda function to re-enable CloudTrail logs and deactivate the root API keys.\n"
        ],
        "Answers": [
            "Using Amazon Inspector, review all of the API calls and configure the inspector agent to leverage SNS topics to notify security of the change to AWS CloudTrail, and revoke the new API keys for the root user.\n",
            "Using AWS Config, create a config rule that detects when AWS CloudTrail is disabled, as well as any calls to the root user create-api-key. Then use a Lambda function to re-enable CloudTrail logs and deactivate the root API keys.\n",
            "Using Amazon CloudWatch, create a CloudWatch event that detects AWS CloudTrail deactivation and a separate Amazon Trusted Advisor check to automatically detect the creation of root API keys. Then use a Lambda function to enable AWS CloudTrail and deactivate the root API keys.\n",
            "Using Amazon CloudTrail, create a new CloudTrail event that detects the deactivation of CloudTrail logs, and a separate CloudTrail event that detects the creation of root API keys. Then use a Lambda function to enable CloudTrail and deactivate the root API keys.\n"
        ],
        "Question": "During a recent internal investigation, it was discovered that all API logging was disabled in a production account, and the root user had created new API keys that appear to have been used several times.What could have been done to detect and automatically remediate the incident?\n",
        "id": 189
    },
    {
        "Correct": [
            "Create IAM roles with permissions corresponding to each Active Directory group.\n",
            "Configure Active Directory to add relying party trust between Active Directory and AWS.\n"
        ],
        "Answers": [
            "Create IAM roles with permissions corresponding to each Active Directory group.\n",
            "Create IAM groups with permissions corresponding to each Active Directory group.\n",
            "Configure Amazon Cloud Directory to support a SAML provider.\n",
            "Configure Active Directory to add relying party trust between Active Directory and AWS.\n",
            "Configure Amazon Cognito to add relying party trust between Active Directory and AWS.\n"
        ],
        "Question": "A company plans to move most of its IT infrastructure to AWS. They want to leverage their existing on-premises Active Directory as an identity provider for AWS.Which combination of steps should a Security Engineer take to federate the company`s on-premises Active Directory with AWS? (Choose two.)\n",
        "id": 190
    },
    {
        "Correct": [
            "Outbound; Protocol tcp; Destination 169.254.169.254; Destination port 80\n"
        ],
        "Answers": [
            "Inbound; Protocol tcp; Source [Instance`s EIP]; Destination 169.254.169.254\n",
            "Inbound; Protocol tcp; Destination 169.254.169.254; Destination port 80\n",
            "Outbound; Protocol tcp; Destination 169.254.169.254; Destination port 80\n",
            "Outbound; Protocol tcp; Destination 169 .254.169.254; Destination port 443\n"
        ],
        "Question": "Your security team implements a host-based firewall on all of your Amazon Elastic Compute Cloud (EC2) instances to block all outgoing traffic. Exceptions must be requested for each specific requirement. Until you request a new rule, you cannot access the instance metadata service. Which firewall rule should you request to be added to your instances to allow instance metadata access?\n",
        "id": 191
    },
    {
        "Correct": [
            "Ensure CloudTrail is enabled. Create a user account for the Auditor and attach the AWSCloudTrailReadOnlyAccess Policy to the user.\n"
        ],
        "Answers": [
            "Enable S3 and ELB logs. Send the logs as a zip file to the IT Auditor.\n",
            "Ensure CloudTrail is enabled. Create a user account for the Auditor and attach the AWSCloudTrailReadOnlyAccess Policy to the user.\n",
            "Ensure that CloudTrail is enabled. Create a user for the IT Auditor and ensure that full control is given to the user for CloudTrail.\n",
            "Enable CloudWatch logs. Create a user for the IT Auditor and ensure that full control is given to the user for the CloudWatch logs.\n"
        ],
        "Question": "A Customer wants to perform an audit to track access to all the AWS resources. Which of the following steps will ensure that the auditor has the right access to the logs of your AWS account?\n",
        "id": 192
    },
    {
        "Correct": [
            "Associate an origin access identity with the CloudFront distribution.\n",
            "Modify the S3 bucket permissions so that only the origin access identity can access the bucket contents.\n"
        ],
        "Answers": [
            "Associate an origin access identity with the CloudFront distribution.\n",
            "Implement a \"Principal\": \"cloudfront.amazonaws.com\" condition in the S3 bucket policy.\n",
            "Modify the S3 bucket permissions so that only the origin access identity can access the bucket contents.\n",
            "Implement security groups so that the S3 bucket can be accessed only by using the intended CloudFront distribution.\n",
            "Configure the S3 bucket policy so that it is accessible only through VPC endpoints, and place the CloudFront distribution into the specified VPC.\n"
        ],
        "Question": "A Security Administrator has a website hosted in Amazon S3. The Administrator has been given the following requirements: Users may access the website by using an Amazon CloudFront distribution. Users may not access the website directly by using an Amazon S3 URL. Which configurations will support these requirements? (Choose two.)\n",
        "id": 193
    },
    {
        "Correct": [
            "Use Amazon CloudWatch logs with two log groups, one for each application, and use an AWS IAM policy to control access to the log groups as required.\n"
        ],
        "Answers": [
            "Aggregate logs into one file, then use Amazon CloudWatch Logs and then design two CloudWatch metric filters to filter sensitive data from the logs.\n",
            "Use Amazon CloudWatch logs to capture all logs, write an AWS Lambda function that parses the log file, and move sensitive data to a different log.\n",
            "Add logic to the application that saves sensitive data logs on the Amazon EC2 instances' local storage, and write a batch script that logs into the EC2 instances and moves sensitive logs to a secure location.\n",
            "Use Amazon CloudWatch logs with two log groups, one for each application, and use an AWS IAM policy to control access to the log groups as required.\n"
        ],
        "Question": "Your application development team is building a solution with two applications. The security team wants each application's logs to be captured in two different places because one of the applications produces logs with sensitive data. How can you meet the requirements with the least risk and effort?\n",
        "id": 194
    },
    {
        "Correct": [
            "Use Amazon S3 server-side encryption with AWS Key Management Service managed keys.\n",
            "Use Amazon S3 server-side encryption with customer-provided keys\n",
            "Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key\n"
        ],
        "Answers": [
            "Use Amazon S3 server-side encryption with AWS Key Management Service managed keys.\n",
            "Use Amazon S3 server-side encryption with customer-provided keys\n",
            "Use Amazon S3 server-side encryption with EC2 key pair.\n",
            "Use Amazon S3 bucket policies to restrict access to the data at rest.\n",
            "Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key\n",
            "Use SSL to encrypt the data while in transit to Amazon S3.\n"
        ],
        "Question": "A company is storing data on Amazon Simple Storage Service (S3). The company`s security policy mandates that data be encrypted at rest. Which of the following methods can achieve this? Choose 3 answers\n",
        "id": 195
    },
    {
        "Correct": [
            "Analyze AWS CloudTrail for activity.\n",
            "Download and analyze a credential report from IAM.\n"
        ],
        "Answers": [
            "Analyze AWS CloudTrail for activity.\n",
            "Analyze Amazon CloudWatch Logs for activity.\n",
            "Download and analyze the IAM Use report from AWS Trusted Advisor.\n",
            "Analyze the resource inventory in AWS Config for IAM user activity.\n",
            "Download and analyze a credential report from IAM.\n"
        ],
        "Question": "An employee accidentally exposed an AWS access key and secret access key during a public presentation. The company Security Engineer immediately disabled the key. How can the Engineer assess the impact of the key exposure and ensure that the credentials were not misused? (Choose two.)\n",
        "id": 196
    },
    {
        "Correct": [
            "Install the Amazon CloudWatch Logs Agent on the EC2 instances, and configure it to send the application logs to CloudWatch Logs.\n"
        ],
        "Answers": [
            "Write an AWS Lambda function that logs into the EC2 instance to pull the application logs from the EC2 instance and persists them into an Amazon S3 bucket.\n",
            "Enable AWS CloudTrail logging for the AWS account, create a new Amazon S3 bucket, and then configure Amazon CloudWatch Logs to receive the application logs from CloudTrail.\n",
            "Create a simple cron job on the EC2 instances that synchronizes the application logs to an Amazon S3 bucket by using rsync.\n",
            "Install the Amazon CloudWatch Logs Agent on the EC2 instances, and configure it to send the application logs to CloudWatch Logs.\n"
        ],
        "Question": "A Software Engineer wrote a customized reporting service that will run on a fleet of Amazon EC2 instances. The company security policy states that application logs for the reporting service must be centrally collected.What is the MOST efficient way to meet these requirements?\n",
        "id": 197
    },
    {
        "Correct": [
            "Enable default encryption with server-side encryption with AWS KMS-managed keys (SSE-KMS) on the S3 bucket.\n",
            "Add a bucket policy that includes a deny if a PutObject request does not include aws:SecureTransport.\n"
        ],
        "Answers": [
            "Enable AES-256 encryption using server-side encryption with Amazon S3-managed encryption keys (SSE-S3) on the S3 bucket.\n",
            "Enable default encryption with server-side encryption with AWS KMS-managed keys (SSE-KMS) on the S3 bucket.\n",
            "Add a bucket policy that includes a deny if a PutObject request does not include aws:SecureTransport.\n",
            "Add a bucket policy with aws:SourceIp to allow uploads and downloads from the corporate intranet only.\n",
            "Enable Amazon Macie to monitor and act on changes to the data lake's S3 bucket.\n"
        ],
        "Question": "A company is building a data lake on Amazon S3. The data consists of millions of small files containing sensitive information. The Security team has the following requirements for the architecture: Data must be encrypted in transit. Data must be encrypted at rest. The bucket must be private, but if the bucket is accidentally made public, the data must remain confidential. Which combination of steps would meet the requirements? (Select TWO.)\n",
        "id": 198
    },
    {
        "Correct": [
            "Verify which Security Group is applied to the particular web server`s elastic network interface (ENI).\n",
            "Verify the registered targets in the ALB.\n"
        ],
        "Answers": [
            "Verify that the 0.0.0.0/0 route in the route table for the web server subnet points to a NAT gateway.\n",
            "Verify which Security Group is applied to the particular web server`s elastic network interface (ENI).\n",
            "Verify that the 0.0.0.0/0 route in the route table for the web server subnet points to the virtual security appliance.\n",
            "Verify the registered targets in the ALB.\n",
            "Verify that the 0.0.0.0/0 route in the public subnet points to a NAT gateway\n"
        ],
        "Question": "A Security Engineer has been asked to troubleshoot inbound connectivity to a web server. This single web server is not receiving inbound connections from the internet, whereas all other web servers are functioning properly. The architecture includes network ACLs, security groups, and a virtual security appliance. In addition, the Development team has implemented Application Load Balancers (ALBs) to distribute the load across all web servers. It is a requirement that traffic between the web servers and the internet flow through the virtual security appliance. The Security Engineer has verified the following: The rule set in the Security Groups is correct The rule set in the network ACLs is correct The rule set in the virtual appliance is correct Which of the following are other valid items to troubleshoot in this scenario? (Choose two.)\n",
        "id": 199
    },
    {
        "Correct": [
            "One in the US West (Oregon) region and one in the US East (Virginia) region.\n"
        ],
        "Answers": [
            "One in the US West (Oregon) region and one in the US East (Virginia) region.\n",
            "Two in the US West (Oregon) region and none in the US East (Virginia) region.\n",
            "One in the US West (Oregon) region and none in the US East (Virginia) region.\n",
            "Two in the US West (Virginia) region and none in the US West (Oregon) region.\n"
        ],
        "Question": "A Solutions Architect is designing a web application that uses Amazon CloudFront, an Elastic Load Balancing Application Load Balancer, and an Auto Scaling group of Amazon EC2 instances. The load balancer and EC2 instances are in the US West (Oregon) region. It has been decided that encryption in transit is necessary by using a customer-branded domain name from the client to CloudFront and from CloudFront to the load balancer. Assuming that AWS Certificate Manager is used, how many certificates will need to be generated?\n",
        "id": 200
    },
    {
        "Correct": [
            "Enable AWS Default Encryption\n"
        ],
        "Answers": [
            "Enable AWS Default Encryption\n",
            "Place the following statement in the IAM policy \"Statement\": [ { \"Sid\": \"Stmt1504640908907\", \"Effect\": \"Allow\", \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::/*\", \"Condition\": { \"Bool\": { \"aws:SecureTransport\": \"false\" } } } ]\n",
            "Place the following statement in the bucket policy\"Statement\": [ { \"Sid\": \"Stmt1504640908907\", \"Effect\": \"Allow\", \"Principal\": \"*\", \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::/*\", \"Condition\": { \"Bool\": { \"aws:SecureTransport\": \"false\" } } } ]\n",
            "Enable versioning for the buckets\n"
        ],
        "Question": "A company has a number of sensitive files available in an S3 bucket. The CIO is worried about the security of the documents in the bucket. As the Security lead, you have been instructed to increase the security for S3 bucket. How can you achieve this?\n",
        "id": 201
    },
    {
        "Correct": [
            "Use Amazon Cognito user pools and a custom authorizer to authenticate and authorize users based on JSON Web Tokens.\n"
        ],
        "Answers": [
            "Use Amazon Cognito user pools and a custom authorizer to authenticate and authorize users based on JSON Web Tokens.\n",
            "Build an OpenID token broker with Amazon and Facebook. Users will authenticate with these identify providers and pass the JSON Web Token to the API to authenticate each API call.\n",
            "Store user credentials in Amazon DynamoDB and have the application retrieve temporary credentials from AWS STS. Make API calls by passing user credentials to the APIs for authentication and authorization.\n",
            "Use Amazon RDS to store user credentials and pass them to the APIs for authentications and authorization.\n"
        ],
        "Question": "A company developed a set of APIs that are being served through the Amazon API Gateway. The API calls need to be authenticated based on OpenID identity providers such as Amazon or Facebook. The APIs should allow access based on a custom authorization model. Which is the simplest and MOST secure design to use to build an authentication and authorization model for the APIs?\n",
        "id": 202
    },
    {
        "Correct": [
            "The Lambda function does not have permissions to access the CloudTrail S3 bucket.\n"
        ],
        "Answers": [
            "The Lambda function does not have permissions to start the Athena query execution.\n",
            "The Security Engineer does not have permissions to start the Athena query execution.\n",
            "The Athena service does not support invocation through Lambda.\n",
            "The Lambda function does not have permissions to access the CloudTrail S3 bucket.\n"
        ],
        "Question": "A Security Engineer has created an Amazon CloudWatch event that invokes an AWS Lambda function daily. The Lambda function runs an Amazon Athena query that checks AWS CloudTrail logs in Amazon S3 to detect whether any IAM user accounts or credentials have been created in the past 30 days. The results of the Athena query are created in the same S3 bucket. The Engineer runs a test execution of the Lambda function via the AWS Console, and the function runs successfully. After several minutes, the Engineer finds that his Athena query has failed with the error message: \"Insufficient Permissions\". The IAM permissions of the Security Engineer and the Lambda function are shown below:Security Engineer{ \"Version\": \"2012-10-17\", \"Statement\": [{ \"Effect\": \"Allow\", \"Action\": [ \"s3:*\", \"iam:*\", \"lambda:*\", \"athena:Get*\", \"athena:List*\", \"cloudwatch:*\" ], \"Resource\": \"*\" }] } Lambda function execution role{ \"Version\": \"2012_10-17\", \"Statement\": [{ \"Effect\": \"Action\", \"Allow\": [ \"athena:*\", \"cloudwatch:*\" ], \"Resource\": \"*\" }] } What is causing the error?\n",
        "id": 203
    },
    {
        "Correct": [
            "Store the database credentials in AWS Secrets Manager. Create an IAM role with access to Secrets Manager by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances. Set up Lambda to use the new role for execution.\n"
        ],
        "Answers": [
            "Store the database credentials in AWS Key Management Service (AWS KMS). Create an IAM role with access to AWS KMS by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances. Set up Lambda to use the new role for execution.\n",
            "Store the database credentials in AWS KMS. Create an IAM role with access to KMS by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances and the Lambda function.\n",
            "Store the database credentials in AWS Secrets Manager. Create an IAM role with access to Secrets Manager by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances and the Lambda function.\n",
            "Store the database credentials in AWS Secrets Manager. Create an IAM role with access to Secrets Manager by using the EC2 and Lambda service principals in the role`s trust policy. Add the role to an EC2 instance profile. Attach the instance profile to the EC2 instances. Set up Lambda to use the new role for execution.\n"
        ],
        "Question": "An organization wants to deploy a three-tier web application whereby the application servers run on Amazon EC2 instances. These EC2 instances need access to credentials that they will use to authenticate their SQL connections to an Amazon RDS DB instance. Also, AWS Lambda functions must issue queries to the RDS database by using the same database credentials. The credentials must be stored so that the EC2 instances and the Lambda functions can access them. No other access is allowed. The access logs must record when the credentials were accessed and by whom. What should the Security Engineer do to meet these requirements?\n",
        "id": 204
    },
    {
        "Correct": [
            "Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the proper API key. Launch each Amazon EC2 instance with the proper IAM role.\n"
        ],
        "Answers": [
            "Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM user with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the API key for the environment. Store an access key for that user in a credential store on each Amazon EC2 instance.\n",
            "Create an AWS Systems Manager Parameter Store secure string for each API key. Encrypt the secure strings using a customer-managed AWS KMS customer master key (CMK). Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the ssm:getparameter action for the proper API key. Launch each Amazon EC2 instance with the proper IAM role.\n",
            "Create an Amazon DynamoDB table encrypted with an AWS KMS customer master key (CMK). Store each API key in a different item in the table. Create an IAM role for each environment with permissions to the kms:decrypt action for the CMK and the dynamodb:getitem action for the correct item. Launch each Amazon EC2 instance with the proper IAM role.\n",
            "Pass the proper API key to each Amazon EC2 instance upon launch utilizing user data. Assign an IAM role to each EC2 instance with permissions to the kms:encrypt and the kms:decrypt actions for a customer-managed AWS KMS customer master key (CMK). In the user data script, encrypt the API key using the CMK. Store the encrypted API key on each EC2 instance.\n"
        ],
        "Question": "A company is migrating an application from its data center to AWS. The application currently stores an API key used to access a third-party service in a local file. When deployed on AWS, the application will run on Amazon EC2 instances. As part of the migration, the application must make the API key more secure. Specifically: Each environment (such as development, test, and production) must have its own API key. All API key access requests should be logged for auditing purposes. The API keys must be encrypted at rest using a customer-managed key. Access permissions must be granular; the development environment cannot access the production API key, for example. What is the MOST secure way to meet these requirements?\n",
        "id": 205
    },
    {
        "Correct": [
            "Outbound; Protocol tcp; Destination 169.254.169.254; Destination port 80\n"
        ],
        "Answers": [
            "Inbound; Protocol tcp; Source [Instance`s EIP]; Destination 169.254.169.254\n",
            "Inbound; Protocol tcp; Destination 169.254.169.254; Destination port 80\n",
            "Outbound; Protocol tcp; Destination 169.254.169.254; Destination port 80\n",
            "Outbound; Protocol tcp; Destination 169 .254.169.254; Destination port 443\n"
        ],
        "Question": "Your security team implements a host-based firewall on all of your Amazon Elastic Compute Cloud (EC2) instances to block all outgoing traffic. Exceptions must be requested for each specific requirement. Until you request a new rule, you cannot access the instance metadata service. Which firewall rule should you request to be added to your instances to allow instance metadata access?\n",
        "id": 206
    },
    {
        "Correct": [
            "Configure CloudFront to use a custom header and configure an AWS WAF rule on the origin`s Application Load Balancer to accept only traffic that contains that header.\n"
        ],
        "Answers": [
            "Use an IP whitelist rule in AWS WAF within CloudFront to ensure that only known client IPs are able to access the application.\n",
            "Configure CloudFront to use a custom header and configure an AWS WAF rule on the origin`s Application Load Balancer to accept only traffic that contains that header.\n",
            "Configure an AWS Lambda@Edge function to validate that the traffic to the Application Load Balancer originates from CloudFront.\n",
            "Attach an origin access identity to the CloudFront origin that allows traffic to the origin that originates from only CloudFront.\n"
        ],
        "Question": "A Network Engineer is designing a new system on AWS that will take advantage of Amazon CloudFront for both content caching and for protecting the underlying origin. There is concern that an external agency might be able to access the IP addresses for the application`s origin and then attack the origin despite it being served by CloudFront. Which of the following solutions provides the strongest level of protection to the origin?\n",
        "id": 207
    },
    {
        "Correct": [
            "Use an API Gateway custom authorizer to invoke an AWS Lambda function to validate each user`s identity.\n"
        ],
        "Answers": [
            "Use AWS IAM authorization and add least-privileged permissions to each respective IAM role\n",
            "Use an API Gateway custom authorizer to invoke an AWS Lambda function to validate each user`s identity.\n",
            "Use Amazon Cognito user pools to provide built-in user management\n",
            "Use Amazon Cognito user pools to integrate with external identity providers.\n"
        ],
        "Question": "As part of securing an API layer built on Amazon API Gateway, a Solutions Architect has to authorize users who are currently authenticated by an existing identity provider. The users must be denied access for a period of one hour after these unsuccessful attempts. How can the authentication be implemented?\n",
        "id": 208
    },
    {
        "Correct": [
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to encrypt and decrypt customer data.\n"
        ],
        "Answers": [
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to decrypt the customer data, and the master keys are used to encrypt the customer data.\n",
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to encrypt the customer data and the master keys are used to decrypt the customer data.\n",
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The master keys are then used to encrypt and decrypt customer data.\n",
            "AWS KMS supports two kinds of keys _ master keys and data keys. Master keys can be used to directly encrypt and decrypt up to 4 KiB of data and can also be used to protect data keys. The data keys are then used to encrypt and decrypt customer data.\n"
        ],
        "Question": "Once again your security officer is on your case and this time is asking you to make sure the AWS Key Management Service (AWS KMS) is working as it is supposed to. You are initially not too sure how KMS even works, however after some intense late night reading you think you have come up with a reasonable definition. Which of the following best describes how the AWS Key Management Service works? Choose the correct answer:\n",
        "id": 209
    },
    {
        "Correct": [
            "Add the Elastic IP addresses of the Security team`s EC2 instances to a trusted IP list in Amazon GuardDuty.\n"
        ],
        "Answers": [
            "Use a filter in AWS CloudTrail to exclude the IP addresses of the Security team`s EC2 instances.\n",
            "Add the Elastic IP addresses of the Security team`s EC2 instances to a trusted IP list in Amazon GuardDuty.\n",
            "Install the Amazon Inspector agent on the EC2 instances that the Security team uses.\n",
            "Grant the Security team`s EC2 instances a role with permissions to call Amazon GuardDuty API operations.\n"
        ],
        "Question": "An organization wants to be alerted when an unauthorized Amazon EC2 instance in its VPC performs a network port scan against other instances in the VPWhen the Security team performs its own internal tests in a separate account by using pre-approved third-party scanners from the AWS Marketplace, the Security team also then receives multiple Amazon GuardDuty events from Amazon CloudWatch alerting on its test activities. How can the Security team suppress alerts about authorized security tests while still receiving alerts about the unauthorized activity?\n",
        "id": 210
    },
    {
        "Correct": [
            "Use Amazon Cognito user pools and a custom authorizer to authenticate and authorize users based on JSON Web Tokens.\n"
        ],
        "Answers": [
            "Use Amazon Cognito user pools and a custom authorizer to authenticate and authorize users based on JSON Web Tokens.\n",
            "Build an OpenID token broker with Amazon and Facebook. Users will authenticate with these identify providers and pass the JSON Web Token to the API to authenticate each API call.\n",
            "Store user credentials in Amazon DynamoDB and have the application retrieve temporary credentials from AWS STS. Make API calls by passing user credentials to the APIs for authentication and authorization.\n",
            "Use Amazon RDS to store user credentials and pass them to the APIs for authentications and authorization.\n"
        ],
        "Question": "A company developed a set of APIs that are being served through the Amazon API Gateway. The API calls need to be authenticated based on OpenID identity providers such as Amazon or Facebook. The APIs should allow access based on a custom authorization model. Which is the simplest and MOST secure design to use to build an authentication and authorization model for the APIs?\n",
        "id": 211
    },
    {
        "Correct": [
            "Design network security in a single layer within the perimeter network (also known as DMZ, demilitarized zone, and screened subnet) to facilitate quicker responses to threats.\n"
        ],
        "Answers": [
            "Use security groups to provide stateful firewalls for Amazon EC2 instances at the hypervisor level.\n",
            "Use network ACLs to provide stateful firewalls at the VPC level to prevent access to any specific AWS resource.\n",
            "Use AWS Direct Connect for secure trusted connections between EC2 instances within private subnets.\n",
            "Design network security in a single layer within the perimeter network (also known as DMZ, demilitarized zone, and screened subnet) to facilitate quicker responses to threats.\n"
        ],
        "Question": "Which of the following minimizes the potential attack surface for applications?\n",
        "id": 212
    },
    {
        "Correct": [
            "Create an IAM role for EC2 that allows list access to objects in the S3 bucket. Launch the instance with the role, and retrieve the role`s credentials from the EC2 Instance metadata\n"
        ],
        "Answers": [
            "Use the AWS account access keys the application retrieves the credentials from the source code of the application.\n",
            "Create a IAM user for the application with permissions that allow list access to the S3 bucket launch the instance as the IAM user and retrieve the IAM user`s credentials from the EC2 instance user data.\n",
            "Create an IAM role for EC2 that allows list access to objects in the S3 bucket. Launch the instance with the role, and retrieve the role`s credentials from the EC2 Instance metadata\n",
            "Create an IAM user for the application with permissions that allow list access to the S3 bucket. The application retrieves the IAM user credentials from a temporary directory with permissions that allow read access only to the application user.\n"
        ],
        "Question": "You have an application running on an EC2 Instance, which will allow users to download files from a private S3 bucket using a pre-signed URL. Before generating the URL the application should verify the existence of the file in S3. How should the application use AWS credentials to access the S3 bucket securely?\n",
        "id": 213
    },
    {
        "Correct": [
            "Use AWS Certificate Manager to provision a certificate on an Elastic Load Balancing in front of the web service`s servers.\n"
        ],
        "Answers": [
            "Upload an SSL certificate to IAM, and configure Amazon CloudFront with the passphrase for the private key.\n",
            "Call KMS.Encrypt() in the client, passing in the data file contents, and call KMS.Decrypt() server-side.\n",
            "Use AWS Certificate Manager to provision a certificate on an Elastic Load Balancing in front of the web service`s servers.\n",
            "Create a new VPC with an Amazon VPC VPN endpoint, and update the web service`s DNS record.\n"
        ],
        "Question": "An organization has a system in AWS that allows a large number of remote workers to submit data files. File sizes vary from a few kilobytes to several megabytes. A recent audit highlighted a concern that data files are not encrypted while in transit over untrusted networks. Which solution would remediate the audit finding while minimizing the effort required?\n",
        "id": 214
    },
    {
        "Correct": [
            "Enable Encryption during the DynamoDB table creation\n"
        ],
        "Answers": [
            "Enable Encryption during the DynamoDB table creation\n",
            "Enable Encryption on the existing table\n",
            "DynamoDB does not support encryption at rest, use AWS RDS service instead\n",
            "DynamoDB does not support encryption at rest, use AWS Redshift service instead\n"
        ],
        "Question": "Your company is going to develop an application in .Net Core which is going to store the data in a DynamoDB table. Security team mandates that all the data needs to be encrypted at rest. How can you achieve this?\n",
        "id": 215
    },
    {
        "Correct": [
            "An outbound rule must be added to the network ACL to allow the response to be sent to the client on the ephemeral port range.\n"
        ],
        "Answers": [
            "The outbound rules on the security group do not allow the response to be sent to the client on the ephemeral port range.\n",
            "The outbound rules on the security group do not allow the response to be sent to the client on the HTTP port.\n",
            "An outbound rule must be added to the network ACL to allow the response to be sent to the client on the ephemeral port range.\n",
            "An outbound rule must be added to the network ACL to allow the response to be sent to the client on the HTTP port.\n"
        ],
        "Question": "A Software Engineer is trying to figure out why network connectivity to an Amazon EC2 instance does not appear to be working correctly. Its security group allows inbound HTTP traffic from 0.0.0.0/0, and the outbound rules have not been modified from the default. A custom network ACL associated with its subnet allows inbound HTTP traffic from 0.0.0.0/0 and has no outbound rules.What would resolve the connectivity issue?\n",
        "id": 216
    },
    {
        "Correct": [
            "Create an IAM role with the proper permission policy to communicate with the DynamoDB table. Use web identity federation, which assumes the IAM role using AssumeRoleWithWebldentity, when the user signs in, granting temporary security credentials using STS.\n"
        ],
        "Answers": [
            "During the install and game configuration process, have each user create an IAM credential and assign the IAM user to a group with proper permissions to communicate with DynamoDB.\n",
            "Create an IAM group that only gives access to your application and to the DynamoDB tables. Then, when writing to DynamoDB, simply include the unique device ID to associate the data with that specific user.\n",
            "Create an IAM role with the proper permission policy to communicate with the DynamoDB table. Use web identity federation, which assumes the IAM role using AssumeRoleWithWebldentity, when the user signs in, granting temporary security credentials using STS.\n",
            "Create an Active Directory server and an AD user for each mobile application user. When the user signs in to the AD sign-on, allow the AD server to federate using SAML 2.0 to IAM and assign a role to the AD user which is the assumed with AssumeRoleWithSAML.\n"
        ],
        "Question": "You're building a mobile application game. The application needs permissions for each user to communicate and store data in DynamoDB tables. What is the best method for granting each mobile device that installs your application to access DynamoDB tables for storage when required? Choose the correct answer from the options below\n",
        "id": 217
    },
    {
        "Correct": [
            "Associate an origin access identity with the CloudFront distribution.\n",
            "Modify the S3 bucket permissions so that only the origin access identity can access the bucket contents.\n"
        ],
        "Answers": [
            "Associate an origin access identity with the CloudFront distribution.\n",
            "Implement a \"Principal\": \"cloudfront.amazonaws.com\" condition in the S3 bucket policy.\n",
            "Modify the S3 bucket permissions so that only the origin access identity can access the bucket contents.\n",
            "Implement security groups so that the S3 bucket can be accessed only by using the intended CloudFront distribution.\n",
            "Configure the S3 bucket policy so that it is accessible only through VPC endpoints, and place the CloudFront distribution into the specified VPC.\n"
        ],
        "Question": "A Security Administrator has a website hosted in Amazon S3. The Administrator has been given the following requirements: Users may access the website by using an Amazon CloudFront distribution. Users may not access the website directly by using an Amazon S3 URL. Which configurations will support these requirements? (Choose two.)\n",
        "id": 218
    },
    {
        "Correct": [
            "Store the data in S3 with Server Side Encryption. Launch an encrypted Redshift cluster and copy the data to the cluster.\n"
        ],
        "Answers": [
            "Store the data in S3 with Server Side Encryption and copy the data over to Redshift cluster\n",
            "Store the data in S3. Launch an encrypted Redshift cluster, copy the data to the Redshift cluster and store back in S3 in encrypted format\n",
            "Store the data in S3 with Server Side Encryption. Launch an encrypted Redshift cluster and copy the data to the cluster.\n",
            "Store the data in S3 with Server Side Encryption. Launch a Redshift cluster, copy the data to cluster and enable encryption on the cluster.\n"
        ],
        "Question": "A company wants to use Redshift cluster for petabyte-scale data warehousing. Data for processing would be stored on Amazon S3. As a security requirement, the company wants the data to be encrypted at rest. As a solution architect how would you implement the solution?\n",
        "id": 219
    },
    {
        "Correct": [
            "Using AWS Config, create a config rule that detects when AWS CloudTrail is disabled, as well as any calls to the root user create-api-key. Then use a Lambda function to re-enable CloudTrail logs and deactivate the root API keys.\n"
        ],
        "Answers": [
            "Using Amazon Inspector, review all of the API calls and configure the inspector agent to leverage SNS topics to notify security of the change to AWS CloudTrail, and revoke the new API keys for the root user.\n",
            "Using AWS Config, create a config rule that detects when AWS CloudTrail is disabled, as well as any calls to the root user create-api-key. Then use a Lambda function to re-enable CloudTrail logs and deactivate the root API keys.\n",
            "Using Amazon CloudWatch, create a CloudWatch event that detects AWS CloudTrail deactivation and a separate Amazon Trusted Advisor check to automatically detect the creation of root API keys. Then use a Lambda function to enable AWS CloudTrail and deactivate the root API keys.\n",
            "Using Amazon CloudTrail, create a new CloudTrail event that detects the deactivation of CloudTrail logs, and a separate CloudTrail event that detects the creation of root API keys. Then use a Lambda function to enable CloudTrail and deactivate the root API keys.\n"
        ],
        "Question": "During a recent internal investigation, it was discovered that all API logging was disabled in a production account, and the root user had created new API keys that appear to have been used several times.What could have been done to detect and automatically remediate the incident?\n",
        "id": 220
    },
    {
        "Correct": [
            "Analyze AWS CloudTrail for activity.\n",
            "Download and analyze a credential report from IAM.\n"
        ],
        "Answers": [
            "Analyze AWS CloudTrail for activity.\n",
            "Analyze Amazon CloudWatch Logs for activity.\n",
            "Download and analyze the IAM Use report from AWS Trusted Advisor.\n",
            "Analyze the resource inventory in AWS Config for IAM user activity.\n",
            "Download and analyze a credential report from IAM.\n"
        ],
        "Question": "An employee accidentally exposed an AWS access key and secret access key during a public presentation. The company Security Engineer immediately disabled the key. How can the Engineer assess the impact of the key exposure and ensure that the credentials were not misused? (Choose two.)\n",
        "id": 221
    },
    {
        "Correct": [
            "Create EBS Snapshots of each of the volumes attached to the compromised instances.\n",
            "Capture a memory dump.\n",
            "Revoke all network ingress and egress except for to/from a forensics.\n"
        ],
        "Answers": [
            "Use AWS Artifact to capture an exact image of the state of each instance.\n",
            "Create EBS Snapshots of each of the volumes attached to the compromised instances.\n",
            "Capture a memory dump.\n",
            "Log in to each instance with administrative credentials to restart the instance.\n",
            "Revoke all network ingress and egress except for to/from a forensics.\n",
            "Run Auto Recovery for Amazon EC2.\n"
        ],
        "Question": "A Security Engineer received an AWS Abuse Notice listing EC2 instance IDs that are reportedly abusing other hosts.Which action should the Engineer take based on this situation? (Choose three.)\n",
        "id": 222
    },
    {
        "Correct": [
            "Change the resource section to \"arn:aws:s3:::appbucket/*\".\n"
        ],
        "Answers": [
            "Change the IAM permissions by applying PutBucketPolicy permissions.\n",
            "Verify that the policy has the same name as the bucket name. If not, make it the same.\n",
            "Change the resource section to \"arn:aws:s3:::appbucket/*\".\n",
            "Add an s3:ListBucket action.\n"
        ],
        "Question": "A company is hosting a web application on AWS and is using an Amazon S3 bucket to store images. Users should have the ability to read objects in the bucket. A Security Engineer has written the following bucket policy to grant public read access:{ \"ID\":\"Policy1502987489630\", \"Version\":\"2012-10-17\", \"Statement\":[ { \"Sid\":\"Stmt1502987487640\", \"Action\":[ \"s3:GetObject\", \"s3:GetObjectVersion\" ], \"Effect\":\"Allow\", \"Resource\":\"arn:aws:s3:::appbucket\", \"Principal\":\"*\" } ] } Attempts to read an object, however, receive the error: \"Action does not apply to any resource(s) in statement.\" What should the Engineer do to fix the error?\n",
        "id": 223
    },
    {
        "Correct": [
            "Use Amazon S3 server-side encryption with AWS Key Management Service managed keys.\n",
            "Use Amazon S3 server-side encryption with customer-provided keys\n",
            "Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key\n"
        ],
        "Answers": [
            "Use Amazon S3 server-side encryption with AWS Key Management Service managed keys.\n",
            "Use Amazon S3 server-side encryption with customer-provided keys\n",
            "Use Amazon S3 server-side encryption with EC2 key pair.\n",
            "Use Amazon S3 bucket policies to restrict access to the data at rest.\n",
            "Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key\n",
            "Use SSL to encrypt the data while in transit to Amazon S3.\n"
        ],
        "Question": "A company is storing data on Amazon Simple Storage Service (S3). The company`s security policy mandates that data be encrypted at rest. Which of the following methods can achieve this? Choose 3 answers\n",
        "id": 224
    },
    {
        "Correct": [
            "Use AWS Config to review the IAM policy assigned to users before and after the incident.\n"
        ],
        "Answers": [
            "Use AWS Config to review the IAM policy assigned to users before and after the incident.\n",
            "Run the GenerateCredentialReport via the AWS CLI, and copy the output to Amazon S3 daily for auditing purposes.\n",
            "Copy AWS CloudFormation templates to S3, and audit for changes from the template.\n",
            "Use Amazon EC2 Systems Manager to deploy images, and review AWS CloudTrail logs for changes.\n"
        ],
        "Question": "A Security Engineer must design a solution that enables the incident Response team to audit for changes to a user`s IAM permissions in the case of a security incident. How can this be accomplished?\n",
        "id": 225
    },
    {
        "Correct": [
            "Use Amazon CloudWatch logs with two log groups, one for each application, and use an AWS IAM policy to control access to the log groups as required.\n"
        ],
        "Answers": [
            "Aggregate logs into one file, then use Amazon CloudWatch Logs and then design two CloudWatch metric filters to filter sensitive data from the logs.\n",
            "Use Amazon CloudWatch logs to capture all logs, write an AWS Lambda function that parses the log file, and move sensitive data to a different log.\n",
            "Add logic to the application that saves sensitive data logs on the Amazon EC2 instances' local storage, and write a batch script that logs into the EC2 instances and moves sensitive logs to a secure location.\n",
            "Use Amazon CloudWatch logs with two log groups, one for each application, and use an AWS IAM policy to control access to the log groups as required.\n"
        ],
        "Question": "Your application development team is building a solution with two applications. The security team wants each application's logs to be captured in two different places because one of the applications produces logs with sensitive data. How can you meet the requirements with the least risk and effort?\n",
        "id": 226
    },
    {
        "Correct": [
            "Create a new CMK, import new key material to it, and point the key alias to the new CMK.\n"
        ],
        "Answers": [
            "Enable automatic key rotation annually for the CMK.\n",
            "Use AWS Command Line interface to create an AWS Lambda function to rotate the existing CMK annually.\n",
            "Import new key material to the existing CMK and manually rotate the CMK.\n",
            "Create a new CMK, import new key material to it, and point the key alias to the new CMK.\n"
        ],
        "Question": "A company has a customer master key (CMK) with imported key materials. Company policy requires that all encryption keys must be rotated every year. What can be done to implement the above policy?\n",
        "id": 227
    },
    {
        "Correct": [
            "Digitized files -> Amazon Kinesis Data Streams -> Kinesis Client Library consumer -> Amazon S3 -> Athena\n"
        ],
        "Answers": [
            "Digitized files -> Amazon Kinesis Data Analytics\n",
            "Digitized files -> Amazon Kinesis Data Firehose -> Amazon S3 -> Amazon Athena\n",
            "Digitized files -> Amazon Kinesis Data Streams -> Kinesis Client Library consumer -> Amazon S3 -> Athena\n",
            "Digitized files -> Amazon Kinesis Data Firehose -> Amazon Elasticsearch\n"
        ],
        "Question": "A pharmaceutical company has digitized versions of historical prescriptions stored on premises. The company would like to move these prescriptions to AWS and perform analytics on the data in them. Any operation with this data requires that the data be encrypted in transit and at rest. Which application flow would meet the data protection requirements on AWS?\n",
        "id": 228
    },
    {
        "Correct": [
            "Install and configure the Amazon CloudWatch Logs agent on the application`s EC2 instance. Create a CloudWatch metric filter to monitor the application logs. Set up CloudWatch alerts based on the metrics.\n"
        ],
        "Answers": [
            "Create a scheduled process to copy the component`s logs into Amazon S3. Use S3 events to trigger a Lambda function that updates Amazon CloudWatch metrics with the log data. Set up CloudWatch alerts based on the metrics.\n",
            "Install and configure the Amazon CloudWatch Logs agent on the application`s EC2 instance. Create a CloudWatch metric filter to monitor the application logs. Set up CloudWatch alerts based on the metrics.\n",
            "Create a scheduled process to copy the application log files to AWS CloudTrail. Use S3 events to trigger Lambda functions that update CloudWatch metrics with the log data. Set up CloudWatch alerts based on the metrics.\n",
            "Create a file watcher that copies data to Amazon Kinesis when the application writes to the log file. Have Kinesis trigger a Lambda function to update Amazon CloudWatch metrics with the log data. Set up CloudWatch alerts based on the metrics.\n"
        ],
        "Question": "An application outputs logs to a text file. The logs must be continuously monitored for security incidents.Which design will meet the requirements with MINIMUM effort?\n",
        "id": 229
    },
    {
        "Correct": [
            "Install the Amazon CloudWatch Logs Agent on the EC2 instances, and configure it to send the application logs to CloudWatch Logs.\n"
        ],
        "Answers": [
            "Write an AWS Lambda function that logs into the EC2 instance to pull the application logs from the EC2 instance and persists them into an Amazon S3 bucket.\n",
            "Enable AWS CloudTrail logging for the AWS account, create a new Amazon S3 bucket, and then configure Amazon CloudWatch Logs to receive the application logs from CloudTrail.\n",
            "Create a simple cron job on the EC2 instances that synchronizes the application logs to an Amazon S3 bucket by using rsync.\n",
            "Install the Amazon CloudWatch Logs Agent on the EC2 instances, and configure it to send the application logs to CloudWatch Logs.\n"
        ],
        "Question": "A Software Engineer wrote a customized reporting service that will run on a fleet of Amazon EC2 instances. The company security policy states that application logs for the reporting service must be centrally collected.What is the MOST efficient way to meet these requirements?\n",
        "id": 230
    },
    {
        "Correct": [
            "Enable Amazon Macie on the S3 buckets that were impacted, then perform data classification. For identified objects that contain PII, use the research function for auditing AWS CloudTrail logs and S3 bucket logs for GET operations.\n"
        ],
        "Answers": [
            "Using Amazon Athena, query the impacted S3 buckets by using the PII query identifier function. Then, create a new Amazon CloudWatch metric for Amazon S3 object access to alert when the objects are accessed.\n",
            "Enable Amazon Macie on the S3 buckets that were impacted, then perform data classification. For identified objects that contain PII, use the research function for auditing AWS CloudTrail logs and S3 bucket logs for GET operations.\n",
            "Enable Amazon GuardDuty and enable the PII rule set on the S3 buckets that were impacted, then perform data classification. Using the PII findings report from GuardDuty, query the S3 bucket logs by using Athena for GET operations.\n",
            "Enable Amazon Inspector on the S3 buckets that were impacted, then perform data classification. For identified objects that contain PII, query the S3 bucket logs by using Athena for GET operations.\n"
        ],
        "Question": "During a recent security audit, it was discovered that multiple teams in a large organization have placed restricted data in multiple Amazon S3 buckets, and the data may have been exposed. The auditor has requested that the organization identify all possible objects that contain personally identifiable information (PII) and then determine whether this information has been accessed. What solution will allow the Security team to complete this request?\n",
        "id": 231
    },
    {
        "Correct": [
            "kms:CreateGrant\n",
            "\"Condition\": { \"Bool\": { \"kms:GrantIsForAWSResource\": true }\n"
        ],
        "Answers": [
            "kms:GenerateDataKey\n",
            "kms:Decrypt\n",
            "kms:CreateGrant\n",
            "\"Condition\": { \"Bool\": { \"kms:ViaService\": \"ec2.us-west-2.amazonaws.com\" } }\n",
            "\"Condition\": { \"Bool\": { \"kms:GrantIsForAWSResource\": true }\n"
        ],
        "Question": "An IAM user with full EC2 permissions could not start an Amazon EC2 instance after it was stopped for a maintenance task. Upon starting the instance, the instance state would change to \"Pending\", but after a few seconds, it would switch back to \"Stopped\".An inspection revealed that the instance has attached Amazon EBS volumes that were encrypted by using a Customer Master Key (CMK). When these encrypted volumes were detached, the IAM user was able to start the EC2 instances.The IAM user policy is as follows:What additional items need to be added to the IAM user policy? (Choose two.)\n",
        "id": 232
    },
    {
        "Correct": [
            "Create an IAM Role and ensure the EC2 Instances use the IAM Role to access the data in the bucket.\n",
            "Configure S3 to use versioning and enable Multi-Factor Authentication (MFA) protected access\n"
        ],
        "Answers": [
            "Create an IAM user and ensure the EC2 Instances use the IAM user credentials to access the data in the bucket.\n",
            "Create an IAM Role and ensure the EC2 Instances use the IAM Role to access the data in the bucket.\n",
            "Use S3 Cross-Region Replication to replicate the objects so that the integrity of data is maintained.\n",
            "Use a S3 bucket policy that prevents accidental deletions\n",
            "Configure S3 to use versioning and enable Multi-Factor Authentication (MFA) protected access\n"
        ],
        "Question": "Your company has a set of EC2 Instances that access data objects stored in an S3 bucket. Your IT Security department is concerned about the security of this architecture and wants you to implement the following: 1) Ensure that the EC2 Instance securely accesses the data objects stored in the S3 bucket 2) Prevent accidental deletion of objects Which of the following would help fulfill the requirements of the IT Security department in a cost-effective way? Choose 2 answers\n",
        "id": 233
    },
    {
        "Correct": [
            "Configure the CloudTrail service in each AWS account and have the logs delivered to a single AWS bucket in the primary account and grant the auditor access to that single bucket in the primary account.\n"
        ],
        "Answers": [
            "Configure the CloudTrail service in each AWS account, and have the logs delivered to an AWS bucket on each account, while granting the auditor permissions to the bucket via roles in the secondary accounts and a single primary IAM account that can assume a read-only role in the secondary AWS accounts.\n",
            "Configure the CloudTrail service in the primary AWS account and configure consolidated billing for all the secondary accounts. Then grant the auditor access to the S3 bucket that receives the CloudTrail log files.\n",
            "Configure the CloudTrail service in each AWS account and enable consolidated logging inside of CloudTrail.\n",
            "Configure the CloudTrail service in each AWS account and have the logs delivered to a single AWS bucket in the primary account and grant the auditor access to that single bucket in the primary account.\n"
        ],
        "Question": "An auditor needs access to logs that record all API events on AWS. The auditor only needs read-only access to the log files and does not need access to each AWS account. The company has multiple AWS accounts, and the auditor needs access to all the logs for all the accounts. What is the best way to configure access for the auditor to view event logs from all accounts? Choose the correct answer from the options below\n",
        "id": 234
    },
    {
        "Correct": [
            "Create an IAM role with read-only permissions to all AWS services in each AWS account. Create one auditor IAM account and add a permissions policy that allows the auditor to assume the ARN role for each AWS account that has an assigned role.\n"
        ],
        "Answers": [
            "Create an IAM user for each AWS account with read-only permission policies for the auditor, and disable each account when the audit is complete.\n",
            "Configure an on-premise AD server and enable SAML and identify federation for single sign-on to each AWS account.\n",
            "Create an IAM role with read-only permissions to all AWS services in each AWS account. Create one auditor IAM account and add a permissions policy that allows the auditor to assume the ARN role for each AWS account that has an assigned role.\n",
            "Create a custom identity broker application that allows the auditor to use existing Amazon credentials to Log into the AWS environments.\n"
        ],
        "Question": "A third party auditor is being brought in to review security processes and configurations for all of a company's AWS accounts. Currently, the company does not use any on-premise identity provider. Instead, they rely on IAM accounts in each of their AWS accounts. The auditor needs read-only access to all AWS resources for each AWS account. Given the requirements, what is the best security method for architecting access for the security auditor? Choose the correct answer from the options below\n",
        "id": 235
    },
    {
        "Correct": [
            "Enable AWS CloudTrail logging across all accounts to a centralized Amazon S3 bucket. Set a lifecycle policy to move the data to Amazon Glacier after 90 days, and expire the data after 7 years.\n"
        ],
        "Answers": [
            "Enable AWS CloudTrail logging across all accounts to a centralized Amazon S3 bucket with versioning enabled. Set a lifecycle policy to move the data to Amazon Glacier daily, and expire the data after 90 days.\n",
            "Enable AWS CloudTrail logging across all accounts to S3 buckets. Set a lifecycle policy to expire the data in each bucket after 7 years.\n",
            "Enable AWS CloudTrail logging across all accounts to Amazon Glacier. Set a lifecycle policy to expire the data after 7 years.\n",
            "Enable AWS CloudTrail logging across all accounts to a centralized Amazon S3 bucket. Set a lifecycle policy to move the data to Amazon Glacier after 90 days, and expire the data after 7 years.\n"
        ],
        "Question": "A Security Engineer must ensure that all API calls are collected across all company accounts, and that they are preserved online and are instantly available for analysis for 90 days. For compliance reasons, this data must be restorable for 7 years.Which steps must be taken to meet the retention needs in a scalable, cost-effective way?\n",
        "id": 236
    },
    {
        "Correct": [
            "Use AWS Artifact to access AWS compliance reports.\n"
        ],
        "Answers": [
            "Read the AWS Customer Agreement.\n",
            "Use AWS Artifact to access AWS compliance reports.\n",
            "Post the question on the AWS Discussion Forums.\n",
            "Run AWS Config and evaluate the configuration outputs.\n"
        ],
        "Question": "A Security Engineer is trying to determine whether the encryption keys used in an AWS service are in compliance with certain regulatory standards.Which of the following actions should the Engineer perform to get further guidance?\n",
        "id": 237
    },
    {
        "Correct": [
            "The Lambda function does not have permissions to access the CloudTrail S3 bucket.\n"
        ],
        "Answers": [
            "The Lambda function does not have permissions to start the Athena query execution.\n",
            "The Security Engineer does not have permissions to start the Athena query execution.\n",
            "The Athena service does not support invocation through Lambda.\n",
            "The Lambda function does not have permissions to access the CloudTrail S3 bucket.\n"
        ],
        "Question": "A Security Engineer has created an Amazon CloudWatch event that invokes an AWS Lambda function daily. The Lambda function runs an Amazon Athena query that checks AWS CloudTrail logs in Amazon S3 to detect whether any IAM user accounts or credentials have been created in the past 30 days. The results of the Athena query are created in the same S3 bucket. The Engineer runs a test execution of the Lambda function via the AWS Console, and the function runs successfully. After several minutes, the Engineer finds that his Athena query has failed with the error message: \"Insufficient Permissions\". The IAM permissions of the Security Engineer and the Lambda function are shown below:Security Engineer{ \"Version\": \"2012-10-17\", \"Statement\": [{ \"Effect\": \"Allow\", \"Action\": [ \"s3:*\", \"iam:*\", \"lambda:*\", \"athena:Get*\", \"athena:List*\", \"cloudwatch:*\" ], \"Resource\": \"*\" }] } Lambda function execution role{ \"Version\": \"2012_10-17\", \"Statement\": [{ \"Effect\": \"Action\", \"Allow\": [ \"athena:*\", \"cloudwatch:*\" ], \"Resource\": \"*\" }] } What is causing the error?\n",
        "id": 238
    },
    {
        "Correct": [
            "Enable the CloudTrail file integrity feature on the trail. Use the digest file created by CloudTrail to verify the integrity of the delivered CloudTrail files.\n"
        ],
        "Answers": [
            "Create an Amazon CloudWatch Events rule that triggers an AWS Lambda function when a new file is delivered. Configure the Lambda function to perform an MD5 hash check on the file, store the name and location of the file, and post the returned hash to an Amazon DynamoDB table. The Security team can use the values stored in DynamoDB to verify the file authenticity.\n",
            "Enable the CloudTrail file integrity feature on an Amazon S3 bucket. Create an IAM policy that grants the Security team access to the file integrity logs stored in the S3 bucket.\n",
            "Enable the CloudTrail file integrity feature on the trail. Use the digest file created by CloudTrail to verify the integrity of the delivered CloudTrail files.\n",
            "Create an AWS Lambda function that is triggered each time a new file is delivered to the CloudTrail bucket. Configure the Lambda function to execute an MD5 hash check on the file, and store the result on a tag in an Amazon S3 object. The Security team can use the information on the tag to verify the integrity of the file.\n"
        ],
        "Question": "Security team wants to ensure that AWS CloudTrail files are not tampered with after being created. Currently, there is a process with multiple trails, using AWS IAM to restrict access to specific trails. The Security team wants to ensure they can trace the integrity of each file and make sure there has been no tampering. Which option will require the LEAST effort to implement and ensure the legitimacy of the file while allowing the Security team to prove the authenticity of the logs?\n",
        "id": 239
    },
    {
        "Correct": [
            "Enable VPC Flow Logs for the production VPC\n"
        ],
        "Answers": [
            "Enable CloudTrail for the production VPC\n",
            "Enable VPC Flow Logs for the production VPC\n",
            "Enable both CloudTrail and VPC Flow Logs for the production VPC\n",
            "Enable both CloudTrail and VPC Flow Logs for the AWS account\n"
        ],
        "Question": "A customer`s security team requires the logging of all network access attempts to Amazon EC2 instances in their production VPC on AWS. Which configuration will meet the security team`s requirement?\n",
        "id": 240
    },
    {
        "Correct": [
            "Call the abort-vault-lock operation, fix the typo, and call the initiate-vault-lock again.\n"
        ],
        "Answers": [
            "Call the abort-vault-lock operation, fix the typo, and call the initiate-vault-lock again.\n",
            "Copy the vault data to Amazon S3, delete the vault, and create a new vault with the data.\n",
            "Update the policy, keeping the vault lock in place.\n",
            "Update the policy and call initiate-vault-lock again to apply the new policy.\n"
        ],
        "Question": "The Security Engineer implemented a new vault lock policy for 10TB of data and called initiate-vault-lock 12 hours ago. The Audit team identified a typo that is allowing incorrect access to the vault.What is the MOST cost-effective way to correct this?\n",
        "id": 241
    },
    {
        "Correct": [
            "One in the US West (Oregon) region and one in the US East (Virginia) region.\n"
        ],
        "Answers": [
            "One in the US West (Oregon) region and one in the US East (Virginia) region.\n",
            "Two in the US West (Oregon) region and none in the US East (Virginia) region.\n",
            "One in the US West (Oregon) region and none in the US East (Virginia) region.\n",
            "Two in the US West (Virginia) region and none in the US West (Oregon) region.\n"
        ],
        "Question": "A Solutions Architect is designing a web application that uses Amazon CloudFront, an Elastic Load Balancing Application Load Balancer, and an Auto Scaling group of Amazon EC2 instances. The load balancer and EC2 instances are in the US West (Oregon) region. It has been decided that encryption in transit is necessary by using a customer-branded domain name from the client to CloudFront and from CloudFront to the load balancer. Assuming that AWS Certificate Manager is used, how many certificates will need to be generated?\n",
        "id": 242
    },
    {
        "Correct": [
            "Ensure CloudTrail is enabled. Create a user account for the Auditor and attach the AWSCloudTrailReadOnlyAccess Policy to the user.\n"
        ],
        "Answers": [
            "Enable S3 and ELB logs. Send the logs as a zip file to the IT Auditor.\n",
            "Ensure CloudTrail is enabled. Create a user account for the Auditor and attach the AWSCloudTrailReadOnlyAccess Policy to the user.\n",
            "Ensure that CloudTrail is enabled. Create a user for the IT Auditor and ensure that full control is given to the user for CloudTrail.\n",
            "Enable CloudWatch logs. Create a user for the IT Auditor and ensure that full control is given to the user for the CloudWatch logs.\n"
        ],
        "Question": "A Customer wants to perform an audit to track access to all the AWS resources. Which of the following steps will ensure that the auditor has the right access to the logs of your AWS account?\n",
        "id": 243
    },
    {
        "Correct": [
            "Use AWS Systems Manager to store the credentials as Secure Strings Parameters. Secure by using an AWS KMS key.\n"
        ],
        "Answers": [
            "Use AWS Systems Manager to store the credentials as Secure Strings Parameters. Secure by using an AWS KMS key.\n",
            "Use AWS Key Management System to store a master key, which is used to encrypt the credentials. The encrypted credentials are stored in an Amazon RDS instance.\n",
            "Use AWS Secrets Manager to store the credentials.\n",
            "Store the credentials in a JSON file on Amazon S3 with server-side encryption.\n"
        ],
        "Question": "A water utility company uses a number of Amazon EC2 instances to manage updates to a fleet of 2,000 Internet of Things (IoT) field devices that monitor water quality. These devices each have unique access credentials. An operational safety policy requires that access to specific credentials is independently auditable. What is the MOST cost-effective way to manage the storage of credentials?\n",
        "id": 244
    },
    {
        "Correct": [
            "Change the security policy on the ELB to disable vulnerable protocols and ciphers.\n"
        ],
        "Answers": [
            "Generate new SSL certificates for all web servers and replace current certificates.\n",
            "Change the security policy on the ELB to disable vulnerable protocols and ciphers.\n",
            "Generate new SSL certificates and use ELB to front-end the encrypted traffic for all web servers.\n",
            "Leverage your current configuration management system to update SSL policy on all web servers.\n"
        ],
        "Question": "Your organization runs a popular e-commerce application deployed on AWS that uses Auto Scaling in conjunction with an Elastic Load balancing (ELB) service with an HTTPS. Your security team reports that an exploitable vulnerability has been discovered in the encryption protocol and cipher that your site uses. Which step should you take to fix this problem?\n",
        "id": 245
    },
    {
        "Correct": [
            "Using security groups that reference the security groups of the other application.\n"
        ],
        "Answers": [
            "Using security groups that reference the security groups of the other application.\n",
            "Using security groups that reference the application servers IP address.\n",
            "Using Network Access Control Lists to allow/deny traffic based on application IP address.\n",
            "Migrating the applications to separate subnets from each other.\n"
        ],
        "Question": "Two Auto Scaling applications, Application A and Application B currently run within a shared set of subnets. A solution architect wants to make sure that Application A can make request to Application B, but Application B should be denied from making request to Application Which is the SIMPLEST solution to achieve this policy?\n",
        "id": 246
    },
    {
        "Correct": [
            "Manage encryption keys in amazon Key Management Service (KMS), upload to amazon simple storage service (s3) with client-side encryption using a KMS customer master key ID and configure Amazon S3 lifecycle policies to store each object using the amazon glacier storage tier.\n"
        ],
        "Answers": [
            "Manage encryption keys on-premise in an encrypted relational database. Set up an on-premises server with sufficient storage to temporarily store files and then upload them to Amazon S3, providing a client-side master key.\n",
            "Manage encryption keys in a Hardware Security Module (HSM) appliance on-premise server with sufficient storage to temporarily store, encrypt, and upload files directly into amazon Glacier.\n",
            "Manage encryption keys in amazon Key Management Service (KMS), upload to amazon simple storage service (s3) with client-side encryption using a KMS customer master key ID and configure Amazon S3 lifecycle policies to store each object using the amazon glacier storage tier.\n",
            "Manage encryption keys in an AWS CloudHSM appliance. Encrypt files prior to uploading on the employee desktop and then upload directly into amazon glacier\n"
        ],
        "Question": "You are designing a personal document-archiving solution for your global enterprise with thousands of employee. Each employee has potentially gigabytes of data to be backed up in this archiving solution. The solution will be exposed to the employees as an application, where they can just drag and drop their files to the archiving system. Employees can retrieve their archives through a web interface. The corporate network has high bandwidth AWS DirectConnect connectivity to AWS. You have regulatory requirements that all data needs to be encrypted before being uploaded to the cloud. How do you implement this in a highly available and cost efficient way?\n",
        "id": 247
    },
    {
        "Correct": [
            "Enable AWS Default Encryption\n"
        ],
        "Answers": [
            "Enable AWS Default Encryption\n",
            "Place the following statement in the IAM policy \"Statement\": [ { \"Sid\": \"Stmt1504640908907\", \"Effect\": \"Allow\", \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::/*\", \"Condition\": { \"Bool\": { \"aws:SecureTransport\": \"false\" } } } ]\n",
            "Place the following statement in the bucket policy\"Statement\": [ { \"Sid\": \"Stmt1504640908907\", \"Effect\": \"Allow\", \"Principal\": \"*\", \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::/*\", \"Condition\": { \"Bool\": { \"aws:SecureTransport\": \"false\" } } } ]\n",
            "Enable versioning for the buckets\n"
        ],
        "Question": "A company has a number of sensitive files available in an S3 bucket. The CIO is worried about the security of the documents in the bucket. As the Security lead, you have been instructed to increase the security for S3 bucket. How can you achieve this?\n",
        "id": 248
    },
    {
        "Correct": [
            "Create IAM roles with permissions corresponding to each Active Directory group.\n",
            "Configure Active Directory to add relying party trust between Active Directory and AWS.\n"
        ],
        "Answers": [
            "Create IAM roles with permissions corresponding to each Active Directory group.\n",
            "Create IAM groups with permissions corresponding to each Active Directory group.\n",
            "Configure Amazon Cloud Directory to support a SAML provider.\n",
            "Configure Active Directory to add relying party trust between Active Directory and AWS.\n",
            "Configure Amazon Cognito to add relying party trust between Active Directory and AWS.\n"
        ],
        "Question": "A company plans to move most of its IT infrastructure to AWS. They want to leverage their existing on-premises Active Directory as an identity provider for AWS.Which combination of steps should a Security Engineer take to federate the company`s on-premises Active Directory with AWS? (Choose two.)\n",
        "id": 249
    },
    {
        "Correct": [
            "Enable default encryption with server-side encryption with AWS KMS-managed keys (SSE-KMS) on the S3 bucket.\n",
            "Add a bucket policy that includes a deny if a PutObject request does not include aws:SecureTransport.\n"
        ],
        "Answers": [
            "Enable AES-256 encryption using server-side encryption with Amazon S3-managed encryption keys (SSE-S3) on the S3 bucket.\n",
            "Enable default encryption with server-side encryption with AWS KMS-managed keys (SSE-KMS) on the S3 bucket.\n",
            "Add a bucket policy that includes a deny if a PutObject request does not include aws:SecureTransport.\n",
            "Add a bucket policy with aws:SourceIp to allow uploads and downloads from the corporate intranet only.\n",
            "Enable Amazon Macie to monitor and act on changes to the data lake's S3 bucket.\n"
        ],
        "Question": "A company is building a data lake on Amazon S3. The data consists of millions of small files containing sensitive information. The Security team has the following requirements for the architecture: Data must be encrypted in transit. Data must be encrypted at rest. The bucket must be private, but if the bucket is accidentally made public, the data must remain confidential. Which combination of steps would meet the requirements? (Select TWO.)\n",
        "id": 250
    },
    {
        "Correct": [
            "Use CloudTrail Log File Integrity Validation.\n"
        ],
        "Answers": [
            "Use CloudTrail Log File Integrity Validation.\n",
            "Use AWS Config SNS Subscriptions and process events in real time.\n",
            "Use CloudTrail backed up to AWS S3 and Glacier.\n",
            "Use AWS Config Timeline forensics.\n"
        ],
        "Question": "Your CTO thinks your AWS account was hacked. What is the only way to know for certain if there was unauthorized access and what they did, assuming your hackers are very sophisticated AWS engineers and doing everything they can to cover their tracks?\n",
        "id": 251
    },
    {
        "Correct": [
            "Only principals from account 111122223333 that have an IAM policy applied that grants access to this key to use the key.\n"
        ],
        "Answers": [
            "All principals from all AWS accounts to use the key.\n",
            "Only the root user from account 111122223333 to use the key.\n",
            "All principals from account 111122223333 to use the key but only on Amazon S3.\n",
            "Only principals from account 111122223333 that have an IAM policy applied that grants access to this key to use the key.\n"
        ],
        "Question": "A Security Engineer who was reviewing AWS Key Management Service (AWS KMS) key policies found this statement in each key policy in the company AWS account. { \"Sid\": \"Enable IAM User Permissions\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::111122223333:root\" }, \"Action\": \"kms:*\", \"Resource\": \"*\" } What does the statement allow?\n",
        "id": 252
    },
    {
        "Correct": [
            "Verify which Security Group is applied to the particular web server`s elastic network interface (ENI).\n",
            "Verify the registered targets in the ALB.\n"
        ],
        "Answers": [
            "Verify that the 0.0.0.0/0 route in the route table for the web server subnet points to a NAT gateway.\n",
            "Verify which Security Group is applied to the particular web server`s elastic network interface (ENI).\n",
            "Verify that the 0.0.0.0/0 route in the route table for the web server subnet points to the virtual security appliance.\n",
            "Verify the registered targets in the ALB.\n",
            "Verify that the 0.0.0.0/0 route in the public subnet points to a NAT gateway\n"
        ],
        "Question": "A Security Engineer has been asked to troubleshoot inbound connectivity to a web server. This single web server is not receiving inbound connections from the internet, whereas all other web servers are functioning properly. The architecture includes network ACLs, security groups, and a virtual security appliance. In addition, the Development team has implemented Application Load Balancers (ALBs) to distribute the load across all web servers. It is a requirement that traffic between the web servers and the internet flow through the virtual security appliance. The Security Engineer has verified the following: The rule set in the Security Groups is correct The rule set in the network ACLs is correct The rule set in the virtual appliance is correct Which of the following are other valid items to troubleshoot in this scenario? (Choose two.)\n",
        "id": 253
    },
    {
        "Correct": [
            "Move the web servers to private subnets without public IP addresses.\n",
            "Configure AWS WAF to provide DDoS attack protection for the ALB.\n"
        ],
        "Answers": [
            "Configure the application`s EC2 instances to use NAT gateways for all inbound traffic.\n",
            "Move the web servers to private subnets without public IP addresses.\n",
            "Configure AWS WAF to provide DDoS attack protection for the ALB.\n",
            "Require all inbound network traffic to route through a bastion host in the private subnet.\n",
            "Require all inbound and outbound network traffic to route through an AWS Direct Connect connection.\n"
        ],
        "Question": "An application is currently secured using network access control lists and security groups. Web servers are located in public subnets behind an Application Load Balancer (ALB); application servers are located in private subnets. How can edge security be enhanced to safeguard the Amazon EC2 instances against attack? (Choose two.)\n",
        "id": 254
    },
    {
        "Correct": [
            "Enable log file validation in the AWS CloudTrail configuration.\n",
            "Configure AWS CloudTrail logs so that they are sent to an Amazon S3 bucket in a different account that only the Security team can access.\n"
        ],
        "Answers": [
            "Enable log file validation in the AWS CloudTrail configuration.\n",
            "Choose SHA-256 as the AWS CloudTrail digest encryption format in the CloudTrail configuration.\n",
            "Configure the AWS CloudTrail Amazon S3 bucket to enable SSE by default.\n",
            "Configure AWS CloudTrail logs so that they are sent to an Amazon S3 bucket in a different account that only the Security team can access.\n",
            "Configure AWS CloudTrail logs so that they are sent to an Amazon S3 bucket with a bucket policy granting access to only the Security team's IAM group.\n"
        ],
        "Question": "A CSO requires all AWS API logs to be stored, and access to those logs to be restricted to only security personnel for auditing purposes. Personnel need to be able to validate the log integrity, and logs must be encrypted in transit and at rest. Which steps should a Security Engineer take to ensure that these requirements are met? (Select TWO.)\n",
        "id": 255
    },
    {
        "Correct": [
            "The application authenticates against LDAP and retrieves the name of an IAM role associated with the user. The application then calls the IAM Security Token Service to assume that IAM role The application can use the temporary credentials to access the appropriate S3 bucket.\n",
            "Develop an identity broker that authenticates against LDAP and then calls IAM Security Token Service to get IAM federated user credentials The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.\n"
        ],
        "Answers": [
            "Develop an identity broker that authenticates against IAM security Token service to assume a IAM role in order to get temporary AWS security credentials The application calls the identity broker to get AWS temporary security credentials with access to the appropriate S3 bucket.\n",
            "The application authenticates against LDAP and retrieves the name of an IAM role associated with the user. The application then calls the IAM Security Token Service to assume that IAM role The application can use the temporary credentials to access the appropriate S3 bucket.\n",
            "Develop an identity broker that authenticates against LDAP and then calls IAM Security Token Service to get IAM federated user credentials The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.\n",
            "The application authenticates against LDAP the application then calls the AWS identity and Access Management (IAM) Security Token service to log in to IAM using the LDAP credentials the application can use the IAM temporary credentials to access the appropriate S3 bucket.\n",
            "The application authenticates against IAM Security Token Service using the LDAP credentials the application uses those temporary AWS security credentials to access the appropriate S3 bucket.\n"
        ],
        "Question": "A corporate web application is deployed within an Amazon Virtual Private Cloud (VPC) and is connected to the corporate data center via an IPsec VPN. The application must authenticate against the on-premises LDAP server. After authentication, each logged-in user can only access an Amazon Simple Storage Space (S3) keyspace specific to that user. Which two approaches can satisfy these objectives? (Choose 2 answers)\n",
        "id": 256
    },
    {
        "Correct": [
            "Use AWS WAF to scan inbound traffic for web exploits. Use a third-party AWS Marketplace solution to restrict egress traffic to specific whitelisted URLs.\n"
        ],
        "Answers": [
            "Use AWS Shield to scan inbound traffic for web exploits. Use VPC Flow Logs and AWS Lambda to restrict egress traffic to specific whitelisted URLs.\n",
            "Use AWS Shield to scan inbound traffic for web exploits. Use a third-party AWS Marketplace solution to restrict egress traffic to specific whitelisted URLs.\n",
            "Use AWS WAF to scan inbound traffic for web exploits. Use VPC Flow Logs and AWS Lambda to restrict egress traffic to specific whitelisted URLs.\n",
            "Use AWS WAF to scan inbound traffic for web exploits. Use a third-party AWS Marketplace solution to restrict egress traffic to specific whitelisted URLs.\n"
        ],
        "Question": "The Security Engineer is managing a web application that processes highly sensitive personal information. The application runs on Amazon EC2. The application has strict compliance requirements, which instruct that all incoming traffic to the application is protected from common web exploits and that all outgoing traffic from the EC2 instances is restricted to specific whitelisted URLs.Which architecture should the Security Engineer use to meet these requirements?\n",
        "id": 257
    },
    {
        "Correct": [
            "Use the operating system built-in, host-based firewall to implement the required rules.\n"
        ],
        "Answers": [
            "Configure AWS WAF rules to implement the required rules.\n",
            "Use the operating system built-in, host-based firewall to implement the required rules.\n",
            "Use a NAT gateway to control ingress and egress according to the requirements.\n",
            "Launch an EC2-based firewall product from the AWS Marketplace, and implement the required rules in that product.\n"
        ],
        "Question": "A company has complex connectivity rules governing ingress, egress, and communications between Amazon EC2 instances. The rules are so complex that they cannot be implemented within the limits of the maximum number of security groups and network access control lists (network ACLs). What mechanism will allow the company to implement all required network rules without incurring additional cost?\n",
        "id": 258
    },
    {
        "Correct": [
            "Configure a proxy solution on Amazon EC2 and route all outbound VPC traffic through it. Perform inspection within proxy software on the EC2 instance.\n",
            "Configure the host-based agent on each EC2 instance within the VPPerform inspection within the host-based agent.\n"
        ],
        "Answers": [
            "Configure a proxy solution on Amazon EC2 and route all outbound VPC traffic through it. Perform inspection within proxy software on the EC2 instance.\n",
            "Configure the host-based agent on each EC2 instance within the VPPerform inspection within the host-based agent.\n",
            "Enable VPC Flow Logs for all subnets in the VPPerform inspection from the Flow Log data within Amazon CloudWatch Logs.\n",
            "Configure Elastic Load Balancing (ELB) access logs. Perform inspection from the log data within the ELB access log files.\n",
            "Configure the CloudWatch Logs agent on each EC2 instance within the VPPerform inspection from the log data within CloudWatch Logs.\n"
        ],
        "Question": "A company requires that IP packet data be inspected for invalid or malicious content. Which of the following approaches achieve this requirement? (Choose two.)\n",
        "id": 259
    },
    {
        "Correct": [
            "Bypass the proxy and use an S3 VPC endpoint with a policy that whitelists only certain S3 buckets within Account 1.\n",
            "Block outbound access to public S3 endpoints on the proxy server.\n"
        ],
        "Answers": [
            "Bypass the proxy and use an S3 VPC endpoint with a policy that whitelists only certain S3 buckets within Account 1.\n",
            "Block outbound access to public S3 endpoints on the proxy server.\n",
            "Configure Network ACLs on Server X to deny access to S3 endpoints.\n",
            "Modify the S3 bucket policy for the legitimate bucket to allow access only from the public IP addresses associated with the application server.\n",
            "Remove the IAM instance role from the application server and save API access keys in a trusted and encrypted application config file.\n"
        ],
        "Question": "A threat assessment has identified a risk whereby an internal employee could exfiltrate sensitive data from production host running inside AWS (Account 1). The threat was documented as follows: Threat description: A malicious actor could upload sensitive data from Server X by configuring credentials for an AWS account (Account 2) they control and uploading data to an Amazon S3 bucket within their control.Server X has outbound internet access configured via a proxy server. Legitimate access to S3 is required so that the application can upload encrypted files to an S3 bucket. Server X is currently using an IAM instance role. The proxy server is not able to inspect any of the server communication due to TLS encryption.Which of the following options will mitigate the threat? (Choose two.)\n",
        "id": 260
    },
    {
        "Correct": [
            "Use web identity federation and register your application with a third-party identity provider such as Google, Amazon, or Facebook to obtain a unique id.\n",
            "Create an IAM role, (TriviaRole), with an IAM policy document attached to it, specifying the conditions under which the app can access TriviaScores DynamoDB table.\n"
        ],
        "Answers": [
            "Use a third-party identity provider such as Google, Facebook or Amazon so users can become an AWS IAM User with access to the application.\n",
            "Use web identity federation and register your application with a third-party identity provider such as Google, Amazon, or Facebook to obtain a unique id.\n",
            "Create an IAM User so users can log in to a third-party identity provider such as a Google, Facebook or Amazon to use the application.\n",
            "Create an IAM role, (TriviaRole), with an IAM policy document attached to it, specifying the conditions under which the app can access TriviaScores DynamoDB table.\n"
        ],
        "Question": "You have created a Trivia Scores DynamoDB table for an application that needs to support thousands of users. You need to ensure that each user can only access their own data in the TriviaScores table. Many users already have accounts with a third-party identity provider, such as Facebook, Google, or Login with Amazon. What should you do? Choose the 2 correct answers:\n",
        "id": 261
    },
    {
        "Correct": [
            "Enabling rotation in Secrets Manager causes the secret to rotate immediately and the applications are using the earlier credential.\n"
        ],
        "Answers": [
            "Migrating the credential to RDS requires that all access come through requests to the Secrets Manager.\n",
            "Enabling rotation in Secrets Manager causes the secret to rotate immediately and the applications are using the earlier credential.\n",
            "The Secrets Manager IAM policy does not allow access to the RDS database.\n",
            "The Secrets Manager IAM policy does not allow access for the applications.\n"
        ],
        "Question": "A company`s database developer has just migrated an Amazon RDS database credential to be stored and managed by AWS Secrets Manager. The developer has also enabled rotation of the credential within the Secrets Manager console and set the rotation to change every 30 days. After a short period of time, a number of existing applications have failed with authentication errors.What is the MOST likely cause of the authentication errors?\n",
        "id": 262
    },
    {
        "Correct": [
            "Configure the target region`s AWS service to communicate with the source region`s AWS KMS so that it can decrypt the resource in the target region.\n"
        ],
        "Answers": [
            "Copy the application`s AWS KMS CMK from the source region to the target region so that it can be used to decrypt the resource after it is copied to the target region.\n",
            "Configure AWS KMS to automatically synchronize the CMK between regions so that it can be used to decrypt the resource in the target region.\n",
            "Use AWS services that replicate data across regions, and re-wrap the data encryption key created in the source region by using the CMK in the target region so that the target region`s CMK can decrypt the database encryption key.\n",
            "Configure the target region`s AWS service to communicate with the source region`s AWS KMS so that it can decrypt the resource in the target region.\n"
        ],
        "Question": "An application has a requirement to be resilient across not only Availability Zones within the application`s primary region but also be available within another region altogether. Which of the following supports this requirement for AWS resources that are encrypted by AWS KMS?\n",
        "id": 263
    },
    {
        "Correct": [
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from sgLB sgDB: allow port 3306 traffic from sgWeb and sgBastion sgBastion: allow port 22 traffic from the corporate IP address range\n"
        ],
        "Answers": [
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from 0.0.0.0/0 sgDB: allow port 3306 traffic from sgWeb and sgBastion sgBastion: allow port 22 traffic from the corporate IP address range\n",
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from sgLB sgDB: allow port 3306 traffic from sgWeb and sgLB sgBastion: allow port 22 traffic from the VPC IP address range\n",
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from sgLB sgDB: allow port 3306 traffic from sgWeb and sgBastion sgBastion: allow port 22 and traffic from the VPC IP address range\n",
            "sgLB: allow port 80 and 443 traffic from 0.0.0.0/0 sgWeb: allow port 80 and 443 traffic from sgLB sgDB: allow port 3306 traffic from sgWeb and sgBastion sgBastion: allow port 22 traffic from the corporate IP address range\n"
        ],
        "Question": "A web application runs in a VPC on EC2 instances behind an ELB Application Load Balancer. The application stores data in an RDS MySQL DB instance. A Linux bastion host is used to apply schema updates to the database - administrators connect to the host via SSH from a corporate workstation. The following security groups are applied to the infrastructure- sgLB - associated with the ELB sgWeb - associated with the EC2 instances sgDB - associated with the database sgBastion - associated with the bastion host Which security group configuration will allow the application to be secure and functional?\n",
        "id": 264
    },
    {
        "Correct": [
            "A network ACL with rules that allow outgoing traffic on port 443 and incoming traffic on ephemeral ports.\n",
            "A security group with a rule that allows outgoing traffic on port 443.\n"
        ],
        "Answers": [
            "A network ACL with a rule that allows outgoing traffic on port 443.\n",
            "A network ACL with rules that allow outgoing traffic on port 443 and incoming traffic on ephemeral ports.\n",
            "A network ACL with rules that allow outgoing traffic on port 443 and incoming traffic on port 443.\n",
            "A security group with a rule that allows outgoing traffic on port 443.\n",
            "A security group with rules that allow outgoing traffic on port 443 and incoming traffic on ephemeral ports.\n",
            "A security group with rules that allow outgoing traffic on port 443 and incoming traffic on port 443.\n"
        ],
        "Question": "An application running on EC2 instances in a VPC must call an external web service via TLS (port 443). The instances run in public subnets. Which configurations below allow the application to function and minimize the exposure of the instances? (Select TWO.)\n",
        "id": 265
    },
    {
        "Correct": [
            "Launch the EC2 instances with an EC2 IAM role to access AWS services. Retrieve the database credentials from AWS Secrets Manager.\n"
        ],
        "Answers": [
            "Retrieve an access key from an AWS Systems Manager SecureString parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.\n",
            "Launch the EC2 instances with an EC2 IAM role to access AWS services. Retrieve the database credentials from AWS Secrets Manager.\n",
            "Retrieve an access key from an AWS Systems Manager plaintext parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.\n",
            "Launch the EC2 instances with an EC2 IAM role to access AWS services. Store the database passwords in an encrypted config file with the application artifacts.\n"
        ],
        "Question": "A large enterprise is deploying a web application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The application stores data in an Amazon RDS Oracle DB instance and Amazon DynamoDThere are separate environments for development, testing, and production. What is the MOST secure and flexible way to obtain password credentials during deployment?\n",
        "id": 266
    },
    {
        "Correct": [
            "Create an IAM role for cross-account access allows the SaaS provider`s account to assume the role and assign it a policy that allows only the actions required by the SaaS application\n"
        ],
        "Answers": [
            "From the AWS Management Console, navigate to the Security Credentials page and retrieve the access and secret key for your account.\n",
            "Create an IAM user within the enterprise account assign a user policy to the IAM user that allows only the actions required by the SaaS application create a new access and secret key for the user and provide these credentials to the SaaS provider.\n",
            "Create an IAM role for cross-account access allows the SaaS provider`s account to assume the role and assign it a policy that allows only the actions required by the SaaS application\n",
            "Create an IAM role for EC2 instances, assign it a policy that allows only the actions required tor the SaaS application to work, provide the role ARN to the SaaS provider to use when launching their application instances.\n"
        ],
        "Question": "An enterprise wants to use a third-party SaaS application. The SaaS application needs to have access to issue several API commands to discover Amazon EC2 resources running within the enterprise`s account. The enterprise has internal security policies that require any outside access to their environment must conform to the principles of least privilege and there must be controls in place to ensure that the credentials used by the SaaS vendor cannot be used by any other third party. Which of the following would meet all of these conditions?\n",
        "id": 267
    },
    {
        "Correct": [
            "The CMK specified in the application does not exist.\n",
            "The CMK specified in the application is not enabled.\n"
        ],
        "Answers": [
            "The CMK specified in the application does not exist.\n",
            "The CMK specified in the application is currently is use.\n",
            "The CMK specified in the application is using the CMK KeyID instead of CMK Amazon Resource Name.\n",
            "The CMK specified in the application is not enabled.\n",
            "The CMK specified in the application is using an alias.\n"
        ],
        "Question": "The Development team receives an error message each time the team members attempt to encrypt or decrypt a Secure String parameter from the SSM Parameter Store by using an AWS KMS customer managed key (CMK). Which CMK-related issues could be responsible? (Choose two.)\n",
        "id": 268
    },
    {
        "Correct": [
            "Customer managed CMK with AWS generated key material\n"
        ],
        "Answers": [
            "AWS managed Customer Master Key (CMK)\n",
            "Customer managed CMK with AWS generated key material\n",
            "Customer managed CMK with imported key material\n",
            "AWS managed data key\n"
        ],
        "Question": "An organization policy states that all encryption keys must be automatically rotated every 12 months.Which AWS Key Management Service (KMS) key type should be used to meet this requirement?\n",
        "id": 269
    },
    {
        "Correct": [
            "Use Amazon S3 Server-Side Encryption with Amazon S3-Managed Keys. Set Amazon S3 ACLs to allow access to specific elements of the platform. Use Amazon S3 to access logs for auditing.\n"
        ],
        "Answers": [
            "Use Amazon S3 Server-Side Encryption with AWS KMS-Managed Keys for storing data. Use AWS KMS Grants to allow access to specific elements of the platform. Use AWS CloudTrail for auditing.\n",
            "Use Amazon S3 Server-Side Encryption with Amazon S3-Managed Keys. Set Amazon S3 ACLs to allow access to specific elements of the platform. Use Amazon S3 to access logs for auditing.\n",
            "Use Amazon S3 Client-Side Encryption with Client-Side Master Key. Set Amazon S3 ACLs to allow access to specific elements of the platform. Use Amazon S3 to access logs for auditing.\n",
            "Use Amazon S3 Client-Side Encryption with AWS KMS-Managed Keys for storing data. Use AWS KMS Grants to allow access to specific elements of the platform. Use AWS CloudTrail for auditing.\n"
        ],
        "Question": "A solutions architect works for a company that has a data lake based on a central Amazon S3 bucket. The data contains sensitive information. The architect must be able to specify exactly which files each user can access. Users access the platform through a SAML federation Single Sign On platform. The architect needs to build a solution that allows fine grained access control, traceability of access to the objects, and usage of the standard tools (AWS Console, AWS CLI) to access the data. Which solution should the architect build?\n",
        "id": 270
    },
    {
        "Correct": [
            "VPC Flow Logs\n",
            "Lambda\n"
        ],
        "Answers": [
            "Internet gateway\n",
            "VPC Flow Logs\n",
            "AWS CloudTrail\n",
            "Lambda\n",
            "AWS Inspector\n"
        ],
        "Question": "You have a three-tier web application with separate subnets for Web, Applications, and Database tiers. Your CISO suspects your application will be the target of malicious activity. You are tasked with notifying the security team in the event your application is port scanned by external systems. Which two AWS Services cloud you leverage to build an automated notification system? (Select two.)\n",
        "id": 271
    },
    {
        "Correct": [
            "The encryption of data at rest has to be enabled when the Amazon EFS file system is created. The encryption of data in transit can be enabled when the file system is mounted in EC2 instance\n"
        ],
        "Answers": [
            "The encryption of data at rest has to be enabled when the Amazon EFS file system is created. The encryption of data in transit can be enabled when the file system is mounted in EC2 instance\n",
            "The encryption of data at rest and in transit can be enabled when the Amazon EFS file system is created.\n",
            "The encryption of data at rest and in transit can only be enabled when the Amazon EFS file system is mounted in EC2 instance.\n",
            "The encryption of data at rest can be enabled when the Amazon EFS file system is mounted in EC2 instance. The encryption of data in transit is enabled when the EFS file system is created using AWS console or CLI.\n"
        ],
        "Question": "An IT company has a big data analytics application that is deployed in EC2 in multiple availability zones. These EC2 instances simultaneously access a shared Amazon EFS file system using a traditional file permissions model. A recent internal security audit has found that there is a potential security risk as the EFS file system is not encrypted for either at rest or in transit. What actions could be taken to address the potential security threat posed by non-encryption of the EFS volume?\n",
        "id": 272
    },
    {
        "Correct": [
            "Use AWS Config to monitor and alert, if any S3 bucket with public access is created\n"
        ],
        "Answers": [
            "Use a bucket policy and place a DENY statement for the PutObject Action\n",
            "Use AWS Config to monitor and alert, if any S3 bucket with public access is created\n",
            "Enable versioning for the bucket\n",
            "Use an IAM policy and place a DENY statement for the PutObject Action\n"
        ],
        "Question": "A company uses S3 to host its sensitive data. The CIO is worried about unwarranted access to the data in the bucket. Which of the following can be used as a security measure but also ensuring that you don`t put too much access restrictions on the bucket for existing users?\n",
        "id": 273
    },
    {
        "Correct": [
            "Update Amazon S3 lifecycle policies to archive old logs to Amazon Glacier, and use or write a service or use CloudWatch Logs agent to also stream your application logs to CloudWatch Logs.\n"
        ],
        "Answers": [
            "Update Amazon S3 lifecycle policies to archive old logs to Amazon Glacier, and add a new policy to push all log entries to Amazon SQS for ingestion by the support team.\n",
            "Update Amazon S3 lifecycle policies to archive old logs to Amazon Glacier, and use or write a service or use CloudWatch Logs agent to also stream your application logs to CloudWatch Logs.\n",
            "Update Amazon Glacier lifecycle policies to pull new logs from Amazon S3, and in the Amazon EC2 console, enable the CloudWatch Logs Agent on all of your application servers.\n",
            "Update Amazon S3 lifecycle policies to archive old logs to Amazon Glacier. Key can be different from the table. Enable Amazon S3 partial uploads on your Amazon S3 bucket, and trigger an Amazon SNS notification when a partial upload occurs.\n"
        ],
        "Question": "Due to compliance regulations, management has asked you to provide a system that allows for cost-effective long-term storage of your application logs and provides a way for support staff to view the logs more quickly. Currently your log system archives logs automatically to Amazon S3 every hour, and support staff must wait for these logs to appear in Amazon S3, because they do not currently have access to the systems to view live logs. What method should you use to become compliant while also providing a faster way for support staff to have access to logs?\n",
        "id": 274
    },
    {
        "Correct": [
            "Create a new S3 bucket. Configure CloudTrail in both accounts to log to this bucket.\n",
            "Create a new IAM role to control access to the S3 bucket.\n",
            "Create an S3 Bucket Policy to control access to the S3 bucket.\n"
        ],
        "Answers": [
            "Create a new S3 bucket. Configure CloudTrail in both accounts to log to this bucket.\n",
            "Use the existing S3 buckets in each account. Configure CloudTrail in each account to log to its own S3 bucket.\n",
            "Create a new IAM user policy to control access to the S3 bucket.\n",
            "Create a new IAM role to control access to the S3 bucket.\n",
            "Allow CloudTrail to perform PUT operations, explicitly deny GET operations, and explicitly allow the Security Team to perform GET operations.\n",
            "Allow CloudTrail to perform PUT operations. Allow the Security Team to perform GET operations.\n",
            "Create an S3 Bucket Policy to control access to the S3 bucket.\n"
        ],
        "Question": "Your organization has two AWS accounts; one for development and the other for production. Each account has EC2 instances running as web servers, a load balancer, and an RDS database. Your security team has asked you to ensure that they can log all interactions with these AWS services and that users cannot tamper with logs. Which of the following steps should you take? (Choose three)\n",
        "id": 275
    },
    {
        "Correct": [
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:CreateLogGroup\", \"logs:CreateLogStream\", \"logs:PutLogEvents\"], \"Effect\": \"Allow\" }\n"
        ],
        "Answers": [
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:*\"], \"Effect\": \"Allow\" }\n",
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:CreateLogStream\"], \"Effect\": \"Allow\" }\n",
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:CreateLogGroup\", \"logs:CreateLogStream\", \"logs:PutLogEvents\"], \"Effect\": \"Allow\" }\n",
            "{ \"Sid\": \"Logging-12345\", \"Resource\": \"*\", \"Action\": [\"logs:CreateLogGroup\", \"logs:CreateLogStream\", \"logs:DeleteLogGroup\", \"logs:DeleteLogStream\", \"logs:getLogEvents\", \"logs:PutLogEvents\"], \"Effect\": \"Allow\" }\n"
        ],
        "Question": "When testing a new AWS Lambda function that retrieves items from an Amazon DynamoDB table, the Security Engineer notices that the function was not logging any data to Amazon CloudWatch Logs.The following policy was assigned to the role assumed by the Lambda function:{ \"Version\": \"2012-10-17\", \"Statement\": [{ \"Sid\": \"Dynamo-1234567\", \"Action\": [ \"dynamodb:GetItem\" ], \"Effect\": \"Allow\", \"Resource\": \"*\" }] } Which least-privilege policy addition would allow this function to log properly?\n",
        "id": 276
    },
    {
        "Correct": [
            "Check the route tables for the application server subnets for routes to the VPC peering connection.\n",
            "Check the database security groups for rules that allow traffic from the application servers.\n"
        ],
        "Answers": [
            "Check to see if the application servers are in a private subnet or public subnet.\n",
            "Check the route tables for the application server subnets for routes to the VPC peering connection.\n",
            "Check the NACLs for the database subnets for rules that allow traffic from the Internet.\n",
            "Check the database security groups for rules that allow traffic from the application servers.\n",
            "Check to see if the database VPC has an Internet gateway\n"
        ],
        "Question": "A company decides to place database hosts in its own VPC, and to set up VPC peering to different VPCs containing the application and web tiers. The application servers are unable to connect to the database. Which network troubleshooting steps should be taken to resolve the issue? (Select TWO.)\n",
        "id": 277
    },
    {
        "Correct": [
            "Send the local text log files to CloudWatch Logs and configure a CloudWatch metric filter. Trigger CloudWatch alarms based on the metrics.\n"
        ],
        "Answers": [
            "Create a Lambda function that mounts the EBS volume with the logs and scans the logs for security incidents. Trigger the function every 5 minutes with a scheduled CloudWatch event.\n",
            "Send the local text log files to CloudWatch Logs and configure a CloudWatch metric filter. Trigger CloudWatch alarms based on the metrics.\n",
            "Install the Amazon Inspector agent on any EC2 instance running the legacy application. Generate CloudWatch alerts based on any Amazon Inspector findings.\n",
            "Export the local text log files to CloudTrail. Create a Lambda function that queries the CloudTrail logs for security incidents using Athena.\n"
        ],
        "Question": "A company has a legacy application that outputs all logs to a local text file. Logs from all applications running on AWS must be continually monitored for security related messages. What can be done to allow the company to deploy the legacy application on Amazon EC2 and still meet the monitoring requirement?\n",
        "id": 278
    },
    {
        "Correct": [
            "The mobile app should authenticate with an Amazon Cognito identity that is authorized to write to an Amazon Kinesis Firehose with an Amazon S3 destination.\n"
        ],
        "Answers": [
            "The mobile app should write to an S3 bucket that allows anonymous PutObject calls.\n",
            "The mobile app should authenticate with an Amazon Cognito identity that is authorized to write to an Amazon Kinesis Firehose with an Amazon S3 destination.\n",
            "The mobile app should authenticate with an embedded IAM access key that is authorized to write to an Amazon Kinesis Firehose with an Amazon S3 destination.\n",
            "The mobile app should call a REST-based service that stores data on Amazon EBS. Deploy the service on multiple EC2 instances across two Availability Zones.\n"
        ],
        "Question": "A mobile application collects data that must be stored in multiple Availability Zones within five minutes of being captured in the app. What architecture securely meets these requirements?\n",
        "id": 279
    },
    {
        "Correct": [
            "AWS IAM roles\n"
        ],
        "Answers": [
            "AWS IAM groups\n",
            "AWS IAM users\n",
            "AWS IAM roles\n",
            "AWS IAM access keys\n"
        ],
        "Question": "A company wants to control access to its AWS resources by using identities and groups that are defined in its existing Microsoft Active Directory. What must the company create in its AWS account to map permissions for AWS services to Active Directory user attributes?\n",
        "id": 280
    },
    {
        "Correct": [
            "Install intrusion prevention software (IPS) on each instance.\n"
        ],
        "Answers": [
            "Use custom route tables to prevent malicious traffic from routing to the instances.\n",
            "Update security groups to deny traffic from the originating source IP addresses.\n",
            "Use network ACLs.\n",
            "Install intrusion prevention software (IPS) on each instance.\n"
        ],
        "Question": "A distributed web application is installed across several EC2 instances in public subnets residing in two Availability Zones. Apache logs show several intermittent brute-force attacks from hundreds of IP addresses at the layer 7 level over the past six months. What would be the BEST way to reduce the potential impact of these attacks in the future?\n",
        "id": 281
    },
    {
        "Correct": [
            "Use the AWS CloudTrail console to search for user activity.\n"
        ],
        "Answers": [
            "Use the AWS CloudTrail console to search for user activity.\n",
            "Use the Amazon CloudWatch Logs console to filter CloudTrail data by user.\n",
            "Use AWS Config to see what actions were taken by the user.\n",
            "Use Amazon Athena to query CloudTrail logs stored in Amazon S3.\n"
        ],
        "Question": "The Security team believes that a former employee may have gained unauthorized access to AWS resources sometime in the past 3 months by using an identified access key.What approach would enable the Security team to find out what the former employee may have done within AWS?\n",
        "id": 282
    },
    {
        "Correct": [
            "The external ID used by the Auditor is missing or incorrect.\n",
            "The Auditor has not been granted sts:AssumeRole for the role in the destination account.\n",
            "The role ARN used by the Auditor is missing or incorrect.\n"
        ],
        "Answers": [
            "The external ID used by the Auditor is missing or incorrect.\n",
            "The Auditor is using the incorrect password.\n",
            "The Auditor has not been granted sts:AssumeRole for the role in the destination account.\n",
            "The Amazon EC2 role used by the Auditor must be set to the destination account role.\n",
            "The secret key used by the Auditor is missing or incorrect.\n",
            "The role ARN used by the Auditor is missing or incorrect.\n"
        ],
        "Question": "A company has contracted with a third party to audit several AWS accounts. To enable the audit, cross-account IAM roles have been created in each account targeted for audit. The Auditor is having trouble accessing some of the accounts. Which of the following may be causing this problem? (Choose three.)\n",
        "id": 283
    },
    {
        "Correct": [
            "Users request a SAML assertion from your on-premises SAML 2.0-compliant identity provider (IdP) and use that assertion to obtain federated access to the AWS Management Console via the AWS single sign-on (SSO) endpoint.\n"
        ],
        "Answers": [
            "Users log in to the AWS Management Console using the AWS Command Line Interface.\n",
            "Users request a SAML assertion from your on-premises SAML 2.0-compliant identity provider (IdP) and use that assertion to obtain federated access to the AWS Management Console via the AWS single sign-on (SSO) endpoint.\n",
            "Users sign in using an OpenID Connect (OIDC) compatible IdP, receive an authentication token, then use that token to log in to the AWS Management Console.\n",
            "Users log in directly to the AWS Management Console using the credentials from your on-premises Kerberos compliant identity provider.\n"
        ],
        "Question": "Your company is migrating infrastructure to AWS. A large number of developers and administrators will need to control this infrastructure using the AWS Management Console. The Identity Management team is objecting to creating an entirely new directory of IAM users for all employees, and the employees are reluctant to commit yet another password to memory. Which of the following will satisfy both these stakeholders?\n",
        "id": 284
    },
    {
        "Correct": [
            "Use AWS Config to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n"
        ],
        "Answers": [
            "Use AWS Config to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n",
            "Use Macie to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n",
            "Use CloudTrail to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n",
            "Use Trusted Advisor to examine the employee's IAM permissions prior to the incident and compare them to the employee's current IAM permissions.\n"
        ],
        "Question": "A security team is creating a response plan in the event an employee executes unauthorized actions on AWS infrastructure. They want to include steps to determine if the employee's IAM permissions changed as part of the incident. What steps should the team document in the plan?\n",
        "id": 285
    },
    {
        "Correct": [
            "Allow Outgoing Traffic on the NACL for ephemeral ports\n"
        ],
        "Answers": [
            "Allow Outgoing Traffic on the NACL for ephemeral ports\n",
            "Allow Outgoing Traffic on the Security groups for port 80\n",
            "Allow Outgoing Traffic on the NACL for port 80\n",
            "Allow Outgoing Traffic on the Security groups for ephemeral ports\n"
        ],
        "Question": "You have setup an EC2 Instance that hosts a web application. You have set the following rulesSecurity Group RulesAllow Inbound Traffic on port 80 from 0.0.0.0/0 Deny Outgoing TrafficNetwork ACLsAllow Inbound Traffic on port 80 from 0.0.0.0/0 Deny Outgoing TrafficUsers are complaining that they cannot access the web server. How can you ensure that the issue gets resolved?\n",
        "id": 286
    },
    {
        "Correct": [
            "Write a script that uses the GenerateCredentialReport, GetCredentialReport, and UpdateAccessKey APIs.\n"
        ],
        "Answers": [
            "In the AWS Console, choose the IAM service and select \"Users\". Review the \"Access Key Age\" column.\n",
            "Define an IAM policy that denies access if the key age is more than three months and apply to all users.\n",
            "Write a script that uses the GenerateCredentialReport, GetCredentialReport, and UpdateAccessKey APIs.\n",
            "Create an Amazon CloudWatch alarm to detect aged access keys and use an AWS Lambda function to disable the keys older than 90 days.\n"
        ],
        "Question": "A Security Engineer has been asked to create an automated process to disable IAM user access keys that are more than three months old.Which of the following options should the Security Engineer use?\n",
        "id": 287
    },
    {
        "Correct": [
            "Post your log data to an Amazon Kinesis data stream, and subscribe your log-processing application so that is configured to process your logging data.\n"
        ],
        "Answers": [
            "Publish your data to CloudWatch Logs, and configure your application to autoscale to handle the load on demand.\n",
            "Publish your log data to an Amazon S3 bucket. Use AWS CloudFormation to create an Auto Scaling group to scale your post-processing application which is configured to pull down your log files stored in Amazon S3.\n",
            "Post your log data to an Amazon Kinesis data stream, and subscribe your log-processing application so that is configured to process your logging data.\n",
            "Configure an Auto Scaling group to increase the size of your Amazon EMR cluster.\n",
            "Create a multi-AZ Amazon RDS MySQL cluster, post the logging data to MySQL, and run a map reduce job to retrieve the required information on user counts.\n"
        ],
        "Question": "Your current log analysis application takes more than four hours to generate a report of the top 10 users of your web application. You have been asked to implement a system that can report this information in real time, ensure that the report is always up to date, and handle increases in the number of requests to your web application. Choose the option that is cost-effective and can fulfill the requirements.\n",
        "id": 288
    },
    {
        "Correct": [
            "Modify the Network ACLs associated with all public subnets in the VPC to deny access from the IP address block\n"
        ],
        "Answers": [
            "Create an AD policy to modify Windows Firewall settings on all hosts in the VPC to deny access from the IP address block\n",
            "Modify the Network ACLs associated with all public subnets in the VPC to deny access from the IP address block\n",
            "Add a rule to all of the VPC 5 Security Groups to deny access from the IP address block\n",
            "Modify the Windows Firewall settings on all Amazon Machine Images (AMIs) that your organization uses in that VPC to deny access from the IP address block\n"
        ],
        "Question": "You are currently hosting multiple applications in a VPC and have logged numerous port scans coming in from a specific IP address block. Your security team has requested that all access from the offending IP address block be denied for the next 24 hours. Which of the following is the best method to quickly and temporarily deny access from the specified IP address block?\n",
        "id": 289
    },
    {
        "Correct": [
            "Create IAM users in the Master account Create cross-account roles in the Dev and Test accounts that have full Admin permissions and grant the Master account access\n"
        ],
        "Answers": [
            "Create IAM users in the Master account with full Admin permissions. Create cross-account roles in the Dev and Test accounts that grant the Master account access to the resources in the account by inheriting permissions from the Master account.\n",
            "Create IAM users and a cross-account role in the Master account that grants full Admin permissions to the Dev and Test accounts.\n",
            "Create IAM users in the Master account Create cross-account roles in the Dev and Test accounts that have full Admin permissions and grant the Master account access\n",
            "Link the accounts using Consolidated Billing. This will give IAM users in the Master account access to resources in the Dev and Test accounts\n"
        ],
        "Question": "You are looking to migrate your Development (Dev) and Test environments to AWS. You have decided to use separate AWS accounts to host each environment. You plan to link each accounts bill to a Master AWS account using Consolidated Billing. To make sure you keep within budget you would like to implement a way for administrators in the Master account to have access to stop, delete and/or terminate resources in both the Dev and Test accounts. Identify which option will allow you to achieve this goal?\n",
        "id": 290
    },
    {
        "Correct": [
            "presentation-sg: Allow ports 80 and 443 from 0.0.0.0/0\n",
            "data-sg: Allow port 1433 from logic-sg\n",
            "logic-sg: Allow port 443 from presentation-sg\n"
        ],
        "Answers": [
            "presentation-sg: Allow ports 80 and 443 from 0.0.0.0/0\n",
            "data-sg: Allow port 1433 from presentation-sg\n",
            "data-sg: Allow port 1433 from logic-sg\n",
            "presentation-sg: Allow port 1433 from data-sg\n",
            "logic-sg: Allow port 443 from presentation-sg\n",
            "logic-sg: Allow port 443 from 0.0.0.0/0\n"
        ],
        "Question": "A Security Engineer must set up security group rules for a three-tier application: Presentation tier - Accessed by users over the web, protected by the security group presentation-sg Logic tier - RESTful API accessed from the presentation tier through HTTPS, protected by the security group logic-sg Data tier - SQL Server database accessed over port 1433 from the logic tier, protected by the security group data-sg Which combination of the following security group rules will allow the application to be secure and functional? (Select THREE.)\n",
        "id": 291
    },
    {
        "Correct": [
            "Set up an AWS Organizations hierarchy, and replace the FullAWSAccess policy with the following Service Control Policy for the governed organization units:\n"
        ],
        "Answers": [
            "Set up an AWS Organizations hierarchy, and replace the FullAWSAccess policy with the following Service Control Policy for the governed organization units:\n",
            "Create multiple IAM users for the regulated accounts, and attach the following policy statement to restrict services as required:\n",
            "Set up an Organizations hierarchy, replace the global FullAWSAccess with the following Service Control Policy at the top level:\n",
            "Set up all users in the Active Directory for federated access to all accounts in the company. Associate Active Directory groups with IAM groups, and attach the following policy statement to restrict services as required:\n"
        ],
        "Question": "A Security Engineer must enforce the use of only Amazon EC2, Amazon S3, Amazon RDS, Amazon DynamoDB, and AWS STS in specific accounts.What is a scalable and efficient approach to meet this requirement?\n",
        "id": 292
    },
    {
        "Correct": [
            "Implement a \"write-only\" CloudTrail event filter to detect any modifications to the AWS account resources.\n"
        ],
        "Answers": [
            "Implement a \"write-only\" CloudTrail event filter to detect any modifications to the AWS account resources.\n",
            "Configure Amazon Macie to classify and discover sensitive data in the Amazon S3 bucket that contains the CloudTrail audit logs.\n",
            "Configure Amazon Athena to read from the CloudTrail S3 bucket and query the logs to examine account activities.\n",
            "Enable Amazon S3 event notifications to trigger an AWS Lambda function that sends an email alarm when there are new CloudTrail API entries.\n"
        ],
        "Question": "A Security Administrator is performing a log analysis as a result of a suspected AWS account compromise. The Administrator wants to analyze suspicious AWS CloudTrail log files but is overwhelmed by the volume of audit logs being generated. What approach enables the Administrator to search through the logs MOST efficiently?\n",
        "id": 293
    },
    {
        "Correct": [
            "Use TCP load balancing on the load balancer, SSL termination on the Amazon EC2 instances, OS-level disk encryption on the Amazon EBS volumes, and Amazon S3 with server-side encryption.\n",
            "Use SSL termination on the load balancer, an SSL listener on the Amazon EC2 instances, Amazon EBS encryption on EBS volumes containing PHI, and Amazon S3 with server-side encryption.\n"
        ],
        "Answers": [
            "Use SSL termination on the load balancer, Amazon EBS encryption on Amazon EC2 instances, and Amazon S3 with server-side encryption.\n",
            "Use SSL termination with a SAN SSL certificate on the load balancer, Amazon EC2 with all Amazon EBS volumes using Amazon EBS encryption, and Amazon S3 with server-side encryption with customer-managed keys.\n",
            "Use TCP load balancing on the load balancer, SSL termination on the Amazon EC2 instances, OS-level disk encryption on the Amazon EBS volumes, and Amazon S3 with server-side encryption.\n",
            "Use TCP load balancing on the load balancer, SSL termination on the Amazon EC2 instances, and Amazon S3 with server-side encryption.\n",
            "Use SSL termination on the load balancer, an SSL listener on the Amazon EC2 instances, Amazon EBS encryption on EBS volumes containing PHI, and Amazon S3 with server-side encryption.\n"
        ],
        "Question": "You are designing an application that contains protected health information. Security and compliance requirements for your application mandate that all protected health information in the application use encryption at rest and in transit. The application uses a three-tier architecture where data flows through the load balancer and is stored on Amazon EBS volumes for processing, and the results are stored in Amazon S3 using the AWS SDK. Which of the following two options satisfy the security requirements? Choose 2 answers\n",
        "id": 294
    },
    {
        "Correct": [
            "AWS CloudTrail\n"
        ],
        "Answers": [
            "AWS CodeCommit\n",
            "AWS CodePipeline\n",
            "AWS CloudTrail\n",
            "AWS CloudWatch\n"
        ],
        "Question": "Your company has an application hosted in AWS, which makes use of DynamoDThere is a requirement from the IT security department to ensure that all source IP addresses, which make calls to the DynamoDB tables, are recorded. Which of the following services can be used to ensure this requirement is fulfilled?\n",
        "id": 295
    },
    {
        "Correct": [
            "Use an 'on instance' proxy and configure this to perform DNS resolution and only allow traffic which doesn't breach security restrictions.\n"
        ],
        "Answers": [
            "Configure the NACL of the instance subnet to block any outbound traffic to the FQDN of the API endpoint or its return traffic\n",
            "Configure the SG of the instance to block any outbound traffic to the FQDN of the API endpoint or its return traffic\n",
            "Configure Layer-7 filtering on the NAT Gateway in the VPC and add a DNS blacklist entry\n",
            "Use an 'on instance' proxy and configure this to perform DNS resolution and only allow traffic which doesn't breach security restrictions.\n"
        ],
        "Question": "Your security team have approached you and asked that you restrict the ability of an EC2 instance to access a certain remote DNS API endpoint. The remote endpoint may change IP's over time and its imperative it can NEVER access this endpoint. What solution will work as expected?\n",
        "id": 296
    },
    {
        "Correct": [
            "email-smtp.us-east-1.amazonaws.com over port 587\n"
        ],
        "Answers": [
            "email.us-east-1.amazonaws.com over port 8080\n",
            "email-pop3.us-east-1.amazonaws.com over port 995\n",
            "email-smtp.us-east-1.amazonaws.com over port 587\n",
            "email-imap.us-east-1.amazonaws.com over port 993\n"
        ],
        "Question": "A Systems Engineer has been tasked with configuring outbound mail through Simple Email Service (SES) and requires compliance with current TLS standards. The mail application should be configured to connect to which of the following endpoints and corresponding ports?\n",
        "id": 297
    },
    {
        "Correct": [
            "Use an EC2 run command to confirm that the \"awslogs\" service is running on all instances.\n",
            "Verify that the permissions used by the agent allow creation of log groups/streams and to put log events.\n"
        ],
        "Answers": [
            "Use an EC2 run command to confirm that the \"awslogs\" service is running on all instances.\n",
            "Verify that the permissions used by the agent allow creation of log groups/streams and to put log events.\n",
            "Check whether any application log entries were rejected because of invalid time stamps by reviewing /var/cwlogs/rejects.log.\n",
            "Check that the trust relationship grants the service \"cwlogs.amazonaws.com\" permission to write objects to the Amazon S3 staging bucket.\n",
            "Verify that the time zone on the application servers is in UTC.\n"
        ],
        "Question": "An organization is using Amazon CloudWatch Logs with agents deployed on its Linux Amazon EC2 instances. The agent configuration files have been checked and the application log files to be pushed are configured correctly. A review has identified that logging from specific instances is missing. Which steps should be taken to troubleshoot the issue? (Choose two.)\n",
        "id": 298
    },
    {
        "Correct": [
            "Create IAM roles that can be mapped to group memberships in the corporate directory.\n",
            "Create an IAM role that establishes a trust relationship between IAM and the corporate directory identity provider (IdP).\n"
        ],
        "Answers": [
            "Create a Direct Connect connection between the corporate network and the AWS region with the company's infrastructure.\n",
            "Create IAM roles that can be mapped to group memberships in the corporate directory.\n",
            "Create a Lambda function to assign IAM roles to the temporary security tokens provided to the users\n",
            "Create IAM users that can be mapped to the employees' corporate identities.\n",
            "Create an IAM role that establishes a trust relationship between IAM and the corporate directory identity provider (IdP).\n"
        ],
        "Question": "A company wishes to enable Single Sign On (SSO) so its employees can login to the management console using their corporate directory identity. Which steps below are required as part of the process? (Select TWO.)\n",
        "id": 299
    },
    {
        "Correct": [
            "Specify \"aws:SecureTransport\": \"true\" within a condition in the S3 bucket policy.\n",
            "Set up default encryption for the S3 bucket.\n",
            "Enable API logging of data events for all S3 objects.\n"
        ],
        "Answers": [
            "Specify \"aws:SecureTransport\": \"true\" within a condition in the S3 bucket policy.\n",
            "Enable a security group for the S3 bucket that allows port 443, but not port 80.\n",
            "Set up default encryption for the S3 bucket.\n",
            "Enable Amazon CloudWatch Logs for the AWS account.\n",
            "Enable API logging of data events for all S3 objects.\n",
            "Enable S3 object versioning for the S3 bucket.\n"
        ],
        "Question": "A Security Administrator is configuring an Amazon S3 bucket and must meet the following security requirements: Encryption in transit Encryption at rest Logging of all object retrievals in AWS CloudTrail Which of the following meet these security requirements? (Choose three.)\n",
        "id": 300
    },
    {
        "Correct": [
            "Ensure that file permissions for monitored files that allow the CloudWatch Logs agent to read the file have not been modified.\n",
            "Verify that the OS Log rotation rules are compatible with the configuration requirements for agent streaming.\n"
        ],
        "Answers": [
            "Ensure that file permissions for monitored files that allow the CloudWatch Logs agent to read the file have not been modified.\n",
            "Verify that the OS Log rotation rules are compatible with the configuration requirements for agent streaming.\n",
            "Configure an Amazon Kinesis producer to first put the logs into Amazon Kinesis Streams.\n",
            "Create a CloudWatch Logs metric to isolate a value that changes at least once during the period before logging stops.\n",
            "Use AWS CloudFormation to dynamically create and maintain the configuration file for the CloudWatch Logs agent.\n"
        ],
        "Question": "Amazon CloudWatch Logs agent is successfully delivering logs to the CloudWatch Logs service. However, logs stop being delivered after the associated log stream has been active for a specific number of hours.What steps are necessary to identify the cause of this phenomenon? (Choose two.)\n",
        "id": 301
    },
    {
        "Correct": [
            "Use OAI for CloudFront to access private S3 objects and select the Restrict Viewer Access option in CloudFront cache behavior to use signed URLs.\n"
        ],
        "Answers": [
            "Configure CloudFront to use signed-URLs to access Amazon S3\n",
            "Store the videos as private objects in Amazon S3 and let CloudFront serve the objects by using only Origin Access Identity (OAI)\n",
            "Use Amazon S3 static website as the origin of CloudFront, and configure CloudFront to deliver the videos by generating a signed URL for users\n",
            "Use OAI for CloudFront to access private S3 objects and select the Restrict Viewer Access option in CloudFront cache behavior to use signed URLs.\n"
        ],
        "Question": "A Solutions Architect has been asked to deliver video content stored on Amazon S3 to specific users from Amazon CloudFront while restricting access by unauthorized users. How can the Architect implement a solution to meet these requirements?\n",
        "id": 302
    }
]